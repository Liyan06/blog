<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs | Liyan Tang</title>
<meta name=keywords content="Paper,NLP,GRAPH,RE">
<meta name=description content="Authors: Fenia Christopoulou, Makoto Miwa, Sophia Ananiadou">
<meta name=author content>
<link rel=canonical href=https://tangliyan.com/blog/posts/connecting_the_dots/>
<link crossorigin=anonymous href=/blog/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/blog/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://tangliyan.com/blog/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://tangliyan.com/blog/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://tangliyan.com/blog/favicon-32x32.png>
<link rel=apple-touch-icon href=https://tangliyan.com/blog/apple-touch-icon.png>
<link rel=mask-icon href=https://tangliyan.com/blog/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.92.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-202974782-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs">
<meta property="og:description" content="Authors: Fenia Christopoulou, Makoto Miwa, Sophia Ananiadou">
<meta property="og:type" content="article">
<meta property="og:url" content="https://tangliyan.com/blog/posts/connecting_the_dots/"><meta property="og:image" content="https://tangliyan.com/blog/papermod-cover.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2021-01-01T00:00:00+00:00">
<meta property="article:modified_time" content="2021-01-01T00:00:00+00:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://tangliyan.com/blog/papermod-cover.png">
<meta name=twitter:title content="Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs">
<meta name=twitter:description content="Authors: Fenia Christopoulou, Makoto Miwa, Sophia Ananiadou">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tangliyan.com/blog/posts/"},{"@type":"ListItem","position":2,"name":"Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs","item":"https://tangliyan.com/blog/posts/connecting_the_dots/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs","name":"Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs","description":"Authors: Fenia Christopoulou, Makoto Miwa, Sophia Ananiadou","keywords":["Paper","NLP","GRAPH","RE"],"articleBody":"Authors: Fenia Christopoulou, Makoto Miwa, Sophia Ananiadou Paper reference: https://arxiv.org/pdf/1909.00228.pdf\nRelation Extraction (RE) Relation Extraction (RE): The extraction of relations between named entities in text.\nRelation Extraction is an important task of NLP. Most existing works focus on intra-sentence RE. In fact, in real-world scenarios, a large amount of relations are expressed across sentences. The task of identifying these relations is named inter-sentence RE.\nTypically, inter-sentence relations occur in textual snippets with several sentences, such as documents. In these snippets, each entity is usually repeated with the same phrases or aliases, the occurrences of which are often named entity mentions and regarded as instances of the entity.\nThe multiple mentions of the target entities in different sentences can be useful for the identification of inter-sentential relations, as these relations may depend on the interactions of their mentions with other entities in the same document. The figure above is an good example of identifying the relationship between “ethambutol”, “isoniazid” and “scotoma”, where they all interact with the green colored entity (and its alias).\ndocument-level RE   In concept, document-level RE the input is considered an annotated document. The annotations include concept-level entities as well as multiple occurrences of each entity under the same phrase of alias, i.e., entity mentions.\n  Objective: the objective of the task is given an annotated document, to identify all the related concept-level pairs in that document.\n  Document-level RE is not common in the general domain, as the entity types of interest can often be found in the same sentence. On the contrary, in the biomedical domain, document-level relations are particularly important given the numerous aliases that biomedical entities can have (as shown in the figure above).\nIntuition Graph-based neural approaches have proven useful in encoding long distance, inter-sentential information. These models interpret words as nodes and connections between them as edges. They typically perform on the nodes by updating the representations during training.\nThis paper: However, a relation between two entities depends on different contexts. It could thus be better expressed with an edge connection that is unique for the pair. A straightforward way to address this is to create graph-based models that rely on edge representations rather focusing on node representations, which are shared between multiple entity pairs.\nContribution  We propose a novel edge-oriented graph neural model for document-level relation extraction, which encodes information into edge representations rather than node representations. Analysis indicates that the document-level graph can effectively encode document-level dependencies. we show that inter-sentence associations can be beneficial for the detection of intra-sentence relations.  Overview of Proposed Model We presented a novel edge-oriented graph neural model (EoG) for document-level relation extraction using multi-instance learning. The proposed model constructs a document-level graph with heterogeneous types of nodes and edges, modelling intra- and inter-sentence pairs simultaneously with an iterative algorithm over the graph edges.\nHere is an illustration of the abstract architecture of the proposed approach. Proposed Model The proposed model consists of four layers: sentence encoding, graph construction, inference and classification layers. The model receives a document (with identified concept-level entities and their textual mentions) and encodes each sentence separately. A document-level graph is constructed and fed into an iterative algorithm to generate edge representations between the target entity nodes.\nSentence Encoding Layer We use a Bi-LSTM to encode each sentence and then get a contextualized word representations of the input sentence. The contextualized word representations from the encoder are then used to construct a document-level graph structure.\nGraph construction Layer Graph construction consists of Node Construction and Edge Construction.\nNode Construction They form three distinct types of nodes in the graph:\n Mention nodes (M) $n_m$. Mention nodes correspond to different mentions of entities in the input document. The representation of a mention node is formed as the average of the words ($w$) that the mention contains, i.e. $\\operatorname{avg}{w{i} \\in m}\\left(\\mathbf{w}_{i}\\right)$. Entity nodes (E) $n_e$. Entity nodes represent unique entity concepts. The representation of an entity node is computed as the average of the mention ($m$) representations associated with the entity, i.e. $\\operatorname{avg}{m{i} \\in e}\\left(\\mathbf{m}_{i}\\right)$. Sentence nodes (S) $n_s$. Sentence nodes correspond to sentences. A sentence node is represented as the average of the word representations in the sentence, i.e. $\\operatorname{avg}{w{i} \\in s}\\left(\\mathbf{w}_{i}\\right)$.  To distinguish different node types in the graph, they concatenate a node type ($t$) embedding to each node representation. The final node representations are then estimated as $\\mathbf{n}{m}=[\\operatorname{avg}{w_{i} \\in m}\\left(\\mathbf{w}{i}\\right) ; \\mathbf{t}{m}], \\mathbf{n}{e}=$ $[\\operatorname{avg}{m_{i} \\in e}\\left(\\mathbf{m}{i}\\right) ; \\mathbf{t}{e}], \\mathbf{n}{s}=[\\operatorname{avg}{w_{i} \\in s}\\left(\\mathbf{w}{i}\\right) ; \\mathbf{t}{s}]$.\nEdge Construction We pre-define the following edge types:\n  Mention-Mention (MM): Mention-to-mention edges are connected if the corresponding mentions reside in the same sentence. The edge representation between each mention pair $m_{i}$ and $m_{j}$ is generated by concatenating the representations of the nodes, the contexts $c_{m_{i}, m_{j}}$ and a distance embedding associated with the distance between the two mentions $d_{m_{i}, m_{j}},$ in terms of intermediate words: $\\mathbf{x}{\\mathbf{M M}} = [\\mathbf{n}{m_{i}} ; \\mathbf{n}{m{j}} ; \\mathbf{c}{m{i}, m_{j}} ; \\mathbf{d}{m{i}, m_{j}}]$, the context is calculated using $$\\begin{aligned} k \u0026\\in {1,2}\\ \\alpha_{k, i} \u0026=\\mathbf{n}{m{k}}^{\\top} \\mathbf{w}{i} \\ \\mathrm{a}{k, i} \u0026=\\frac{\\exp \\left(\\alpha_{k, i}\\right)}{\\sum_{j \\in[1, n], j \\notin m_{k}} \\exp \\left(\\alpha_{k, j}\\right)} \\ \\mathrm{a}{i} \u0026=\\left(\\mathrm{a}{1, i}+\\mathrm{a}{2, i}\\right) / 2 \\ \\mathrm{c}{m_{1}, m_{2}} \u0026=\\mathbf{H}^{\\top} \\mathrm{a} \\end{aligned}$$ where $\\mathbf{H} \\in \\mathbb{R}^{w \\times d}$ is a sentence word representations matrix.\n  Mention-Sentence (MS): Mention-to-sentence nodes are connected if the mention is in the sentence. The initial edge representation is represented as $\\mathbf{x}{\\mathbf{MS}} = [\\mathbf{n}{m} ; \\mathbf{n}_{s}]$.\n  Mention-Entity (ME): Mention-to-entity nodes are connected if the mention is associated with the entity, $\\mathbf{x}{\\mathbf{ME}} = [\\mathbf{n}{m} ; \\mathbf{n}_{e}]$.\n  Sentence-Sentence (SS): To encode the distance between sentences, they concatenate to the sentence node representations their distance in the form of an embedding. They connect all sentence nodes in the graph, $\\mathbf{x}{\\mathbf{MS}} = [\\mathbf{n}{s_i} ; \\mathbf{n}{s_j}; \\mathbf{d}{s_i,s_j}]$.\n  Entity-Sentence (ES): Entity-to-sentence nodes are connected if at least one mention of the entity is in this sentence, $\\mathbf{x}{\\mathbf{ES}} = [\\mathbf{n}{e} ; \\mathbf{n}_{s}]$.\n  Then there is a linear transformation to make sure each edge representation has the same dimension. For different edge representations, the dimension of the linear transformation layer is different: $$\\mathbf{e}{z}^{(1)}=\\mathbf{W}{z} \\mathbf{x}{z}$$ where $\\mathbf{e}{z}^{(1)}$ is an edge representation of length 1. $\\mathbf{W}{z} \\in \\mathbb{R}^{d{z} \\times d}$ corresponds to a learned matrix and $z \\in[\\mathrm{MM}, \\mathrm{MS}, \\mathrm{ME}, \\mathrm{SS}, \\mathrm{ES}]$.\nInference Layer Note that entity-to-entity (EE) edge is not pre-defined in the previous step. We can only generate EE edge representations by representing a path between their nodes. we adapt two-step inference mechanism to encode interactions between nodes and edges in the graph and hence model EE associations.\nFirst Step Goal: generate a path between two nodes $i$ and $j$ using intermediate nodes $k$ (Intermediate nodes without adjacent edges to the target nodes are ignored).\nWe thus combine the representations of two consecutive edges $e_{ik}$ and $e_{kj}$, using a modified bilinear transformation. This action generates an edge representation of double length. We combine all existing paths between $i$ and $j$ through $k$:\n$$f\\left(\\mathbf{e}{i k}^{(l)}, \\mathbf{e}{k j}^{(l)}\\right)=\\sigma\\left(\\mathbf{e}{i k}^{(l)} \\odot\\left(\\mathbf{W} \\mathbf{e}{k j}^{(l)}\\right)\\right)$$ where $\\mathbf{W} \\in$ $\\mathbb{R}^{d_{z} \\times d_{z}}$ is a learned parameter matrix, $\\odot$ refers to element-wise multiplication, $l$ is the length of the edge and $\\mathbf{e}_{i k}$ corresponds to the representation of the edge between nodes $i$ and $k$.\nSecond Step During the second step, we aggregate the original (short) edge representation and the new (longer) edge representation resulted from Equation (3) as follows:$$ \\mathbf{e}{i j}^{(2 l)}=\\beta \\mathbf{e}{i j}^{(l)}+(1-\\beta) \\sum_{k \\neq i, j} f\\left(\\mathbf{e}{i k}^{(l)}, \\mathbf{e}{k j}^{(l)}\\right)$$ where $\\beta \\in[0,1]$.\nThe two steps are repeated a finite number of times N.\n Everytime when going through step one, we find an intermediate node. With initial edge length equal to 1, the first iteration results in edges of length up-to 2. The second iteration results in edges of length up-to 4. Similarly, after N iterations, the length of edges will be upto $2^N$.Here is an illustration after iterations:   There can be many valid node $k$ between node $i$ and node $j$, here is an illustration   Classification Layer We use the entity-to-entity edges (EE) of the document graph that correspond to the concept-level entity pairs to classify the concept-level entity pairs $$ \\mathbf{y}=\\operatorname{softmax}\\left(\\mathbf{W}{c} \\mathbf{e}{\\mathrm{EE}}+\\mathbf{b}{c}\\right) $$ where $\\mathbf{W}{c} \\in \\mathbb{R}^{r \\times d_{z}}$ and $\\mathbf{b}_{c} \\in \\mathbb{R}^{r}$ are learned parameters of the classification layer and $r$ is the number of relation categories.\nResult Three models being compared:\n Edge-oriented Graph (EoG) refers to our main model with edges {MM, ME, MS, ES, SS}. The EoG (Full) setting refers to a model with a fully connected graph, where the graph nodes are all connected to each other, including E nodes. The EoG (NoInf) setting refers to a no inference model, where the iterative inference algorithm is ignored. The EoG (Sent) setting refers to a model that was trained on sentences instead of documents.   Our model performs significantly better on intra- and inter-sentential pairs, even compared to most of the models with external knowledge. For the inter-sentence pairs, performance significantly drops with EoG(Full) and EoG(NoInf). The former might indicate the existence of certain reasoning paths that should be followed in order to relate entities residing in different sentences. The intra-sentence pairs substantially benefit from the document-level information.   Removal of ES edges reduces the performance of all pairs, as encoding of EE edges becomes more difficult and requires long inference paths as shown in figure (a). [we enable identification of pairs across sentences only through MM and ME edge. In this case, the minimum inference length is 6 (E-M-M-E-M-M-E)]  As shown in figure (b), the introduction of S nodes results in a path with half the length, which we expect to better represent the relation.   The figure above illustrates that for long-distanced pairs, EoG has lower performance, indicating a possible requirement for other latent document-level information.  Bad Cases Analysis  The model cannot find associations between entities if they are connected by “and”. MIssing coreference connections. Incomplete entity linking.   Reference:\n Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs. https://arxiv.org/pdf/1909.00228.pdf.  ","wordCount":"1640","inLanguage":"en","datePublished":"2021-01-01T00:00:00Z","dateModified":"2021-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://tangliyan.com/blog/posts/connecting_the_dots/"},"publisher":{"@type":"Organization","name":"Liyan Tang","logo":{"@type":"ImageObject","url":"https://tangliyan.com/blog/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://tangliyan.com/blog/ accesskey=h title="Liyan Tang (Alt + H)">Liyan Tang</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://tangliyan.com/blog/archives title=Archive>
<span>Archive</span>
</a>
</li>
<li>
<a href=https://tangliyan.com/blog/tags/ title=Tags>
<span>Tags</span>
</a>
</li>
<li>
<a href=https://tangliyan.com/blog/search/ title="Search (Alt + /)" accesskey=/>
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://tangliyan.com/blog/>Home</a>&nbsp;»&nbsp;<a href=https://tangliyan.com/blog/posts/>Posts</a></div>
<h1 class=post-title>
Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs
</h1>
<div class=post-meta><span title="2021-01-01 00:00:00 +0000 UTC">January 1, 2021</span>&nbsp;·&nbsp;8 min
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#relation-extraction-re aria-label="Relation Extraction (RE)">Relation Extraction (RE)</a><ul>
<li>
<a href=#document-level-re aria-label="document-level RE">document-level RE</a></li></ul>
</li>
<li>
<a href=#intuition aria-label=Intuition>Intuition</a></li>
<li>
<a href=#contribution aria-label=Contribution>Contribution</a></li>
<li>
<a href=#overview-of-proposed-model aria-label="Overview of Proposed Model">Overview of Proposed Model</a></li>
<li>
<a href=#proposed-model aria-label="Proposed Model">Proposed Model</a><ul>
<li>
<a href=#sentence-encoding-layer aria-label="Sentence Encoding Layer">Sentence Encoding Layer</a></li>
<li>
<a href=#graph-construction-layer aria-label="Graph construction Layer">Graph construction Layer</a><ul>
<li>
<a href=#node-construction aria-label="Node Construction">Node Construction</a></li>
<li>
<a href=#edge-construction aria-label="Edge Construction">Edge Construction</a></li></ul>
</li>
<li>
<a href=#inference-layer aria-label="Inference Layer">Inference Layer</a><ul>
<li>
<a href=#first-step aria-label="First Step">First Step</a></li>
<li>
<a href=#second-step aria-label="Second Step">Second Step</a></li></ul>
</li>
<li>
<a href=#classification-layer aria-label="Classification Layer">Classification Layer</a></li></ul>
</li>
<li>
<a href=#result aria-label=Result>Result</a></li>
<li>
<a href=#bad-cases-analysis aria-label="Bad Cases Analysis">Bad Cases Analysis</a>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><p>Authors: Fenia Christopoulou, Makoto Miwa, Sophia Ananiadou <br>
Paper reference: <a href=https://arxiv.org/pdf/1909.00228.pdf>https://arxiv.org/pdf/1909.00228.pdf</a></p>
<h2 id=relation-extraction-re>Relation Extraction (RE)<a hidden class=anchor aria-hidden=true href=#relation-extraction-re>#</a></h2>
<p><strong>Relation Extraction (RE): The extraction of relations between named entities in text.</strong></p>
<img src="https://img-blog.csdnimg.cn/20201231080735572.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_1,color_FFFFFF,t_70#pic_center" width=600>
<p>Relation Extraction is an important task of NLP. Most existing works focus on intra-sentence RE. In fact, in real-world scenarios, a large amount of relations are expressed across sentences. The task of identifying these relations is named <strong>inter-sentence RE</strong>.</p>
<p>Typically, inter-sentence relations occur in textual snippets with several sentences, such as documents. <em>In these snippets, each entity is usually repeated with the same phrases or aliases, the occurrences of which are often named entity mentions and regarded as instances of the entity.</em></p>
<p>The multiple mentions of the target entities in different sentences can be useful for the identification of inter-sentential relations, as these relations may depend on the interactions of their mentions with other entities in the same document. The figure above is an good example of identifying the relationship between &ldquo;ethambutol&rdquo;, &ldquo;isoniazid&rdquo; and &ldquo;scotoma&rdquo;, where they all interact with the green colored entity (and its alias).</p>
<h3 id=document-level-re>document-level RE<a hidden class=anchor aria-hidden=true href=#document-level-re>#</a></h3>
<ul>
<li>
<p><strong>In concept, document-level RE the input is considered an annotated document.</strong> The annotations include concept-level entities as well as multiple occurrences of each entity under the same phrase of alias, i.e., entity mentions.</p>
</li>
<li>
<p><strong>Objective</strong>: the objective of the task is given an annotated document, to <strong>identify all the related concept-level pairs in that document.</strong></p>
</li>
</ul>
<p>Document-level RE is not common in the general domain, as the entity types of interest can often be found in the same sentence. On the contrary, in the biomedical domain, document-level relations are particularly important given the numerous aliases that biomedical entities can have (as shown in the figure above).</p>
<h2 id=intuition>Intuition<a hidden class=anchor aria-hidden=true href=#intuition>#</a></h2>
<p>Graph-based neural approaches have proven useful in encoding long distance, inter-sentential information. These models interpret words as nodes and connections between them as edges. They typically perform on the nodes by updating the representations during training.</p>
<p>This paper: However, a relation between two entities depends on different contexts. <strong>It could thus be better expressed with an edge connection that is unique for the pair.</strong> A straightforward way to address this is to create graph-based models that rely on edge representations rather focusing on node representations, which are shared between multiple entity pairs.</p>
<h2 id=contribution>Contribution<a hidden class=anchor aria-hidden=true href=#contribution>#</a></h2>
<ul>
<li>We propose a novel edge-oriented graph neural model for document-level relation extraction, which encodes information into edge representations rather than node representations.</li>
<li>Analysis indicates that the document-level graph can effectively encode document-level dependencies.</li>
<li>we show that inter-sentence associations can be beneficial for the detection of intra-sentence relations.</li>
</ul>
<h2 id=overview-of-proposed-model>Overview of Proposed Model<a hidden class=anchor aria-hidden=true href=#overview-of-proposed-model>#</a></h2>
<p>We presented a novel <strong>edge-oriented graph neural model (EoG)</strong> for document-level relation extraction using multi-instance learning. The proposed model constructs a document-level graph with <em>heterogeneous types of nodes and edges</em>, modelling intra- and inter-sentence pairs simultaneously with an iterative algorithm over the graph edges.</p>
<p>Here is an illustration of the abstract architecture of the proposed approach.
<img loading=lazy src="https://img-blog.csdnimg.cn/20201230111413873.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_1,color_FFFFFF,t_70#pic_center" alt=在这里插入图片描述>
</p>
<h2 id=proposed-model>Proposed Model<a hidden class=anchor aria-hidden=true href=#proposed-model>#</a></h2>
<p>The proposed model consists of four layers: sentence encoding, graph construction, inference and classification layers. The model receives a document (with identified concept-level entities and their textual mentions) and encodes each sentence separately. A document-level graph is constructed and fed into an iterative algorithm to generate edge representations between the target entity nodes.</p>
<h3 id=sentence-encoding-layer>Sentence Encoding Layer<a hidden class=anchor aria-hidden=true href=#sentence-encoding-layer>#</a></h3>
<p>We use a Bi-LSTM to encode each sentence and then get a contextualized word representations of the input sentence. The contextualized word representations from the encoder are then used to construct a document-level graph structure.</p>
<h3 id=graph-construction-layer>Graph construction Layer<a hidden class=anchor aria-hidden=true href=#graph-construction-layer>#</a></h3>
<p>Graph construction consists of <strong>Node Construction</strong> and <strong>Edge Construction</strong>.</p>
<h4 id=node-construction>Node Construction<a hidden class=anchor aria-hidden=true href=#node-construction>#</a></h4>
<p>They form three distinct types of nodes in the graph:</p>
<ul>
<li><strong>Mention nodes</strong> (M) $n_m$. Mention nodes correspond to different mentions of entities in the input document. The representation of a mention node is formed as the average of the words ($w$) that the mention contains, i.e. $\operatorname{avg}<em>{w</em>{i} \in m}\left(\mathbf{w}_{i}\right)$.</li>
<li><strong>Entity nodes</strong> (E) $n_e$. Entity nodes represent unique entity concepts. The representation of an entity node is computed as the average of the mention ($m$) representations associated with the entity, i.e. $\operatorname{avg}<em>{m</em>{i} \in e}\left(\mathbf{m}_{i}\right)$.</li>
<li><strong>Sentence nodes</strong> (S) $n_s$. Sentence nodes correspond to sentences. A sentence node is represented as the average of the word representations in the sentence, i.e. $\operatorname{avg}<em>{w</em>{i} \in s}\left(\mathbf{w}_{i}\right)$.</li>
</ul>
<p><em>To distinguish different node types in the graph</em>, they concatenate a node type ($t$) embedding to each node representation. The final node representations are then estimated as $\mathbf{n}<em>{m}=[\operatorname{avg}</em>{w_{i} \in m}\left(\mathbf{w}<em>{i}\right) ; \mathbf{t}</em>{m}], \mathbf{n}<em>{e}=$ $[\operatorname{avg}</em>{m_{i} \in e}\left(\mathbf{m}<em>{i}\right) ; \mathbf{t}</em>{e}], \mathbf{n}<em>{s}=[\operatorname{avg}</em>{w_{i} \in s}\left(\mathbf{w}<em>{i}\right) ; \mathbf{t}</em>{s}]$.</p>
<h4 id=edge-construction>Edge Construction<a hidden class=anchor aria-hidden=true href=#edge-construction>#</a></h4>
<p>We pre-define the following edge types:</p>
<ul>
<li>
<p><strong>Mention-Mention (MM): Mention-to-mention edges are connected if the corresponding mentions reside in the same sentence.</strong> The edge representation between each mention pair $m_{i}$ and $m_{j}$ is generated by concatenating the representations of the nodes, the contexts $c_{m_{i}, m_{j}}$ and a distance embedding associated with the distance between the two mentions $d_{m_{i}, m_{j}},$ in terms of intermediate words: $\mathbf{x}<em>{\mathbf{M M}} = [\mathbf{n}</em>{m_{i}} ; \mathbf{n}<em>{m</em>{j}} ; \mathbf{c}<em>{m</em>{i}, m_{j}} ; \mathbf{d}<em>{m</em>{i}, m_{j}}]$, the context is calculated using
$$\begin{aligned} k &\in {1,2}\ \alpha_{k, i} &=\mathbf{n}<em>{m</em>{k}}^{\top} \mathbf{w}<em>{i} \ \mathrm{a}</em>{k, i} &=\frac{\exp \left(\alpha_{k, i}\right)}{\sum_{j \in[1, n], j \notin m_{k}} \exp \left(\alpha_{k, j}\right)} \ \mathrm{a}<em>{i} &=\left(\mathrm{a}</em>{1, i}+\mathrm{a}<em>{2, i}\right) / 2 \ \mathrm{c}</em>{m_{1}, m_{2}} &=\mathbf{H}^{\top} \mathrm{a} \end{aligned}$$ where $\mathbf{H} \in \mathbb{R}^{w \times d}$ is a sentence word representations matrix.</p>
</li>
<li>
<p><strong>Mention-Sentence (MS): Mention-to-sentence nodes are connected if the mention is in the sentence.</strong> The initial edge representation is represented as $\mathbf{x}<em>{\mathbf{MS}} = [\mathbf{n}</em>{m} ; \mathbf{n}_{s}]$.</p>
</li>
<li>
<p><strong>Mention-Entity (ME): Mention-to-entity nodes are connected if the mention is associated with the entity</strong>, $\mathbf{x}<em>{\mathbf{ME}} = [\mathbf{n}</em>{m} ; \mathbf{n}_{e}]$.</p>
</li>
<li>
<p><strong>Sentence-Sentence (SS)</strong>: To encode the distance between sentences, they concatenate
to the sentence node representations their distance in the form of an embedding. <strong>They connect all sentence nodes in the graph</strong>, $\mathbf{x}<em>{\mathbf{MS}} = [\mathbf{n}</em>{s_i} ; \mathbf{n}<em>{s_j}; \mathbf{d}</em>{s_i,s_j}]$.</p>
</li>
<li>
<p><strong>Entity-Sentence (ES)</strong>: Entity-to-sentence nodes are connected if at least one mention of the entity is in this sentence, $\mathbf{x}<em>{\mathbf{ES}} = [\mathbf{n}</em>{e} ; \mathbf{n}_{s}]$.</p>
</li>
</ul>
<p>Then there is a linear transformation to make sure each edge representation has the same dimension. For different edge representations, the dimension of the linear transformation layer is different: $$\mathbf{e}<em>{z}^{(1)}=\mathbf{W}</em>{z} \mathbf{x}<em>{z}$$ where $\mathbf{e}</em>{z}^{(1)}$ is an edge representation of length 1. $\mathbf{W}<em>{z} \in \mathbb{R}^{d</em>{z} \times d}$ corresponds to a learned matrix and $z \in[\mathrm{MM}, \mathrm{MS}, \mathrm{ME}, \mathrm{SS}, \mathrm{ES}]$.</p>
<h3 id=inference-layer>Inference Layer<a hidden class=anchor aria-hidden=true href=#inference-layer>#</a></h3>
<p><strong>Note that entity-to-entity (EE) edge is not pre-defined in the previous step. We can only generate EE edge representations by representing a path between their nodes.</strong> <em>we adapt two-step inference mechanism to encode interactions between nodes and edges in the graph and hence model EE associations.</em></p>
<h4 id=first-step>First Step<a hidden class=anchor aria-hidden=true href=#first-step>#</a></h4>
<p>Goal: generate a path between two nodes $i$ and $j$ using intermediate nodes $k$ (Intermediate nodes without adjacent edges to the target nodes are ignored).</p>
<p>We thus combine the representations of two consecutive edges $e_{ik}$ and $e_{kj}$, using a modified bilinear transformation. <strong>This action generates an edge representation of double length.</strong> We combine all existing paths between $i$ and $j$ through $k$:</p>
<p>$$f\left(\mathbf{e}<em>{i k}^{(l)}, \mathbf{e}</em>{k j}^{(l)}\right)=\sigma\left(\mathbf{e}<em>{i k}^{(l)} \odot\left(\mathbf{W} \mathbf{e}</em>{k j}^{(l)}\right)\right)$$
where $\mathbf{W} \in$ $\mathbb{R}^{d_{z} \times d_{z}}$ is a learned parameter matrix, $\odot$ refers to element-wise multiplication, $l$ is the length of the edge and $\mathbf{e}_{i k}$ corresponds to the representation of the edge between nodes $i$ and $k$.</p>
<h4 id=second-step>Second Step<a hidden class=anchor aria-hidden=true href=#second-step>#</a></h4>
<p>During the second step, we aggregate the original (short) edge representation and the new (longer) edge representation resulted from Equation (3) as follows:$$
\mathbf{e}<em>{i j}^{(2 l)}=\beta \mathbf{e}</em>{i j}^{(l)}+(1-\beta) \sum_{k \neq i, j} f\left(\mathbf{e}<em>{i k}^{(l)}, \mathbf{e}</em>{k j}^{(l)}\right)$$ where $\beta \in[0,1]$.</p>
<p>The two steps are repeated a finite number of times N.</p>
<ul>
<li>Everytime when going through step one, we find an intermediate node. With initial edge length equal to 1, the first iteration results in edges of length up-to 2. The second iteration results in edges of length up-to 4. Similarly, after N iterations, the length of edges will be upto $2^N$.Here is an illustration after iterations:</li>
</ul>
<img src="https://img-blog.csdnimg.cn/20201230131120926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_20,color_FFFFFF,t_70#pic_center" width=700>
<ul>
<li>There can be many valid node $k$ between node $i$ and node $j$, here is an illustration
<img src="https://img-blog.csdnimg.cn/20201230131140997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_18,color_FFFFFF,t_70#pic_center" width=350></li>
</ul>
<h3 id=classification-layer>Classification Layer<a hidden class=anchor aria-hidden=true href=#classification-layer>#</a></h3>
<p>We use the entity-to-entity edges (EE) of the document graph that correspond to the concept-level entity pairs to classify the concept-level entity pairs
$$
\mathbf{y}=\operatorname{softmax}\left(\mathbf{W}<em>{c} \mathbf{e}</em>{\mathrm{EE}}+\mathbf{b}<em>{c}\right)
$$ where $\mathbf{W}</em>{c} \in \mathbb{R}^{r \times d_{z}}$ and $\mathbf{b}_{c} \in \mathbb{R}^{r}$ are learned parameters of the classification layer and $r$ is the number of relation categories.</p>
<h2 id=result>Result<a hidden class=anchor aria-hidden=true href=#result>#</a></h2>
<p>Three models being compared:</p>
<ol>
<li>Edge-oriented Graph (EoG) refers to our main model with edges {MM, ME, MS, ES, SS}.</li>
<li>The EoG (Full) setting refers to a model with a fully connected graph, where the graph nodes are all connected to each other, including E nodes.</li>
<li>The EoG (NoInf) setting refers to a no inference model, where the iterative inference algorithm is ignored.</li>
<li>The EoG (Sent) setting refers to a model that was trained on sentences instead of documents.</li>
</ol>
<p><img loading=lazy src="https://img-blog.csdnimg.cn/20201230134900216.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_16,color_FFFFFF,t_70#pic_center" alt=在这里插入图片描述>
</p>
<ul>
<li>Our model performs significantly better on intra- and inter-sentential pairs, even compared to most of the models with external knowledge.</li>
<li>For the inter-sentence pairs, performance significantly drops with EoG(Full) and EoG(NoInf). <strong>The former might indicate the existence of certain reasoning paths that should be followed in order to relate entities residing in different sentences.</strong></li>
<li><em>The intra-sentence pairs substantially benefit from the document-level information.</em></li>
</ul>
<img src="https://img-blog.csdnimg.cn/20201230135047935.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_1,color_FFFFFF,t_70#pic_center" width=500>
<ul>
<li>Removal of ES edges reduces the performance of all pairs, as encoding of EE edges becomes more difficult and requires long inference paths as shown in figure (a). [we enable identification of pairs across sentences only through MM and ME edge. In this case, the minimum inference length is 6 (E-M-M-E-M-M-E)]
<img loading=lazy src="https://img-blog.csdnimg.cn/20201230135211342.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_1,color_FFFFFF,t_70#pic_center" alt=在这里插入图片描述>
</li>
<li>As shown in figure (b), the introduction of S nodes results in a path with half the length, which we expect to better represent the relation.</li>
</ul>
<p><img loading=lazy src="https://img-blog.csdnimg.cn/2020123100372664.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_1,color_FFFFFF,t_70#pic_center" alt=在这里插入图片描述>
</p>
<ul>
<li>The figure above illustrates that for long-distanced pairs, EoG has lower performance, indicating a possible requirement for other latent document-level information.</li>
</ul>
<h2 id=bad-cases-analysis>Bad Cases Analysis<a hidden class=anchor aria-hidden=true href=#bad-cases-analysis>#</a></h2>
<ul>
<li>The model cannot find associations between entities if they are connected by &ldquo;and&rdquo;.</li>
<li>MIssing coreference connections.</li>
<li>Incomplete entity linking.</li>
</ul>
<hr>
<p>Reference:</p>
<ul>
<li>Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs. <a href=https://arxiv.org/pdf/1909.00228.pdf>https://arxiv.org/pdf/1909.00228.pdf</a>.</li>
</ul>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://tangliyan.com/blog/tags/paper/>PAPER</a></li>
<li><a href=https://tangliyan.com/blog/tags/nlp/>NLP</a></li>
<li><a href=https://tangliyan.com/blog/tags/graph/>GRAPH</a></li>
<li><a href=https://tangliyan.com/blog/tags/re/>RE</a></li>
</ul>
<nav class=paginav>
<a class=prev href=https://tangliyan.com/blog/posts/relation_extraction/>
<span class=title>« Prev Page</span>
<br>
<span>Overlook of Relation Extraction</span>
</a>
<a class=next href=https://tangliyan.com/blog/posts/corss_lingual/>
<span class=title>Next Page »</span>
<br>
<span>Cross-Lingual Learning</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs on twitter" href="https://twitter.com/intent/tweet/?text=Paper%20Review%20-%20Connecting%20the%20Dots%3a%20Document-level%20Neural%20Relation%20Extraction%20with%20Edge-oriented%20Graphs&url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconnecting_the_dots%2f&hashtags=Paper%2cNLP%2cGRAPH%2cRE"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconnecting_the_dots%2f&title=Paper%20Review%20-%20Connecting%20the%20Dots%3a%20Document-level%20Neural%20Relation%20Extraction%20with%20Edge-oriented%20Graphs&summary=Paper%20Review%20-%20Connecting%20the%20Dots%3a%20Document-level%20Neural%20Relation%20Extraction%20with%20Edge-oriented%20Graphs&source=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconnecting_the_dots%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconnecting_the_dots%2f&title=Paper%20Review%20-%20Connecting%20the%20Dots%3a%20Document-level%20Neural%20Relation%20Extraction%20with%20Edge-oriented%20Graphs"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconnecting_the_dots%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs on whatsapp" href="https://api.whatsapp.com/send?text=Paper%20Review%20-%20Connecting%20the%20Dots%3a%20Document-level%20Neural%20Relation%20Extraction%20with%20Edge-oriented%20Graphs%20-%20https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconnecting_the_dots%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Paper Review - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs on telegram" href="https://telegram.me/share/url?text=Paper%20Review%20-%20Connecting%20the%20Dots%3a%20Document-level%20Neural%20Relation%20Extraction%20with%20Edge-oriented%20Graphs&url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconnecting_the_dots%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href=https://tangliyan.com/blog/>Liyan Tang</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
<script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script>
</body>
</html>