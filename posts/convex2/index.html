<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Introduction to Convex Optimization - Primal problem to Dual problem | Liyan Tang</title>
<meta name=keywords content="ML,MATH,OPTIMIZATION">
<meta name=description content="Consider an optimization problem in the standard form (we call this a primal problem):
We denote the optimal value of this as $p^\star$. We don&rsquo;t assume the problem is convex.
The Lagrange dual function We define the Lagrangian $L$ associated with the problem as $$ L(x,\lambda, v) = f_0(x) + \sum^m_{i=1}\lambda_if_i(x) + \sum^p_{i=1}v_ih_i(x)$$ We call vectors $\lambda$ and $v$ the dual variables or Lagrange multiplier vectors associated with the problem (1).">
<meta name=author content>
<link rel=canonical href=https://tangliyan.com/blog/posts/convex2/>
<link crossorigin=anonymous href=/blog/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/blog/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://tangliyan.com/blog/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://tangliyan.com/blog/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://tangliyan.com/blog/favicon-32x32.png>
<link rel=apple-touch-icon href=https://tangliyan.com/blog/apple-touch-icon.png>
<link rel=mask-icon href=https://tangliyan.com/blog/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.92.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-202974782-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="Introduction to Convex Optimization - Primal problem to Dual problem">
<meta property="og:description" content="Consider an optimization problem in the standard form (we call this a primal problem):
We denote the optimal value of this as $p^\star$. We don&rsquo;t assume the problem is convex.
The Lagrange dual function We define the Lagrangian $L$ associated with the problem as $$ L(x,\lambda, v) = f_0(x) + \sum^m_{i=1}\lambda_if_i(x) + \sum^p_{i=1}v_ih_i(x)$$ We call vectors $\lambda$ and $v$ the dual variables or Lagrange multiplier vectors associated with the problem (1).">
<meta property="og:type" content="article">
<meta property="og:url" content="https://tangliyan.com/blog/posts/convex2/"><meta property="og:image" content="https://tangliyan.com/blog/papermod-cover.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2020-03-29T00:00:00+00:00">
<meta property="article:modified_time" content="2020-03-29T00:00:00+00:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://tangliyan.com/blog/papermod-cover.png">
<meta name=twitter:title content="Introduction to Convex Optimization - Primal problem to Dual problem">
<meta name=twitter:description content="Consider an optimization problem in the standard form (we call this a primal problem):
We denote the optimal value of this as $p^\star$. We don&rsquo;t assume the problem is convex.
The Lagrange dual function We define the Lagrangian $L$ associated with the problem as $$ L(x,\lambda, v) = f_0(x) + \sum^m_{i=1}\lambda_if_i(x) + \sum^p_{i=1}v_ih_i(x)$$ We call vectors $\lambda$ and $v$ the dual variables or Lagrange multiplier vectors associated with the problem (1).">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tangliyan.com/blog/posts/"},{"@type":"ListItem","position":2,"name":"Introduction to Convex Optimization - Primal problem to Dual problem","item":"https://tangliyan.com/blog/posts/convex2/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Introduction to Convex Optimization - Primal problem to Dual problem","name":"Introduction to Convex Optimization - Primal problem to Dual problem","description":"Consider an optimization problem in the standard form (we call this a primal problem):\nWe denote the optimal value of this as $p^\\star$. We don\u0026rsquo;t assume the problem is convex.\nThe Lagrange dual function We define the Lagrangian $L$ associated with the problem as $$ L(x,\\lambda, v) = f_0(x) + \\sum^m_{i=1}\\lambda_if_i(x) + \\sum^p_{i=1}v_ih_i(x)$$ We call vectors $\\lambda$ and $v$ the dual variables or Lagrange multiplier vectors associated with the problem (1).","keywords":["ML","MATH","OPTIMIZATION"],"articleBody":"Consider an optimization problem in the standard form (we call this a primal problem):\nWe denote the optimal value of this as $p^\\star$. We donâ€™t assume the problem is convex.\nThe Lagrange dual function We define the Lagrangian $L$ associated with the problem as $$ L(x,\\lambda, v) = f_0(x) + \\sum^m_{i=1}\\lambda_if_i(x) + \\sum^p_{i=1}v_ih_i(x)$$ We call vectors $\\lambda$ and $v$ the dual variables or Lagrange multiplier vectors associated with the problem (1).\nWe define the Lagrange dual function (or just dual function) $g$ as the minimum value of the Lagrangian over $x$: for $\\lambda \\in \\mathbf{R}^m, v\\in\\mathbf{R}^p$, $$g(\\lambda,v) = \\mathop{\\rm inf}\\limits_{x\\in \\mathcal{D}} L(x, \\lambda, v) = \\mathop{\\rm inf}\\limits_{x\\in \\mathcal{D}} \\left( f_0(x) + \\sum^m_{i=1}\\lambda_if_i(x) + \\sum^p_{i=1}v_ih_i(x)\\right)$$\nNote that once we choose an $x$, $f_i(x)$ and $h_i(x)$ are fixed and therefore the dual function is a family of affine functions of ($\\lambda$, $v$), which is concave even the problem (1) is not convex.\nLower bound property The dual function yields lower bounds on the optimal value $p^\\star$ of the problem (1): For any $\\lambda \\succeq 0$ and any $v$ we have $$ g(\\lambda,v) \\leq p^\\star$$\nSuppose $\\tilde{x}$ is a feasible point for the problem (1), i.e., $f_i(\\tilde{x}) \\leq 0$ and $h_i(\\tilde{x}) = 0$, and $\\lambda \\succeq 0$. Then we have\n$$ L(\\tilde{x}, \\lambda, v) = f_0(\\tilde{x}) + \\sum^m_{i=1}\\lambda_if_i(\\tilde{x}) + \\sum^p_{i=1}v_ih_i(\\tilde{x}) \\leq f_0(\\tilde{x})$$\nHence $$ g(\\lambda,v) = \\mathop{\\rm inf}\\limits_{x\\in \\mathcal{D}} L(x, \\lambda, v) \\leq L(\\tilde{x}, \\lambda, v) \\leq f_0(\\tilde{x})$$\nSince $g(\\lambda,v) \\leq f_0(\\tilde{x})$ holds for every feasible point $\\tilde{x}$, the inequality $g(\\lambda,v) \\leq p$ follows. The inequality holds, but is vacuous, when $g(\\lambda,v) = -\\infty$. The dual function gives a nontrivial lower bound on $p^\\star$ only when $\\lambda \\succeq 0$ and $(\\lambda,v) \\in \\textbf{dom},g$, i.e., $g(\\lambda,v)  - \\infty$. We refer to a pair $(\\lambda,v)$ with $\\lambda \\succeq 0$ and $(\\lambda,v) \\in \\textbf{dom},g$ as dual feasible.\nDerive an analytical expression for the Lagrange dual function Practice problem 1: Least-squares solution of linear equations The Lagrangian is $L(x,v) = x^\\top x + v^\\top(Ax-b)$. The dual function is given by $g(v) = \\text{inf}_x L(x,v)$. Since $L(x,v)$ is a convex quadratic function of $x$, we can find the minimizing $x$ from the optimality condition\n$$ \\nabla_x L(x,v) = 2x + A^\\top v = 0$$\nwhich yields $x = -(1/2)A^\\top v$. Therefore the dual function is\n$$ g(v) = L(-(1/2)A^\\top v, v) = -(1/4)v^\\top AA^\\top v - b^\\top v$$\nTherefore, $p^\\star \\geq -(1/4)v^\\top AA^\\top v - b^\\top v$. The next step is to maximize $-(1/4)v^\\top AA^\\top v - b^\\top v$.\nPractice problem 2: Standard form Linear Programming The Lagrangian is $$ L(x, \\lambda, v) = c^\\top x - \\sum^n_{i=1}\\lambda_ix_i + v^\\top(Ax-b) = -b^\\top v + (c + A^\\top v - \\lambda)^\\top x$$\nThe dual function is $$ g(\\lambda, v) = \\mathop{\\rm inf}\\limits_{x} L(x, \\lambda, v) = -b^\\top v + \\mathop{\\rm inf}\\limits_{x}, (c + A^\\top v - \\lambda)^\\top x$$\nWe see that $g(\\lambda,v)$ is a linear function. Since a linear function is bounded below only when it is zero. Thus, $g(\\lambda,v) = -\\infty$ except when $c + A^\\top v - \\lambda = 0$. Therefore,\nThe lower bound property is nontrivial only when $\\lambda$ and $v$ satisfy $\\lambda \\succeq 0$ and $c + A^\\top v - \\lambda$. When this occurs, $-b^\\top v$ is a lower bound on the optimal value of the LP. We can form an equivalent dual problem by making these equality constraints explicit:\nThis problem, in turn, can be expressed as\nThe Lagrange dual problem For each pair $(\\lambda,v)$ with $\\lambda \\succeq 0$, the Lagrange dual function gives us a lower bound on the optimal value $p^\\star$ of the optimization problem (1). Thus we have a lower bound that depends on some parameters $\\lambda, v$.\nThis leads to the optimization problem\nThis problem is called the Lagrange dual problem associated with the problem (1). In this context the original problem (1) is sometimes called the primal problem. We refer to $(\\lambda^\\star, v^\\star)$ as dual optimal or optimal Lagrange multipliers if they are optimal for the problem (2). The Lagrange dual problem (2) is a convex optimization problem, since the objective to be maximized is concave and the constraint is convex. This is the case whether or not the primal problem (5.1) is convex.\nNote: the dual problem is always convex.\nWeak/ Strong duality The optimal value of the Lagrange dual problem, which we denote $d^\\star$, is, by definition, the best lower bound on $p^\\star$ that can be obtained from the Lagrange dual function. The inequality\n$$ d^\\star \\leq p^\\star$$\nwhich holds even if the original problem is not convex. This property is called weak duality.\nWe refer to the difference $p^\\star - d^\\star$ as the optimal duality gap of the original problem. Note that th optimal duality gap is always nonnegative.\nWe say that strong duality holds if\n$$ d^\\star = p^\\star$$\nNote that strong duality does not hold in general. But if the primal problem (11) is convex with $f_1, â€¦, f_k$ convex, we usually (but not always) have strong duality.\nSlaterâ€™s condition Slaterâ€™s condition: There exists an $x \\in \\mathbf{relint}, D$ such that $$f_i(x) Such a point is called strictly feasible.\nSlaterâ€™s theorem: If Slaterâ€™s condition holds for a convex problem, then the strong duality holds.\nComplementary slackness Suppose the strong duality holds. Let $x^\\star$ be a primal optimal and $(\\lambda^\\star, v^\\star)$ be a dual optimal point. This means that\nWe conclude that the two inequalities in this chain hold with equality. Since the inequality in the third line is an equality, we conclude that $x^\\star$ minimizes $L(x, \\lambda^\\star, v^\\star)$ over $x$.\nAnother important conclusion is\n$$ \\lambda_i^\\star f_i(x^\\star) = 0, \\quad i = 1,â€¦,m$$\nKKT optimality conditions We now assume that the functions $f_0, â€¦, f_m, h_1, â€¦,h_p$ are differentiable, but we make no assumptions yet about convexity.\nKKT conditions for nonconvex problems Suppose the strong duality holds. Let $x^\\star$ be a primal optimal and $(\\lambda^\\star, v^\\star)$ be a dual optimal point. Since $x^\\star$ minimizes $L(x, \\lambda^\\star, v^\\star)$ over $x$, it follows that its gradient must vanish at $x^\\star$, i.e.,\n$$ \\nabla f_0(x^\\star) + \\sum^m_{i=1}\\lambda_i^\\star \\nabla f_i(x^\\star) + \\sum^p_{i=1}v_i^\\star \\nabla h_i(x^\\star) = 0$$\nThe KKT conditions are the following: For any optimization problem with differentiable objective and constraint functions for which strong duality obtains, any pair of primal and dual optimal points must satisfy the KKT conditions.\nKKT conditions for convex problems When the primal problem is convex, the KKT conditions are also sufficient for the points to be primal and dual optimal. That is, if $f_i$ are convex and $h_i$ are affine, and $\\tilde{x}, \\tilde{\\lambda}, \\tilde{v}$ are any points that satisfy the KKT conditions\nthen $\\tilde{x}$ and $(\\tilde{\\lambda_i}, \\tilde{v_i})$ are primal and dual optimal, with zero duality gap. To see this, note that the first two conditions state that $\\tilde{x}$ is primal feasible. Since $\\tilde{\\lambda_i}$ â‰¥ 0, $L(x,\\tilde{\\lambda},\\tilde{v})$ is convex in $x$; the last KKT condition states that its gradient with respect to $x$ vanishes at $x = \\tilde{x}$, so it follows that $\\tilde{x}$ minimizes $L(x,\\tilde{\\lambda},\\tilde{v})$ over $x$. From this we conclude that\nThis shows that $\\tilde{x}$ and $(\\tilde{\\lambda},\\tilde{v})$ have zero duality gap, and therefore are primal and dual optimal.\nWe conclude the following:\n For any convex optimization problem with differentiable objective and constraint functions, any points that satisfy the KKT conditions are primal and dual optimal, and have zero duality gap. If a convex optimization problem with differentiable objective and constraint functions satisfies Slaterâ€™s condition, then the KKT conditions provide necessary and sufficient conditions for optimality: Slaterâ€™s condition implies that the optimal duality gap is zero and the dual optimum is attained, so $x$ is optimal iff there are $(\\lambda, v)$ that, together with $x$, satisfy the KKT conditions.  Solving the primal problem via the dual Note that if strong duality holds and a dual optimal solution $(\\lambda^\\star, v^\\star)$ exists, then any primal optimal point is also a minimizer of $L(x, \\lambda^\\star, v^\\star)$. This fact sometimes allows us to compute a primal optimal solution from a dual optimal solution.\nMore precisely, suppose we have strong duality and an optimal $(\\lambda^\\star, v^\\star)$ is known. Suppose that the minimizer of $L(x, \\lambda^\\star, v^\\star)$, i.e., the solution of\nis unique (For a convex problem this occurs). Then if the solution is primal feasible, it must be primal optimal; if it is not primal feasible, then no primal optimal point can exist, i.e., we can conclude that the primal optimum is not attained.\n Reference:\n Convex Optimization* by Stephen Boyd and Lieven Vandenberghe.  ","wordCount":"1407","inLanguage":"en","datePublished":"2020-03-29T00:00:00Z","dateModified":"2020-03-29T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://tangliyan.com/blog/posts/convex2/"},"publisher":{"@type":"Organization","name":"Liyan Tang","logo":{"@type":"ImageObject","url":"https://tangliyan.com/blog/favicon.ico"}}}</script><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},svg:{fontCache:'global'}}</script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://tangliyan.com/blog/ accesskey=h title="Liyan Tang (Alt + H)">Liyan Tang</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://tangliyan.com/blog/archives title=Archive>
<span>Archive</span>
</a>
</li>
<li>
<a href=https://tangliyan.com/blog/tags/ title=Tags>
<span>Tags</span>
</a>
</li>
<li>
<a href=https://tangliyan.com/blog/search/ title="Search (Alt + /)" accesskey=/>
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://tangliyan.com/blog/>Home</a>&nbsp;Â»&nbsp;<a href=https://tangliyan.com/blog/posts/>Posts</a></div>
<h1 class=post-title>
Introduction to Convex Optimization - Primal problem to Dual problem
</h1>
<div class=post-meta><span title="2020-03-29 00:00:00 +0000 UTC">March 29, 2020</span>&nbsp;Â·&nbsp;7 min
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#the-lagrange-dual-function aria-label="The Lagrange dual function">The Lagrange dual function</a></li>
<li>
<a href=#lower-bound-property aria-label="Lower bound property">Lower bound property</a></li>
<li>
<a href=#derive-an-analytical-expression-for-the-lagrange-dual-function aria-label="Derive an analytical expression for the Lagrange dual function">Derive an analytical expression for the Lagrange dual function</a><ul>
<li>
<a href=#practice-problem-1-least-squares-solution-of-linear-equations aria-label="Practice problem 1: Least-squares solution of linear equations">Practice problem 1: Least-squares solution of linear equations</a></li>
<li>
<a href=#practice-problem-2-standard-form-linear-programming aria-label="Practice problem 2: Standard form Linear Programming">Practice problem 2: Standard form Linear Programming</a></li></ul>
</li>
<li>
<a href=#the-lagrange-dual-problem aria-label="The Lagrange dual problem">The Lagrange dual problem</a></li>
<li>
<a href=#weak-strong-duality aria-label="Weak/ Strong duality">Weak/ Strong duality</a></li>
<li>
<a href=#slaters-condition aria-label="Slaterâ€™s condition">Slaterâ€™s condition</a></li>
<li>
<a href=#complementary-slackness aria-label="Complementary slackness">Complementary slackness</a></li>
<li>
<a href=#kkt-optimality-conditions aria-label="KKT optimality conditions">KKT optimality conditions</a><ul>
<li>
<a href=#kkt-conditions-for-nonconvex-problems aria-label="KKT conditions for nonconvex problems">KKT conditions for nonconvex problems</a></li>
<li>
<a href=#kkt-conditions-for-convex-problems aria-label="KKT conditions for convex problems">KKT conditions for convex problems</a></li></ul>
</li>
<li>
<a href=#solving-the-primal-problem-via-the-dual aria-label="Solving the primal problem via the dual">Solving the primal problem via the dual</a>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><p>Consider an optimization problem in the standard form (we call this a <em>primal problem</em>):</p>
<img src=https://img-blog.csdnimg.cn/20200327232141243.png width=600 div align=center>
<p>We denote the optimal value of this as $p^\star$. We don&rsquo;t assume the problem is convex.</p>
<h2 id=the-lagrange-dual-function>The Lagrange dual function<a hidden class=anchor aria-hidden=true href=#the-lagrange-dual-function>#</a></h2>
<p>We define the <em>Lagrangian $L$</em> associated with the problem as
$$ L(x,\lambda, v) = f_0(x) + \sum^m_{i=1}\lambda_if_i(x) + \sum^p_{i=1}v_ih_i(x)$$
We call vectors $\lambda$ and $v$ the <em>dual variables</em> or <em>Lagrange multiplier vectors</em> associated with the problem (1).</p>
<p>We define the <em>Lagrange dual function</em> (or just <em>dual function</em>) $g$ as the minimum value of the Lagrangian over $x$: for $\lambda \in \mathbf{R}^m, v\in\mathbf{R}^p$,
$$g(\lambda,v) = \mathop{\rm inf}\limits_{x\in \mathcal{D}} L(x, \lambda, v) = \mathop{\rm inf}\limits_{x\in \mathcal{D}} \left( f_0(x) + \sum^m_{i=1}\lambda_if_i(x) + \sum^p_{i=1}v_ih_i(x)\right)$$</p>
<p>Note that once we choose an $x$, $f_i(x)$ and $h_i(x)$ are fixed and therefore the dual function is a family of affine functions of ($\lambda$, $v$), <strong>which is concave even the problem (1) is not convex</strong>.</p>
<h2 id=lower-bound-property>Lower bound property<a hidden class=anchor aria-hidden=true href=#lower-bound-property>#</a></h2>
<p>The dual function yields lower bounds on the optimal value $p^\star$ of the problem (1): For any $\lambda \succeq 0$ and any $v$ we have
$$ g(\lambda,v) \leq p^\star$$</p>
<p>Suppose $\tilde{x}$ is a feasible point for the problem (1), <em>i.e.</em>, $f_i(\tilde{x}) \leq 0$ and $h_i(\tilde{x}) = 0$, and $\lambda \succeq 0$. Then we have</p>
<p>$$ L(\tilde{x}, \lambda, v) = f_0(\tilde{x}) + \sum^m_{i=1}\lambda_if_i(\tilde{x}) + \sum^p_{i=1}v_ih_i(\tilde{x}) \leq f_0(\tilde{x})$$</p>
<p>Hence
$$ g(\lambda,v) = \mathop{\rm inf}\limits_{x\in \mathcal{D}} L(x, \lambda, v) \leq L(\tilde{x}, \lambda, v) \leq f_0(\tilde{x})$$</p>
<p>Since $g(\lambda,v) \leq f_0(\tilde{x})$ holds for every feasible point $\tilde{x}$, the inequality $g(\lambda,v) \leq p$ follows. The inequality holds, but is vacuous, when $g(\lambda,v) = -\infty$. The dual function gives a nontrivial lower bound on $p^\star$ only when $\lambda \succeq 0$ and $(\lambda,v) \in \textbf{dom},g$, <em>i.e.</em>, $g(\lambda,v) > -
\infty$. We refer to a pair $(\lambda,v)$ with $\lambda \succeq 0$ and $(\lambda,v) \in \textbf{dom},g$ as dual feasible.</p>
<h2 id=derive-an-analytical-expression-for-the-lagrange-dual-function>Derive an analytical expression for the Lagrange dual function<a hidden class=anchor aria-hidden=true href=#derive-an-analytical-expression-for-the-lagrange-dual-function>#</a></h2>
<h3 id=practice-problem-1-least-squares-solution-of-linear-equations>Practice problem 1: Least-squares solution of linear equations<a hidden class=anchor aria-hidden=true href=#practice-problem-1-least-squares-solution-of-linear-equations>#</a></h3>
<img src=https://img-blog.csdnimg.cn/20200327232930972.png width=250>
<p>The Lagrangian is $L(x,v) = x^\top x + v^\top(Ax-b)$. The dual function is given by $g(v) = \text{inf}_x L(x,v)$. Since $L(x,v)$ is a convex quadratic function of $x$, we can find the minimizing $x$ from the optimality condition</p>
<p>$$ \nabla_x L(x,v) = 2x + A^\top v = 0$$</p>
<p>which yields $x = -(1/2)A^\top v$. Therefore the dual function is</p>
<p>$$ g(v) = L(-(1/2)A^\top v, v) = -(1/4)v^\top AA^\top v - b^\top v$$</p>
<p>Therefore, $p^\star \geq -(1/4)v^\top AA^\top v - b^\top v$. The next step is to maximize $-(1/4)v^\top AA^\top v - b^\top v$.</p>
<h3 id=practice-problem-2-standard-form-linear-programming>Practice problem 2: Standard form Linear Programming<a hidden class=anchor aria-hidden=true href=#practice-problem-2-standard-form-linear-programming>#</a></h3>
<img src=https://img-blog.csdnimg.cn/20200327232956789.png width=250>
<p>The Lagrangian is
$$ L(x, \lambda, v) = c^\top x - \sum^n_{i=1}\lambda_ix_i + v^\top(Ax-b) = -b^\top v + (c + A^\top v - \lambda)^\top x$$</p>
<p>The dual function is
$$ g(\lambda, v) = \mathop{\rm inf}\limits_{x} L(x, \lambda, v) = -b^\top v + \mathop{\rm inf}\limits_{x}, (c + A^\top v - \lambda)^\top x$$</p>
<p>We see that $g(\lambda,v)$ is a linear function. Since a linear function is bounded below only when it is zero. Thus, $g(\lambda,v) = -\infty$ except when $c + A^\top v - \lambda = 0$. Therefore,</p>
<img src=https://img-blog.csdnimg.cn/20200327233108435.png width=500>
<p>The lower bound property is nontrivial only when $\lambda$ and $v$ satisfy $\lambda \succeq 0$ and $c + A^\top v - \lambda$. When this occurs, $-b^\top v$ is a lower bound on the optimal value of the LP. We can form an equivalent <em>dual problem</em> by making these equality constraints explicit:</p>
<img src=https://img-blog.csdnimg.cn/20200327233217770.png width=400>
<p>This problem, in turn, can be expressed as</p>
<img src=https://img-blog.csdnimg.cn/20200327233234789.png width=400>
<h2 id=the-lagrange-dual-problem>The Lagrange dual problem<a hidden class=anchor aria-hidden=true href=#the-lagrange-dual-problem>#</a></h2>
<p>For each pair $(\lambda,v)$ with $\lambda \succeq 0$, the Lagrange dual function gives us a lower bound on the optimal value $p^\star$ of the optimization problem (1). Thus we have a lower bound that depends on some parameters $\lambda, v$.</p>
<p>This leads to the optimization problem</p>
<img src=https://img-blog.csdnimg.cn/20200327233250585.png width=450>
<p>This problem is called the <em>Lagrange dual problem</em> associated with the problem (1). In this context the original problem (1) is sometimes called the <em>primal problem</em>. We refer to $(\lambda^\star, v^\star)$ as <em>dual optimal</em> or <em>optimal Lagrange multipliers</em> if they are optimal for the problem (2). The Lagrange dual problem (2) is a convex optimization problem, since the objective to be maximized is concave and the constraint is convex. <em>This is the case whether or not the primal problem (5.1) is convex</em>.</p>
<p><strong>Note: the dual problem is always convex.</strong></p>
<h2 id=weak-strong-duality>Weak/ Strong duality<a hidden class=anchor aria-hidden=true href=#weak-strong-duality>#</a></h2>
<p>The optimal value of the Lagrange dual problem, which we denote $d^\star$, is, by definition, the best lower bound on $p^\star$ that can be obtained from the Lagrange dual function. The inequality</p>
<p>$$ d^\star \leq p^\star$$</p>
<p>which holds <em>even if the original problem is not convex</em>. This property is called <em>weak duality</em>.</p>
<p>We refer to the difference $p^\star - d^\star$ as the optimal duality gap of the original problem. Note that th optimal duality gap is always nonnegative.</p>
<p>We say that strong duality holds if</p>
<p>$$ d^\star = p^\star$$</p>
<p>Note that strong duality does not hold in general. But if the primal problem (11) is convex with $f_1, &mldr;, f_k$ convex, we usually (but not always) have strong duality.</p>
<h2 id=slaters-condition>Slaterâ€™s condition<a hidden class=anchor aria-hidden=true href=#slaters-condition>#</a></h2>
<p><strong>Slaterâ€™s condition:</strong> There exists an $x \in \mathbf{relint}, D$ such that $$f_i(x) &lt; 0, \quad i = 1,&mldr;,m, \quad Ax = b $$</p>
<p>Such a point is called <em>strictly feasible</em>.</p>
<p><strong>Slater&rsquo;s theorem</strong>: If Slater&rsquo;s condition holds for a convex problem, then the strong duality holds.</p>
<h2 id=complementary-slackness>Complementary slackness<a hidden class=anchor aria-hidden=true href=#complementary-slackness>#</a></h2>
<p>Suppose the strong duality holds. Let $x^\star$ be a primal optimal and $(\lambda^\star, v^\star)$ be a dual optimal point. This means that</p>
<img src=https://img-blog.csdnimg.cn/20200327233431277.png width=500>
<p>We conclude that the two inequalities in this chain hold with equality. Since the inequality in the third line is an equality, we conclude that $x^\star$ minimizes $L(x, \lambda^\star, v^\star)$ over $x$.</p>
<p>Another important conclusion is</p>
<p>$$ \lambda_i^\star f_i(x^\star) = 0, \quad i = 1,&mldr;,m$$</p>
<h2 id=kkt-optimality-conditions>KKT optimality conditions<a hidden class=anchor aria-hidden=true href=#kkt-optimality-conditions>#</a></h2>
<p>We now assume that the functions $f_0, &mldr;, f_m, h_1, &mldr;,h_p$ are differentiable, but we make no assumptions yet about convexity.</p>
<h3 id=kkt-conditions-for-nonconvex-problems>KKT conditions for nonconvex problems<a hidden class=anchor aria-hidden=true href=#kkt-conditions-for-nonconvex-problems>#</a></h3>
<p>Suppose the strong duality holds. Let $x^\star$ be a primal optimal and $(\lambda^\star, v^\star)$ be a dual optimal point. Since $x^\star$ minimizes $L(x, \lambda^\star, v^\star)$ over $x$, it follows that its gradient must vanish at $x^\star$, <em>i.e.</em>,</p>
<p>$$ \nabla f_0(x^\star) + \sum^m_{i=1}\lambda_i^\star \nabla f_i(x^\star) + \sum^p_{i=1}v_i^\star \nabla h_i(x^\star) = 0$$</p>
<p>The KKT conditions are the following:
<img src=https://img-blog.csdnimg.cn/20200327233506361.png width=800></p>
<p><strong>For any optimization problem with differentiable objective and constraint functions for which strong duality obtains, any pair of primal and dual optimal points must satisfy the KKT conditions.</strong></p>
<h3 id=kkt-conditions-for-convex-problems>KKT conditions for convex problems<a hidden class=anchor aria-hidden=true href=#kkt-conditions-for-convex-problems>#</a></h3>
<p>When the primal problem is convex, the KKT conditions are also sufficient for the points to be primal and dual optimal. That is, if $f_i$ are convex and $h_i$ are affine, and $\tilde{x}, \tilde{\lambda}, \tilde{v}$ are any points that satisfy the KKT conditions</p>
<img src=https://img-blog.csdnimg.cn/20200327233624376.png width=800>
<p>then $\tilde{x}$ and $(\tilde{\lambda_i}, \tilde{v_i})$ are primal and dual optimal, with zero duality gap. To see this, note that the first two conditions state that $\tilde{x}$ is primal feasible. Since $\tilde{\lambda_i}$ â‰¥ 0, $L(x,\tilde{\lambda},\tilde{v})$ is convex in $x$; the last KKT condition states that its gradient with respect to $x$ vanishes at $x = \tilde{x}$, so it follows that $\tilde{x}$ minimizes $L(x,\tilde{\lambda},\tilde{v})$ over $x$. From this we conclude that</p>
<img src=https://img-blog.csdnimg.cn/20200327233718963.png width=500>
<p>This shows that $\tilde{x}$ and $(\tilde{\lambda},\tilde{v})$ have zero duality gap, and therefore are primal and dual optimal.</p>
<p>We conclude the following:</p>
<ul>
<li><strong>For any convex optimization problem with differentiable objective and constraint functions, any points that satisfy the KKT conditions are primal and dual optimal, and have zero duality gap.</strong></li>
<li><strong>If a convex optimization problem with differentiable objective and constraint functions satisfies Slaterâ€™s condition, then the KKT conditions provide necessary and sufficient conditions for optimality: Slaterâ€™s condition implies that the optimal duality gap is zero and the dual optimum is attained, so $x$ is optimal iff there are $(\lambda, v)$ that, together with $x$, satisfy the KKT conditions.</strong></li>
</ul>
<h2 id=solving-the-primal-problem-via-the-dual>Solving the primal problem via the dual<a hidden class=anchor aria-hidden=true href=#solving-the-primal-problem-via-the-dual>#</a></h2>
<p>Note that if strong duality holds and a dual optimal solution $(\lambda^\star, v^\star)$ exists, then any primal optimal point is also a minimizer of $L(x, \lambda^\star, v^\star)$. This fact sometimes allows us to compute a primal optimal solution from a dual optimal solution.</p>
<p>More precisely, suppose we have strong duality and an optimal $(\lambda^\star, v^\star)$ is known. Suppose that the minimizer of $L(x, \lambda^\star, v^\star)$, <em>i.e.</em>, the solution of</p>
<img src=https://img-blog.csdnimg.cn/20200327233802690.png width=500>
<p>is unique (For a convex problem this occurs). Then if the solution is primal feasible, it must be primal optimal; if it is not primal feasible, then no primal optimal point can exist, <em>i.e.</em>, we can conclude that the primal optimum is not attained.</p>
<hr>
<p>Reference:</p>
<ul>
<li>Convex Optimization* by Stephen Boyd and Lieven Vandenberghe.</li>
</ul>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://tangliyan.com/blog/tags/ml/>ML</a></li>
<li><a href=https://tangliyan.com/blog/tags/math/>MATH</a></li>
<li><a href=https://tangliyan.com/blog/tags/optimization/>OPTIMIZATION</a></li>
</ul>
<nav class=paginav>
<a class=prev href=https://tangliyan.com/blog/posts/svm/>
<span class=title>Â« Prev Page</span>
<br>
<span>SVM, Dual SVM, Non-linear SVM</span>
</a>
<a class=next href=https://tangliyan.com/blog/posts/convex1/>
<span class=title>Next Page Â»</span>
<br>
<span>Introduction to Convex Optimization - Basic Concepts</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Introduction to Convex Optimization - Primal problem to Dual problem on twitter" href="https://twitter.com/intent/tweet/?text=Introduction%20to%20Convex%20Optimization%20-%20Primal%20problem%20to%20Dual%20problem&url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconvex2%2f&hashtags=ML%2cMATH%2cOPTIMIZATION"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Introduction to Convex Optimization - Primal problem to Dual problem on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconvex2%2f&title=Introduction%20to%20Convex%20Optimization%20-%20Primal%20problem%20to%20Dual%20problem&summary=Introduction%20to%20Convex%20Optimization%20-%20Primal%20problem%20to%20Dual%20problem&source=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconvex2%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Introduction to Convex Optimization - Primal problem to Dual problem on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconvex2%2f&title=Introduction%20to%20Convex%20Optimization%20-%20Primal%20problem%20to%20Dual%20problem"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Introduction to Convex Optimization - Primal problem to Dual problem on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconvex2%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Introduction to Convex Optimization - Primal problem to Dual problem on whatsapp" href="https://api.whatsapp.com/send?text=Introduction%20to%20Convex%20Optimization%20-%20Primal%20problem%20to%20Dual%20problem%20-%20https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconvex2%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Introduction to Convex Optimization - Primal problem to Dual problem on telegram" href="https://telegram.me/share/url?text=Introduction%20to%20Convex%20Optimization%20-%20Primal%20problem%20to%20Dual%20problem&url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fconvex2%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href=https://tangliyan.com/blog/>Liyan Tang</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
<script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script>
</body>
</html>