<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Hidden Markov Model (HMM) | Liyan Tang</title>
<meta name=keywords content="NLP,MATH">
<meta name=description content="Before reading this post, make sure you are familiar with the EM Algorithm and decent among of knowledge of convex optimization. If not, please check out my previous post
  EM Algorithm
  convex optimization primal and dual problem
  Let&rsquo;s get started!
Conditional independence $A$ and $B$ are conditionally independent given $C$ if and only if, given knowledge that $C$ occurs, knowledge of whether $A$ occurs provides no information on the likelihood of $B$ occurring, and knowledge of whether $B$ occurs provides no information on the likelihood of $A$ occurring.">
<meta name=author content>
<link rel=canonical href=https://tangliyan.com/blog/posts/hmm/>
<link crossorigin=anonymous href=/blog/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/blog/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://tangliyan.com/blog/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://tangliyan.com/blog/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://tangliyan.com/blog/favicon-32x32.png>
<link rel=apple-touch-icon href=https://tangliyan.com/blog/apple-touch-icon.png>
<link rel=mask-icon href=https://tangliyan.com/blog/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.92.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-202974782-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="Hidden Markov Model (HMM)">
<meta property="og:description" content="Before reading this post, make sure you are familiar with the EM Algorithm and decent among of knowledge of convex optimization. If not, please check out my previous post
  EM Algorithm
  convex optimization primal and dual problem
  Let&rsquo;s get started!
Conditional independence $A$ and $B$ are conditionally independent given $C$ if and only if, given knowledge that $C$ occurs, knowledge of whether $A$ occurs provides no information on the likelihood of $B$ occurring, and knowledge of whether $B$ occurs provides no information on the likelihood of $A$ occurring.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://tangliyan.com/blog/posts/hmm/"><meta property="og:image" content="https://tangliyan.com/blog/papermod-cover.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2020-05-03T00:00:00+00:00">
<meta property="article:modified_time" content="2020-05-03T00:00:00+00:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://tangliyan.com/blog/papermod-cover.png">
<meta name=twitter:title content="Hidden Markov Model (HMM)">
<meta name=twitter:description content="Before reading this post, make sure you are familiar with the EM Algorithm and decent among of knowledge of convex optimization. If not, please check out my previous post
  EM Algorithm
  convex optimization primal and dual problem
  Let&rsquo;s get started!
Conditional independence $A$ and $B$ are conditionally independent given $C$ if and only if, given knowledge that $C$ occurs, knowledge of whether $A$ occurs provides no information on the likelihood of $B$ occurring, and knowledge of whether $B$ occurs provides no information on the likelihood of $A$ occurring.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tangliyan.com/blog/posts/"},{"@type":"ListItem","position":2,"name":"Hidden Markov Model (HMM)","item":"https://tangliyan.com/blog/posts/hmm/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Hidden Markov Model (HMM)","name":"Hidden Markov Model (HMM)","description":"Before reading this post, make sure you are familiar with the EM Algorithm and decent among of knowledge of convex optimization. If not, please check out my previous post\n  EM Algorithm\n  convex optimization primal and dual problem\n  Let\u0026rsquo;s get started!\nConditional independence $A$ and $B$ are conditionally independent given $C$ if and only if, given knowledge that $C$ occurs, knowledge of whether $A$ occurs provides no information on the likelihood of $B$ occurring, and knowledge of whether $B$ occurs provides no information on the likelihood of $A$ occurring.","keywords":["NLP","MATH"],"articleBody":"Before reading this post, make sure you are familiar with the EM Algorithm and decent among of knowledge of convex optimization. If not, please check out my previous post\n  EM Algorithm\n  convex optimization primal and dual problem\n  Let’s get started!\nConditional independence $A$ and $B$ are conditionally independent given $C$ if and only if, given knowledge that $C$ occurs, knowledge of whether $A$ occurs provides no information on the likelihood of $B$ occurring, and knowledge of whether $B$ occurs provides no information on the likelihood of $A$ occurring.\nFormally, if we denote conditional independence of $A$ and $B$ given $C$ by $(A\\perp B)\\mid C$, then by definition, we have\n$$(A\\perp B)\\mid C\\quad \\iff \\quad P(A, B\\mid C)= P(A\\mid C) \\cdot P(B\\mid C)$$\nGiven the knowledge that $C$ occurs, to show the knowledge of whether $B$ occurs provides no information on the likelihood of $A$ occurring, we have\n$$ \\begin{aligned} P(A | B ,C) \u0026=\\frac{P(A , B , C)}{P(B , C)} \\\\ \u0026=\\frac{P(A , B | C) \\cdot P(C)}{P(B , C)} \\\\ \u0026=\\frac{P(A | C) \\cdot P(B | C) \\cdot P(C)}{P(B | C) \\cdot P(C)} \\\\ \u0026=P(A | C) \\end{aligned} $$\nTwo classical cases where $X$ and $Z$ are conditionally independent Case 1 :\nFrom the above directed graph, we have $P(X,Y,Z) = P(X)\\cdot P(Y|X)\\cdot P(Z|Y)$. Hence we have\n$$ \\begin{aligned} P(Z|X,Y) \u0026= \\frac{P(X,Y,Z)}{P(X,Y)}\\\\ \u0026= \\frac{P(X)\\cdot P(Y|X)\\cdot P(Z|Y)}{P(X)\\cdot P(Y|X)}\\\\ \u0026= P(Z|Y) \\end{aligned} $$\nTherefore, $X$ and $Z$ are conditionally independent.\nCase 2 :\nFrom the above directed graph, we have $P(X,Y,Z) = P(Y)\\cdot P(X|Y) \\cdot P(Z|Y)$. Hence we have\n$$ \\begin{aligned} P(Z|X,Y) \u0026= \\frac{P(X,Y,Z)}{P(X,Y)}\\\\ \u0026= \\frac{P(Y)\\cdot P(X|Y) \\cdot P(Z|Y)}{P(Y)\\cdot P(X|Y)}\\\\ \u0026= P(Z|Y) \\end{aligned} $$\nTherefore, $X$ and $Z$ are conditionally independent.\nSettings of the Hidden Markov Model (HMM) The HMM is based on augmenting the Markov chain. A Markov chain is a model that tells us something about the probabilities of sequences of random variables, states, each of which can take on values from some set. A Markov chain makes a very strong assumption that if we want to predict the future in the sequence, all that matters is the current state.\nTo put it formally, suppose we have a sequence of state variables $z_1, z_2, …, z_n$. Then the Markov assumption is\n$$ p(z_n | z_1z_2…z_{n-1}) = p(z_n | z_{n-1}) $$\nA Markov chain is useful when we need to compute a probability for a sequence of observable events. However, in many cases the events we are interested in are hidden. For example we don’t normally observe part-of-speech (POS) tags in a text. Rather, we see words, and must infer the tags from the word sequence. We call the tags hidden because they are not observed.\nA hidden Markov model (HMM) allows us to talk about both observed events (like words that we see in the input) and hidden events (like part-of-speech tags) that we think of as causal factors in our probabilistic model. An HMM is specified by the following components:\n  A sequence of hidden states $z$, where $z_k$ takes values from all possible hidden states $Z = {1,2,..,m}$.\n  A sequence of observations $x$, where $x = (x_1, x_2, …, x_n)$. Each one is drawn from a vocabulary $V$.\n  A transition probability matrix $A$, where $A$ is an $m \\times m$ matrix. $A_{ij}$ represents the probability of moving from state $i$ to state $j$: $A_{ij} = p(z_{t+1}=j| z_t=i)$, and $\\sum_{j=1}^{m} A_{ij} = 1$ for all $i$.\n  An emission probability matrix $B$, where $B$ is an $m \\times |V|$ matrix. $B_{ij}$ represents the probability of an observation $x_j$ being generated from a state $i$: $B_{ij} = P(x_t = V_j|z_t = i)$\n  An initial probability distribution $\\pi$ over states, where $\\pi = (\\pi_1, \\pi_2, …, \\pi_m)$. $\\pi_i$ is the probability that the Markov chain will start in state $i$. $\\sum_{i=1}^{m} \\pi_i = 1$.\n  Given a sequence $x$ and the corresponding hidden states $z$ (like one in the picture above), we have\n$$ P(x, z|\\theta) = p(z_1) \\cdot [p(z_2|z_1)\\cdot p(z_3|z_2)\\cdot … \\cdotp(z_n|z_{n-1})] \\cdot [p(x_1|z_1)\\cdot p(x_2|z_2)\\cdot … \\cdot p(x_n|z_n)] \\tag 0$$\nWe get $p(z_1)$ from $\\pi$, $p(z_{k+1}|z_k)$ from $A$, and $p(x_k|z_k)$ from $B$.\nUseful probabilities $p(z_k | x)$ and $p(z_{k+1}, z_k | x)$ $p(z_k | x)$ and $p(z_{k+1}, z_k | x)$ are useful probabilities and we are going to use them later.\nIntuition: Once we have a sequence $x$, we might be interested in find the probability of any hidden state $z_k$, i.e., find probabilities $p(z_k =1| x), p(z_k =2| x), …, p(z_k =m| x)$. we have the following\n$$ \\begin{aligned} p(z_k | x) \u0026= \\frac{p(z_k, x)}{p(x)} \u0026 \u0026 (1)\\\\ \u0026\\propto p(z_k, x) \u0026 \u0026 (2)\\ \\end{aligned} $$\nNote that from $(1)$ to (2), since $p(x)$ doesn’t change for all values of $z_k$, $p(z_k | x)$ is proportional to $p(z_k, x)$.\n$$ \\begin{aligned} p(z_k=i, x) \u0026= p(z_k=i, x_{1:k}, x_{k+1:n}) \\\\ \u0026= p(z_k=i, x_{1:k}) \\cdot p(x_{k+1:n}|z_k=i, x_{1:k}) \u0026 \u0026 (3)\\\\ \u0026= p(z_k=i, x_{1:k}) \\cdot p(x_{k+1:n}|z_k=i) \u0026 \u0026 (4.1) \\\\ \u0026= \\alpha_k(z_k=i) \\cdot \\beta_k(z_k=i) \u0026\u0026(4.11)\\ \\end{aligned} $$\nFrom the above graph, we see that the second term $(3)$ is the 2nd classical cases. So $x_{k+1:n}$ and $x_{1:k}$ are conditionally independent. This is why we can go from $(3)$ to $(4.1)$. We are going to use the Forward Algorithm to compute $p(z_k, x_{1:k})$, and Backward Algorithm to compute $p(x_{k+1:n}|z_k)$ later.\nWe denote $p(z_k, x_{1:k})$ by $\\alpha_k(z_k)$ and $p(x_{k+1:n}|z_k)$ by $\\beta_k(z_k)$.\nAfter we know how to calculate these two terms separately, we can calculate $p(z_k | x)$ easily by introducing a normalization term. That is,\n$$ \\begin{aligned} p(z_k = i | x) \u0026= \\frac{p(z_k = i, x)}{\\sum_{j=1}^m p(z_k = j, x)} \\\\ \u0026= \\frac{\\alpha_k(z_k=i)\\beta_k(z_k=i)}{\\sum_{j=1}^{m} \\alpha_k(z_k=j)\\beta_k(z_k=j)} \u0026\u0026 (4.2) \\end{aligned} $$\nwhere $\\sum_j^m p(z_k = j, x)$ is the normalization term which makes $p(z_k = 1, x)$ take values between $0$ and $1$ for all $z_k$.\nSimilarly, we are also interested in finding $p(z_{k+1}, z_k | x)$, where\n$$ p(z_{k+1}, z_k | x) \\propto p(z_{k+1}, z_k, x)$$\nBy using the property of conditional independence, we have\n$$ \\begin{aligned} p(z_{k+1}=j, z_k=i, x) \u0026= p(z_k=i, z_{k+1}=j, x_{1:k}, x_{k+1}, x_{k+2:n}) \\\\ \u0026= p(z_k=i, x_{1:k}) \\cdot p(x_{k+2:n)|z_{k+1}=j}) \\cdot p(z_{k+1}=j|z_{k}=i) \\cdot p(x_{k+1}| z_{k+1}=j) \u0026\u0026 (4.3)\\\\ \u0026= \\alpha_k(z_k=i) \\cdot \\beta_{k+1}(z_{k+1}=j) \\cdot p(z_{k+1}=j|z_{k}=i) \\cdot p(x_{k+1}| z_{k+1}=j) \u0026\u0026 (4.4) \\ \\end{aligned} $$\nNote that we can find the third and the forth term from the transition probability matrix and the emission probability matrix. Again, we can calculate $p(z_{k+1}, z_k | x)$ simply by introducing a normalization term. That is,\n$$ \\begin{aligned} p(z_{k+1}=s, z_k=r | x) \u0026= \\frac{p(z_{k+1}=s, z_k=r, x)}{\\sum_{i=1}^{m} \\sum_{j=1}^{m} p(z_{k+1}=j, z_k=i, x)} \\\\ \u0026= \\frac{\\alpha_k(z_k=r) \\cdot \\beta_{k+1}(z_{k+1}=s) \\cdot p(z_{k+1}=s|z_{k}=r) \\cdot p(x_{k+1}| z_{k+1}=s)}{\\sum_{i=1}^{m} \\alpha_k(z_k=i) \\cdot \\beta_{k+1}(z_{k+1}=j) \\cdot p(z_{k+1}=j|z_{k}=i) \\cdot p(x_{k+1}| z_{k+1}=j)} \u0026\u0026 (4.42) \\end{aligned} $$\nRemark\n  We denote\n$$ \\gamma_k(i) = p(z_k = i | x) = \\frac{p(z_k=i, x)}{p(x)} \\tag{4.43}$$\n  We denote\n$$ \\xi_k(i,j) = p(z_{k+1}=j, z_k=i | x) = \\frac{p(z_{k+1}=j, z_k=i, x)}{p(x)} \\tag{4.44}$$\n  Three fundamental problems of HMM Problem 1 (Likelihood): Given an observation sequence $x$ and parameters $\\theta = (A, B, \\pi)$, determine the likelihood $p(x|\\theta)$.\nProblem 2 (Learning): Given an observation sequence $x$, learn the parameters $\\theta = (A, B, \\pi)$.\nProblem 3 (Inference): Given an observation sequence $x$ and parameters $\\theta = (A, B, \\pi)$, discover the best hidden state sequence $z$.\nProblem 1 (Likelihood) Goal: Given an observation sequence $x$ and parameters $\\theta = (A, B, \\pi)$, determine the likelihood $p(x|\\theta)$.\nNaive Way:\nFrom $(0)$, we have already know how to compute $P(x, z|\\theta)$, so we can compute $p(x|\\theta)$ by summing all possible sequence $z$:\n$$ p(x|\\theta) = \\sum_z P(x, z|\\theta) \\cdot p(z|\\theta)$$\nThis method is not applicable since there are $m^n$ ways of combinations of sequence $z$. So we introduce the following two algorithm: Forward Algorithm and Backward Algorithm.\nForward Algorithm  Goal: Compute $p(z_k, x_{1:k})$, given $\\theta = (A, B, \\pi)$.  From the picture above, it’s natural to compute $p(z_k, x_{1:k})$ by dynamic programming (DP). That is, to calculate it in terms of $p(z_{k-1}, x_{1:k-1})$:\n$$ \\begin{aligned} p(z_k , x_{1:k}) \u0026= \\sum_{z_{k-1}} p(z_k, z_{k-1}, x_{1:k-1}, x_k) \u0026 \u0026 (5)\\\\ \u0026= \\sum_{z_{k-1}} p(z_{k-1}, x_{1:k-1}) \\cdot p(z_k, x_k|z_{k-1}, x_{1:k-1}) \u0026 \u0026 (6)\\\\ \u0026= \\sum_{z_{k-1}} p(z_{k-1}, x_{1:k-1}) \\cdot p(z_k|z_{k-1}, x_{1:k-1}) \\cdot p(x_k|z_k, z_{k-1}, x_{1:k-1}) \u0026 \u0026 (7)\\\\ \u0026= \\sum_{z_{k-1}} p(z_{k-1}, x_{1:k-1}) \\cdot p(z_k|z_{k-1}) \\cdot p(x_k|z_k) \u0026 \u0026 (8)\\ \\end{aligned} $$\nRamark:\n  From $(6)$ to $(7)$, we use the fact that $p(b,c|a) = p(b|a) \\cdot p(c|a,b)$.\n  From $(7)$ to $(8)$, we use the conditional independence, which is visualized in the picture above.\n  We denote $p(z_k , x_{1:k})$ by $\\alpha_k(z_k)$, so\n$$ \\alpha_k(z_k) = p(z_k , x_{1:k}) = \\sum_{z_{k-1}} \\alpha_{k-1}(z_{k-1}) \\cdot p(z_k|z_{k-1}) \\cdot p(x_k|z_k) \\tag 9$$\n  In equation $(9)$, the term $p(z_k|z_{k-1})$ is the transition probability from state $z_{k-1}$ to state $z_{k}$; the term $p(x_k|z_k)$ is the emission probability of observing $x_k$ given state $z_k$.\n  $\\alpha_1(z_1=q) = p(z_1=q, x_1) = \\pi_q \\cdot p(x_1 | z_1 = q)$, where $p(x_1 | z_1 = q)$ is an emmission probability.\n  Knowing how to compute $p(z_k , x_{1:k})$ recurssively, we have\n$$p(x|\\theta) = p(x_{1:n}|\\theta) = \\sum_{z_n} p(z_n, x_{1:n}) = \\sum_{z_n} \\alpha_n(z_n) = \\sum_{q=1}^{m} \\alpha_n(z_n=q)$$\nBackward Algorithm  Goal: Compute $p(x_{k+1:n} | z_k)$, given $\\theta = (A, B, \\pi)$.  Again, we are going to use DP to compute $p(x_{k+1:n} | z_k)$ in terms of $p(x_{k+2:n} | z_{k+1})$:\n$$ \\begin{aligned} p(x_{k+1:n} | z_k) \u0026= \\sum_{z_{k+1}} p(x_{k+1}, x_{k+2:n}, z_{k+1} | z_k) \\\\ \u0026= \\sum_{z_{k+1}} p(x_{k+2:n}, z_{k+1}| z_k) \\cdot p(x_{k+1}| z_k, x_{k+2:n}, z_{k+1}) \\\\ \u0026= \\sum_{z_{k+1}} p(z_{k+1}|z_k) \\cdot p(x_{k+2:n}|z_{k+1}, z_k) \\cdot p(x_{k+1} | z_k, x_{k+2:n}, z_{k+1}) \u0026\u0026 (10)\\\\ \u0026= \\sum_{z_{k+1}} p(x_{k+2:n}|z_{k+1}) \\cdot p(z_{k+1}|z_k) \\cdot p(x_{k+1}|z_{k+1}) \u0026\u0026 (11)\\ \\end{aligned} $$\nRamark:\n  From $(10)$ to $(11)$, we use the conditional independece similar to the one in forward algorithm.\n  We denote $p(x_{k+1:n} | z_k)$ by $\\beta_k(z_k)$, so\n$$ \\beta_k(z_k) = p(x_{k+1:n} | z_k) = \\sum_{z_{k+1}} p(x_{k+2:n}|z_{k+1}) \\cdot p(z_{k+1}|z_k) \\cdot p(x_{k+1}|z_{k+1}) \\tag {12}$$\n  In equation $(12)$, the term $p(z_{k+1}|z_k)$ is the transition probability from state $z_{k}$ to state $z_{k+1}$; the term $p(x_{k+1}|z_{k+1})$ is the emission probability of observing $x_{k+1}$ given state $z_{k+1}$.\n  $\\beta_n(z_n) = 1$.\n  Knowing how to compute $p(x_{k+1:n} | z_k)$ recursively, we have\n$$ \\begin{aligned} p(x|\\theta) \u0026= \\sum_{z_1} p(x, z_1) = \\sum_{z_1} p(x | z_1) \\cdot p(z_1) \\\\ \u0026= \\sum_{z_1} p(x_1, x_{1+1:n} | z_1) \\cdot p(z_1) \\\\ \u0026= \\sum_{z_1} p(x_1 | z_1) \\cdot p(x_{1+1:n}|z_1, x_1) \\cdot p(z_1) \u0026\u0026(13)\\\\ \u0026= \\sum_{z_1} p(x_1 | z_1) \\cdot p(x_{1+1:n}|z_1) \\cdot p(z_1) \u0026\u0026(14)\\\\ \u0026= \\sum_{z_1} p(x_1 | z_1) \\cdot \\beta_1(z_1) \\cdot p(z_1) \\\\ \u0026= \\sum_{q=1}^m \\beta_1(z_1=q) \\cdot p(x_1 | z_1=q) \\cdot \\pi_q \\end{aligned} $$\nFrom $(13)$ to $(14)$, we use the conditional independence. To make it clean, I didn’t include $\\theta$ in the above derivation, but keep in mind $x$ is conditioned on $\\theta$.\nProblem 2 (Learning) Goal: Given an observation sequence $x$, learn the parameters $\\theta = (A, B, \\pi)$.\nGiven that the hidden states are unknown, it’s natural to use the EM Algorithm to solve parameters. Remind that the EM Algorithm consists of two steps:\n An expectation (E) step, which creates a function $Q(\\theta, \\theta_i)$ for the expectation of the log-likelihood $\\log p(x,z|\\theta)$ evaluated using the current conditional distribution of $z$ given $x$ and the current estimate of the parameters $\\theta_i$, where  $$ \\begin{aligned} Q(\\theta, \\theta_i) \u0026= E_{z \\sim P(z|x,\\theta_i)}[\\log p(x,z|\\theta)] \\\\ \u0026= \\sum_z P(z|x,\\theta_i) \\cdot \\log p(x,z|\\theta) \\ \\end{aligned} $$\n A maximization (M) step, which computes parameters maximizing the expected log-likelihood $Q(\\theta, \\theta_i)$ found on the $E$ step and then update parameters to $\\theta_{i+1}$.  We fist initialize parameters $\\theta_0 = (A_0, B_0, \\pi_0)$\nE Step:\nWe are going to construct $Q(\\theta, \\theta_i)$.\n$$ \\begin{aligned} Q(\\theta, \\theta_i) \u0026= E_{z \\sim P(z|x,\\theta_i)}[\\log p(x,z|\\theta)] \\\\ \u0026= \\sum_z P(z|x,\\theta_i) \\cdot \\log p(x,z|\\theta) \\\\ \u0026= \\log p(x,z|\\theta) \\cdot \\frac{p(x,z|\\theta_i)}{p(x|\\theta_i)} \u0026\u0026(15)\\\\ \u0026\\propto \\log p(x,z|\\theta) \\cdot p(x,z|\\theta_i) \u0026\u0026(16)\\ \\end{aligned} $$\nSince we know $x$ and $\\theta_i$, $p(x|\\theta_i)$ is a constant and therefore we can write from $(15)$ to $(16)$. In the earlier section “Settings of the Hidden Markov Model” of the post, we deduce that\n$$P(x, z|\\theta) = p(z_1) \\cdot [p(z_2|z_1)\\cdot p(z_3|z_2)\\cdot … \\cdotp(z_n|z_{n-1})] \\cdot [p(x_1|z_1)\\cdot p(x_2|z_2)\\cdot … \\cdot p(x_n|z_n)]$$\nSo we can formulate $Q(\\theta, \\theta_i)$ as\n$$ \\begin{aligned} Q(\\theta, \\theta_i) \u0026= \\sum_z \\left( \\log \\pi_{z_i} + \\sum_{t=1}^{n-1} \\log p(z_{t+1}|z_t) + \\sum_{t=1}^{n} \\log p(x_n|z_n)\\right) \\cdot p(x,z|\\theta_i) \\\\ \u0026= \\sum_z \\log \\pi_{z_i} \\cdot p(x,z|\\theta_i) + \\sum_z \\sum_{t=1}^{n-1} \\log p(z_{t+1}|z_t) \\cdot p(x,z|\\theta_i) + \\sum_z \\sum_{t=1}^{n} \\log p(x_t|z_t) \\cdot p(x,z|\\theta_i) \\ \\end{aligned} $$\nM Step:\nWe are going to maximize $Q(\\theta, \\theta_i)$ and update $\\theta_{i+1}$.\nNote that we write $Q(\\theta, \\theta_i)$ as the sum of three terms. The first therm is related to $\\pi$, the second term is related to $A$, and the third term is related to $B$. Therefore we can maximize each term separately.\nWe can write the first term as\n$$\\sum_z \\log \\pi_{z_i} \\cdot p(x,z|\\theta_i) = \\sum_{j=1}^m \\log \\pi_j \\cdot p(x, z_1 = j|\\theta_i)$$\nunder the constraint $\\sum_{j=1}^m \\pi_j = 1$. Clearly, this is a convex optimization problem:\nThe Lagrangian $L$ associated with the problem is\n$$ L(\\pi, v) = \\sum_{j=1}^m \\log \\pi_j \\cdot p(x, z_1 = j|\\theta_i) + v \\cdot (\\sum_{j=1}^m \\pi_j - 1)$$\nNote that any pair of primal and dual optimal points must satisfy the KKT conditions. So we use one KKT property that the gradient must vanish at the optimal point to find $\\pi$. This might not be the optimal $\\pi$ since “any pair of primal and dual optimal points must satisfy the KKT conditions” doesn’t imply that a point satisfying the KKT conditions is the optimal.\n$$ \\begin{aligned} \\frac{\\partial L}{\\partial \\pi_j} = p(x, z_1=j|\\theta_i) \\cdot \\frac{1}{\\pi_j} + v \u0026 = 0 \\\\ p(x, z_1=j|\\theta_i) + v \\cdot \\pi_j \u0026 = 0 \\\\ \\pi_j \u0026 = \\frac{-p(x, z_1=j|\\theta_i)}{v} \u0026 \u0026 (17)\\ \\end{aligned} $$\nBy setting $\\frac{\\partial L}{\\partial \\pi_j} = 0$ for all $j$, we have\n$$ \\begin{aligned} \\sum_{j=1}^m p(x, z_1=j|\\theta_i) + v \\cdot \\sum_{j=1}^m \\pi_j \u0026= 0 \\\\ p(x|\\theta_i) + v \u0026= 0\\\\ v \u0026= - p(x|\\theta_i) \u0026\u0026 (18)\\ \\end{aligned} $$\nBy plugging $(18)$ into $(17)$, we have\n$$ \\pi_j = \\frac{-p(x, z_1=j|\\theta_i)}{v} = \\frac{p(x, z_1=j|\\theta_i)}{p(x|\\theta_i)} = \\gamma_1(j)$$.\nIn the similar way, we can write the second term as\n$$ \\sum_z \\sum_{t=1}^{n-1} \\log p(z_{t+1}|z_t) \\cdot p(x,z|\\theta_i) = \\sum_{j=1}^m \\sum_{k=1}^m \\sum_{t=1}^{n-1} \\log p(z_{t+1}=k|z_t=j) \\cdot p(x,z_t=j, z_{t+1}=k|\\theta_i) \\ \\sum_z \\sum_{t=1}^{n} \\log p(x_t|z_t) \\cdot p(x,z|\\theta_i) = \\sum_{j=1}^m \\sum_{t=1}^n \\log p(x_t|z_t=j) \\cdot p(x,z_t=j|\\theta_i) $$\nwith seperate constraints\n$$\\sum_{k=1}^m p(z_{t+1}=k|z_t=j) = 1, \\ \\sum_{j=1}^m p(x_t|z_t=j) = 1 $$\nWe can solve for optimal parameters similar to solving for $\\pi$. After we set the gradient of corresponding Lagrangian to $0$, we have\n$$ \\begin{aligned} A_{jk} \u0026= p(z_{t+1}=k|z_t=j) \\\\ \u0026= \\frac{\\sum_{t=1}^{n-1} p(x, z_t=j, z_{t+1}=k|\\theta_i)}{\\sum_{t=1}^{n-1} p(x, z_t=j|\\theta_i)} \\\\ \u0026= \\frac{\\sum_{t=1}^{n-1} p(x, z_t=j, z_{t+1}=k|\\theta_i)/ p(x|\\theta_i)}{\\sum_{t=1}^{n-1} p(x, z_t=j|\\theta_i)/p(x|\\theta_i)} \\\\ \u0026= \\frac{\\sum_{t=1}^{n-1} \\xi_t(jk)}{\\sum_{t=1}^{n-1} \\gamma_t(j)} \u0026\u0026(19)\\\\ B_{jk} \u0026= p(x_t= V_k|z_t=j) \\\\ \u0026= \\frac{\\sum_{t=1}^{n-1} p(x, z_t=j|\\theta_i)\\cdot I(x_t= V_k)}{\\sum_{t=1}^{n-1} p(x, z_t=j | \\theta_i)} \\\\ \u0026= \\frac{\\sum_{t=1}^{n-1} p(x, z_t=j|\\theta_i)/ p(x|\\theta_i) \\cdot I(x_t= V_k)}{\\sum_{t=1}^{n-1} p(x, z_t=j | \\theta_i)/ p(x|\\theta_i)} \\\\ \u0026= \\frac{\\sum_{t=1}^{n-1} \\gamma_t(j) \\cdot I(x_t=V_k)}{\\sum_{t=1}^{n-1} \\gamma_t(j)} \u0026\u0026(20)\\ \\end{aligned} $$\nRemark: $I(x_t= V_k)$ is an indicator function. If $x_t= V_k$, then $I(x_t= V_k) = 1$, and $0$ otherwise. We get the results $(19)$ and $(20)$ from $(4.43)$ and $(4.44)$.\nWe also call this algorithm Baum-Welch algorithm.\nProblem 3 (Inference) Goal: Given an observation sequence $x$ and parameters $\\theta = (A, B, \\pi)$, discover the best hidden state sequence $z$.\nMethod 1:Brute force.\nThis is not applicable. Every hidden state has $m$ choices and the sequence has length $n$. So there are $m^n$ possible combinations.\nMethod 2: Use Forward/ Backward Algorithm. Given a sequence $x$, we know how to compute $p(z_k | x)$ from the top of the post. Therefore, at each time $k$, we can compute $p(z_k=i| x)$ for all $i \\in {1,2,…,m}$ and choose the one with the highest probability. In the way, at every time, we chose the most possible hidden state. However, there is still a problem. It only finds the most possible hidden state locally and doesn’t take the whole sequence into account. Even if we chose the most possible hidden state at each time $k$. The combination of them might not be the best one and even doesn’t make sense. Foe example, if $A_{ij} = 0$, then if $z_k=i$, $z_{k+1}$ cannot take state $j$. But the Forward/ Backward Algorithm doesn’t take it into account. We can think of it as a greedy approach to approximate the best result.\nMethod 3: Viterbi algorithm:\nThe Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states that results in a sequence of observed events in HMM.\nWe define $\\delta_k(i)$ to be the maximum probability among all paths which are at state $i$ at time $k$. That is,\n$$\\delta_k(i) = \\mathop{\\rm max}\\limits_{i_1:i_{k-1}} p(i_k=i, i_1:i_{k-1}, x_{1:k}|\\theta), \\quad i= 1,2,…,m$$\nWe can construct a recurssion formula $\\delta_k(i)$. That is,\n$$ \\begin{aligned} \\delta_{k+1}(i) \u0026= \\mathop{\\rm max}\\limits_{i_1:i_{k}} p(i_{k+1}=i, i_1:i_{k}, x_{1:k+1}|\\theta) \\\\ \u0026= \\mathop{\\rm max}\\limits_{1\\leq j \\leq m} \\delta_k(j) \\cdot A_{ji} \\cdot p(x_{k+1}|z_{k+1}=i) \u0026\u0026 i= 1,2,…,m; , k=1,2,…,n-1\\ \\end{aligned} $$\nAnd the base case is $\\delta_{1}(i) = \\pi_i \\cdot p(x_1| z_1=i)$.\nTherefore, we compute the optimal probability $P^{*}$\n$$P^{*} = \\mathop{\\rm max}\\limits_{1 \\leq i \\leq m} \\delta_n(i)$$\nby recursion. During the process of finding the highest probability of a path, we keep recording the hidden states associate with the path. So after we find the the highest probability, we also record the path associated with it and therefore the best sequence $z$.\n Reference:\n https://towardsdatascience.com/conditional-independence-the-backbone-of-bayesian-networks-85710f1b35b https://courses.cs.washington.edu/courses/cse473/16au/slides-16au/25-bn.pdf https://en.wikipedia.org/wiki/Conditional_independence https://web.stanford.edu/~jurafsky/slp3/A.pdf https://www.cs.cmu.edu/~epxing/Class/10701-08s/recitation/em-hmm.pdf https://people.eecs.berkeley.edu/~stephentu/writeups/hmm-baum-welch-derivation.pdf  ","wordCount":"2842","inLanguage":"en","datePublished":"2020-05-03T00:00:00Z","dateModified":"2020-05-03T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://tangliyan.com/blog/posts/hmm/"},"publisher":{"@type":"Organization","name":"Liyan Tang","logo":{"@type":"ImageObject","url":"https://tangliyan.com/blog/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://tangliyan.com/blog/ accesskey=h title="Liyan Tang (Alt + H)">Liyan Tang</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://tangliyan.com/blog/archives title=Archive>
<span>Archive</span>
</a>
</li>
<li>
<a href=https://tangliyan.com/blog/tags/ title=Tags>
<span>Tags</span>
</a>
</li>
<li>
<a href=https://tangliyan.com/blog/search/ title="Search (Alt + /)" accesskey=/>
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://tangliyan.com/blog/>Home</a>&nbsp;»&nbsp;<a href=https://tangliyan.com/blog/posts/>Posts</a></div>
<h1 class=post-title>
Hidden Markov Model (HMM)
</h1>
<div class=post-meta><span title="2020-05-03 00:00:00 +0000 UTC">May 3, 2020</span>&nbsp;·&nbsp;14 min
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#conditional-independence aria-label="Conditional independence">Conditional independence</a><ul>
<li>
<a href=#two-classical-cases-where-x-and-z-are-conditionally-independent aria-label="Two classical cases where $X$ and $Z$ are conditionally independent">Two classical cases where $X$ and $Z$ are conditionally independent</a></li></ul>
</li>
<li>
<a href=#settings-of-the-hidden-markov-model-hmm aria-label="Settings of the Hidden Markov Model (HMM)">Settings of the Hidden Markov Model (HMM)</a></li>
<li>
<a href=#useful-probabilities-pz_k--x-and-pz_k1-z_k--x aria-label="Useful probabilities $p(z_k | x)$ and $p(z_{k+1}, z_k | x)$">Useful probabilities $p(z_k | x)$ and $p(z_{k+1}, z_k | x)$</a></li>
<li>
<a href=#three-fundamental-problems-of-hmm aria-label="Three fundamental problems of HMM">Three fundamental problems of HMM</a></li>
<li>
<a href=#problem-1-likelihood aria-label="Problem 1 (Likelihood)">Problem 1 (Likelihood)</a><ul>
<li>
<a href=#forward-algorithm aria-label="Forward Algorithm">Forward Algorithm</a></li>
<li>
<a href=#backward-algorithm aria-label="Backward Algorithm">Backward Algorithm</a></li></ul>
</li>
<li>
<a href=#problem-2-learning aria-label="Problem 2 (Learning)">Problem 2 (Learning)</a></li>
<li>
<a href=#problem-3-inference aria-label="Problem 3 (Inference)">Problem 3 (Inference)</a>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><p>Before reading this post, make sure you are familiar with the <em>EM Algorithm</em> and decent among of knowledge of <em>convex optimization</em>. If not, please check out my previous post</p>
<ul>
<li>
<p><a href=./em.md>EM Algorithm</a></p>
</li>
<li>
<p><a href=./convex2.md>convex optimization primal and dual problem</a></p>
</li>
</ul>
<p>Let&rsquo;s get started!</p>
<h2 id=conditional-independence>Conditional independence<a hidden class=anchor aria-hidden=true href=#conditional-independence>#</a></h2>
<p>$A$ and $B$ are conditionally independent given $C$ if and only if, given knowledge that $C$ occurs, knowledge of whether $A$ occurs provides no information on the likelihood of $B$ occurring, and knowledge of whether $B$ occurs provides no information on the likelihood of $A$ occurring.</p>
<p>Formally, if we denote conditional independence of $A$ and $B$ given $C$ by $(A\perp B)\mid C$, then by definition, we have</p>
<p>$$(A\perp B)\mid C\quad \iff \quad P(A, B\mid C)= P(A\mid C) \cdot P(B\mid C)$$</p>
<p>Given the knowledge that $C$ occurs, to show the knowledge of whether $B$ occurs provides no information on the likelihood of $A$ occurring, we have</p>
<p>$$
\begin{aligned}
P(A | B ,C) &=\frac{P(A , B , C)}{P(B , C)} \\ &=\frac{P(A , B | C) \cdot P(C)}{P(B , C)} \\ &=\frac{P(A | C) \cdot P(B | C) \cdot P(C)}{P(B | C) \cdot P(C)} \\ &=P(A | C)
\end{aligned}
$$</p>
<h3 id=two-classical-cases-where-x-and-z-are-conditionally-independent>Two classical cases where $X$ and $Z$ are conditionally independent<a hidden class=anchor aria-hidden=true href=#two-classical-cases-where-x-and-z-are-conditionally-independent>#</a></h3>
<p><strong>Case 1</strong> :</p>
<img src=https://img-blog.csdnimg.cn/20200503030533838.png width=300>
<p>From the above directed graph, we have $P(X,Y,Z) = P(X)\cdot P(Y|X)\cdot P(Z|Y)$. Hence we have</p>
<p>$$
\begin{aligned}
P(Z|X,Y) &= \frac{P(X,Y,Z)}{P(X,Y)}\\ &= \frac{P(X)\cdot P(Y|X)\cdot P(Z|Y)}{P(X)\cdot P(Y|X)}\\ &= P(Z|Y)
\end{aligned}
$$</p>
<p>Therefore, $X$ and $Z$ are conditionally independent.</p>
<p><strong>Case 2</strong> :</p>
<img src=https://img-blog.csdnimg.cn/20200503030633989.png width=290>
<p>From the above directed graph, we have $P(X,Y,Z) = P(Y)\cdot P(X|Y) \cdot P(Z|Y)$. Hence we have</p>
<p>$$
\begin{aligned}
P(Z|X,Y) &= \frac{P(X,Y,Z)}{P(X,Y)}\\ &= \frac{P(Y)\cdot P(X|Y) \cdot P(Z|Y)}{P(Y)\cdot P(X|Y)}\\ &= P(Z|Y)
\end{aligned}
$$</p>
<p>Therefore, $X$ and $Z$ are conditionally independent.</p>
<h2 id=settings-of-the-hidden-markov-model-hmm>Settings of the Hidden Markov Model (HMM)<a hidden class=anchor aria-hidden=true href=#settings-of-the-hidden-markov-model-hmm>#</a></h2>
<p>The <em>HMM</em> is based on augmenting the <em>Markov chain</em>. A Markov chain is a model that tells us something about the probabilities of sequences of random variables, <em>states</em>, each of which can take on values from some set. A Markov chain makes a very strong assumption that if we want to predict the future in the sequence, all that matters is the current state.</p>
<p>To put it formally, suppose we have a sequence of state variables $z_1, z_2, &mldr;, z_n$. Then the Markov assumption is</p>
<p>$$ p(z_n | z_1z_2&mldr;z_{n-1}) = p(z_n | z_{n-1}) $$</p>
<p>A Markov chain is useful when we need to compute a probability for a sequence of observable events. However, in many cases the events we are interested in are hidden. For example we don’t normally observe part-of-speech (POS) tags in a text. Rather, we see words, and must infer the tags from the word sequence. We call the tags hidden because they are not observed.</p>
<img src=https://img-blog.csdnimg.cn/20200503030900976.png width=450>
<p>A hidden Markov model (HMM) allows us to talk about both observed events (like words that we see in the input) and hidden events (like part-of-speech tags) that we think of as causal factors in our probabilistic model. An HMM is specified by the following components:</p>
<ul>
<li>
<p><strong>A sequence of hidden states $z$</strong>, where $z_k$ takes values from all possible hidden states $Z = {1,2,..,m}$.</p>
</li>
<li>
<p><strong>A sequence of observations $x$</strong>, where $x = (x_1, x_2, &mldr;, x_n)$. Each one is drawn from a vocabulary $V$.</p>
</li>
<li>
<p><strong>A transition probability matrix $A$</strong>, where $A$ is an $m \times m$ matrix. $A_{ij}$ represents the probability of moving from state $i$ to state $j$: $A_{ij} = p(z_{t+1}=j| z_t=i)$, and $\sum_{j=1}^{m} A_{ij} = 1$ for all $i$.</p>
</li>
<li>
<p><strong>An emission probability matrix $B$</strong>, where $B$ is an $m \times |V|$ matrix. $B_{ij}$ represents the probability of an observation $x_j$ being generated from a state $i$: $B_{ij} = P(x_t = V_j|z_t = i)$</p>
</li>
<li>
<p><strong>An initial probability distribution $\pi$ over states</strong>, where $\pi = (\pi_1, \pi_2, &mldr;, \pi_m)$. $\pi_i$ is the probability that the Markov chain will start in state $i$. $\sum_{i=1}^{m} \pi_i = 1$.</p>
</li>
</ul>
<p>Given a sequence $x$ and the corresponding hidden states $z$ (like one in the picture above), we have</p>
<p>$$ P(x, z|\theta) = p(z_1) \cdot [p(z_2|z_1)\cdot p(z_3|z_2)\cdot &mldr; \cdotp(z_n|z_{n-1})] \cdot [p(x_1|z_1)\cdot p(x_2|z_2)\cdot &mldr; \cdot p(x_n|z_n)] \tag 0$$</p>
<p>We get $p(z_1)$ from $\pi$, $p(z_{k+1}|z_k)$ from $A$, and $p(x_k|z_k)$ from $B$.</p>
<h2 id=useful-probabilities-pz_k--x-and-pz_k1-z_k--x>Useful probabilities $p(z_k | x)$ and $p(z_{k+1}, z_k | x)$<a hidden class=anchor aria-hidden=true href=#useful-probabilities-pz_k--x-and-pz_k1-z_k--x>#</a></h2>
<p>$p(z_k | x)$ and $p(z_{k+1}, z_k | x)$ are useful probabilities and we are going to use them later.</p>
<p>Intuition: Once we have a sequence $x$, we might be interested in find the probability of any hidden state $z_k$, <em>i.e.</em>, find probabilities $p(z_k =1| x), p(z_k =2| x), &mldr;, p(z_k =m| x)$. we have the following</p>
<p>$$
\begin{aligned}
p(z_k | x) &= \frac{p(z_k, x)}{p(x)} & & (1)\\ &\propto p(z_k, x) & & (2)\
\end{aligned}
$$</p>
<p>Note that from $(1)$ to (2), since $p(x)$ doesn&rsquo;t change for all values of $z_k$, $p(z_k | x)$ is proportional to $p(z_k, x)$.</p>
<p>$$
\begin{aligned}
p(z_k=i, x) &= p(z_k=i, x_{1:k}, x_{k+1:n}) \\ &= p(z_k=i, x_{1:k}) \cdot p(x_{k+1:n}|z_k=i, x_{1:k}) & & (3)\\ &= p(z_k=i, x_{1:k}) \cdot p(x_{k+1:n}|z_k=i) & & (4.1) \\ &= \alpha_k(z_k=i) \cdot \beta_k(z_k=i) &&(4.11)\
\end{aligned}
$$</p>
<img src=https://img-blog.csdnimg.cn/20200503030958998.png width=550>
<p>From the above graph, we see that the second term $(3)$ is the 2nd classical cases. So $x_{k+1:n}$ and $x_{1:k}$ are conditionally independent. This is why we can go from $(3)$ to $(4.1)$. We are going to use the <em>Forward Algorithm</em> to compute $p(z_k, x_{1:k})$, and <em>Backward Algorithm</em> to compute $p(x_{k+1:n}|z_k)$ later.</p>
<p><strong>We denote $p(z_k, x_{1:k})$ by $\alpha_k(z_k)$ and $p(x_{k+1:n}|z_k)$ by $\beta_k(z_k)$.</strong></p>
<p>After we know how to calculate these two terms separately, we can calculate $p(z_k | x)$ easily by introducing a normalization term. That is,</p>
<p>$$
\begin{aligned}
p(z_k = i | x) &= \frac{p(z_k = i, x)}{\sum_{j=1}^m p(z_k = j, x)} \\ &= \frac{\alpha_k(z_k=i)\beta_k(z_k=i)}{\sum_{j=1}^{m} \alpha_k(z_k=j)\beta_k(z_k=j)} && (4.2)
\end{aligned}
$$</p>
<p>where $\sum_j^m p(z_k = j, x)$ is the normalization term which makes $p(z_k = 1, x)$ take values between $0$ and $1$ for all $z_k$.</p>
<p>Similarly, we are also interested in finding $p(z_{k+1}, z_k | x)$, where</p>
<p>$$ p(z_{k+1}, z_k | x) \propto p(z_{k+1}, z_k, x)$$</p>
<p>By using the property of conditional independence, we have</p>
<p>$$
\begin{aligned}
p(z_{k+1}=j, z_k=i, x) &= p(z_k=i, z_{k+1}=j, x_{1:k}, x_{k+1}, x_{k+2:n}) \\ &= p(z_k=i, x_{1:k}) \cdot p(x_{k+2:n)|z_{k+1}=j}) \cdot p(z_{k+1}=j|z_{k}=i) \cdot p(x_{k+1}| z_{k+1}=j) && (4.3)\\ &= \alpha_k(z_k=i) \cdot \beta_{k+1}(z_{k+1}=j) \cdot p(z_{k+1}=j|z_{k}=i) \cdot p(x_{k+1}| z_{k+1}=j) && (4.4) \
\end{aligned}
$$</p>
<p>Note that we can find the third and the forth term from the transition probability matrix and the emission probability matrix. Again, we can calculate $p(z_{k+1}, z_k | x)$ simply by introducing a normalization term. That is,</p>
<p>$$
\begin{aligned}
p(z_{k+1}=s, z_k=r | x) &= \frac{p(z_{k+1}=s, z_k=r, x)}{\sum_{i=1}^{m} \sum_{j=1}^{m} p(z_{k+1}=j, z_k=i, x)} \\ &= \frac{\alpha_k(z_k=r) \cdot \beta_{k+1}(z_{k+1}=s) \cdot p(z_{k+1}=s|z_{k}=r) \cdot p(x_{k+1}| z_{k+1}=s)}{\sum_{i=1}^{m} \alpha_k(z_k=i) \cdot \beta_{k+1}(z_{k+1}=j) \cdot p(z_{k+1}=j|z_{k}=i) \cdot p(x_{k+1}| z_{k+1}=j)} && (4.42)
\end{aligned}
$$</p>
<p><em>Remark</em></p>
<ul>
<li>
<p>We denote</p>
<p>$$ \gamma_k(i) = p(z_k = i | x) = \frac{p(z_k=i, x)}{p(x)} \tag{4.43}$$</p>
</li>
<li>
<p>We denote</p>
<p>$$ \xi_k(i,j) = p(z_{k+1}=j, z_k=i | x) = \frac{p(z_{k+1}=j, z_k=i, x)}{p(x)} \tag{4.44}$$</p>
</li>
</ul>
<h2 id=three-fundamental-problems-of-hmm>Three fundamental problems of HMM<a hidden class=anchor aria-hidden=true href=#three-fundamental-problems-of-hmm>#</a></h2>
<p><strong>Problem 1 (Likelihood):</strong> Given an observation sequence $x$ and parameters $\theta = (A, B, \pi)$, determine the likelihood $p(x|\theta)$.</p>
<p><strong>Problem 2 (Learning):</strong> Given an observation sequence $x$, learn the parameters $\theta = (A, B, \pi)$.</p>
<p><strong>Problem 3 (Inference):</strong> Given an observation sequence $x$ and parameters $\theta = (A, B, \pi)$, discover the best hidden state sequence $z$.</p>
<h2 id=problem-1-likelihood>Problem 1 (Likelihood)<a hidden class=anchor aria-hidden=true href=#problem-1-likelihood>#</a></h2>
<p><strong>Goal: Given an observation sequence $x$ and parameters $\theta = (A, B, \pi)$, determine the likelihood $p(x|\theta)$.</strong></p>
<p><em>Naive Way:</em></p>
<p>From $(0)$, we have already know how to compute $P(x, z|\theta)$, so we can compute $p(x|\theta)$ by summing all possible sequence $z$:</p>
<p>$$ p(x|\theta) = \sum_z P(x, z|\theta) \cdot p(z|\theta)$$</p>
<p>This method is not applicable since there are $m^n$ ways of combinations of sequence $z$. So we introduce the following two algorithm: <em>Forward Algorithm</em> and <em>Backward Algorithm</em>.</p>
<h3 id=forward-algorithm>Forward Algorithm<a hidden class=anchor aria-hidden=true href=#forward-algorithm>#</a></h3>
<img src=https://img-blog.csdnimg.cn/20200503031104373.png width=550>
<ul>
<li><strong>Goal:</strong> Compute $p(z_k, x_{1:k})$, given $\theta = (A, B, \pi)$.</li>
</ul>
<p>From the picture above, it&rsquo;s natural to compute $p(z_k, x_{1:k})$ by dynamic programming (DP). That is, to calculate it in terms of $p(z_{k-1}, x_{1:k-1})$:</p>
<p>$$
\begin{aligned}
p(z_k , x_{1:k}) &= \sum_{z_{k-1}} p(z_k, z_{k-1}, x_{1:k-1}, x_k) & & (5)\\ &= \sum_{z_{k-1}} p(z_{k-1}, x_{1:k-1}) \cdot p(z_k, x_k|z_{k-1}, x_{1:k-1}) & & (6)\\ &= \sum_{z_{k-1}} p(z_{k-1}, x_{1:k-1}) \cdot p(z_k|z_{k-1}, x_{1:k-1}) \cdot p(x_k|z_k, z_{k-1}, x_{1:k-1}) & & (7)\\ &= \sum_{z_{k-1}} p(z_{k-1}, x_{1:k-1}) \cdot p(z_k|z_{k-1}) \cdot p(x_k|z_k) & & (8)\
\end{aligned}
$$</p>
<p><em>Ramark:</em></p>
<ul>
<li>
<p>From $(6)$ to $(7)$, we use the fact that $p(b,c|a) = p(b|a) \cdot p(c|a,b)$.</p>
</li>
<li>
<p>From $(7)$ to $(8)$, we use the conditional independence, which is visualized in the picture above.</p>
</li>
<li>
<p>We denote $p(z_k , x_{1:k})$ by $\alpha_k(z_k)$, so</p>
<p>$$ \alpha_k(z_k) = p(z_k , x_{1:k}) = \sum_{z_{k-1}} \alpha_{k-1}(z_{k-1}) \cdot p(z_k|z_{k-1}) \cdot p(x_k|z_k) \tag 9$$</p>
</li>
<li>
<p>In equation $(9)$, the term $p(z_k|z_{k-1})$ is the transition probability from state $z_{k-1}$ to state $z_{k}$; the term $p(x_k|z_k)$ is the emission probability of observing $x_k$ given state $z_k$.</p>
</li>
<li>
<p>$\alpha_1(z_1=q) = p(z_1=q, x_1) = \pi_q \cdot p(x_1 | z_1 = q)$, where $p(x_1 | z_1 = q)$ is an emmission probability.</p>
</li>
</ul>
<p>Knowing how to compute $p(z_k , x_{1:k})$ recurssively, we have</p>
<p>$$p(x|\theta) = p(x_{1:n}|\theta) = \sum_{z_n} p(z_n, x_{1:n}) = \sum_{z_n} \alpha_n(z_n) = \sum_{q=1}^{m} \alpha_n(z_n=q)$$</p>
<h3 id=backward-algorithm>Backward Algorithm<a hidden class=anchor aria-hidden=true href=#backward-algorithm>#</a></h3>
<ul>
<li><strong>Goal:</strong> Compute $p(x_{k+1:n} | z_k)$, given $\theta = (A, B, \pi)$.</li>
</ul>
<p>Again, we are going to use <em>DP</em> to compute $p(x_{k+1:n} | z_k)$ in terms of $p(x_{k+2:n} | z_{k+1})$:</p>
<p>$$
\begin{aligned}
p(x_{k+1:n} | z_k) &= \sum_{z_{k+1}} p(x_{k+1}, x_{k+2:n}, z_{k+1} | z_k) \\ &= \sum_{z_{k+1}} p(x_{k+2:n}, z_{k+1}| z_k) \cdot p(x_{k+1}| z_k, x_{k+2:n}, z_{k+1}) \\ &= \sum_{z_{k+1}} p(z_{k+1}|z_k) \cdot p(x_{k+2:n}|z_{k+1}, z_k) \cdot p(x_{k+1} | z_k, x_{k+2:n}, z_{k+1}) && (10)\\ &= \sum_{z_{k+1}} p(x_{k+2:n}|z_{k+1}) \cdot p(z_{k+1}|z_k) \cdot p(x_{k+1}|z_{k+1}) && (11)\
\end{aligned}
$$</p>
<p><em>Ramark:</em></p>
<ul>
<li>
<p>From $(10)$ to $(11)$, we use the conditional independece similar to the one in forward algorithm.</p>
</li>
<li>
<p>We denote $p(x_{k+1:n} | z_k)$ by $\beta_k(z_k)$, so</p>
<p>$$ \beta_k(z_k) = p(x_{k+1:n} | z_k) = \sum_{z_{k+1}} p(x_{k+2:n}|z_{k+1}) \cdot p(z_{k+1}|z_k) \cdot p(x_{k+1}|z_{k+1}) \tag {12}$$</p>
</li>
<li>
<p>In equation $(12)$, the term $p(z_{k+1}|z_k)$ is the transition probability from state $z_{k}$ to state $z_{k+1}$; the term $p(x_{k+1}|z_{k+1})$ is the emission probability of observing $x_{k+1}$ given state $z_{k+1}$.</p>
</li>
<li>
<p>$\beta_n(z_n) = 1$.</p>
</li>
</ul>
<p>Knowing how to compute $p(x_{k+1:n} | z_k)$ recursively, we have</p>
<p>$$
\begin{aligned}
p(x|\theta) &= \sum_{z_1} p(x, z_1) = \sum_{z_1} p(x | z_1) \cdot p(z_1) \\ &= \sum_{z_1} p(x_1, x_{1+1:n} | z_1) \cdot p(z_1) \\ &= \sum_{z_1} p(x_1 | z_1) \cdot p(x_{1+1:n}|z_1, x_1) \cdot p(z_1) &&(13)\\ &= \sum_{z_1} p(x_1 | z_1) \cdot p(x_{1+1:n}|z_1) \cdot p(z_1) &&(14)\\ &= \sum_{z_1} p(x_1 | z_1) \cdot \beta_1(z_1) \cdot p(z_1) \\ &= \sum_{q=1}^m \beta_1(z_1=q) \cdot p(x_1 | z_1=q) \cdot \pi_q
\end{aligned}
$$</p>
<p>From $(13)$ to $(14)$, we use the conditional independence. To make it clean, I didn&rsquo;t include $\theta$ in the above derivation, but keep in mind $x$ is conditioned on $\theta$.</p>
<h2 id=problem-2-learning>Problem 2 (Learning)<a hidden class=anchor aria-hidden=true href=#problem-2-learning>#</a></h2>
<p><strong>Goal: Given an observation sequence $x$, learn the parameters $\theta = (A, B, \pi)$.</strong></p>
<p>Given that the hidden states are unknown, it&rsquo;s natural to use the <em>EM Algorithm</em> to solve parameters. Remind that the <em>EM Algorithm</em> consists of two steps:</p>
<ul>
<li>An <em>expectation (E) step</em>, which creates a function $Q(\theta, \theta_i)$ for the expectation of the log-likelihood $\log p(x,z|\theta)$ evaluated using the current conditional distribution of $z$ given $x$ and the current estimate of the parameters $\theta_i$, where</li>
</ul>
<p>$$
\begin{aligned}
Q(\theta, \theta_i) &= E_{z \sim P(z|x,\theta_i)}[\log p(x,z|\theta)] \\ &= \sum_z P(z|x,\theta_i) \cdot \log p(x,z|\theta) \ <br>
\end{aligned}
$$</p>
<ul>
<li>A <em>maximization (M) step</em>, which computes parameters maximizing the expected log-likelihood $Q(\theta, \theta_i)$ found on the $E$ step and then update parameters to $\theta_{i+1}$.</li>
</ul>
<p>We fist initialize parameters $\theta_0 = (A_0, B_0, \pi_0)$</p>
<p><strong>E Step:</strong></p>
<p>We are going to construct $Q(\theta, \theta_i)$.</p>
<p>$$
\begin{aligned}
Q(\theta, \theta_i) &= E_{z \sim P(z|x,\theta_i)}[\log p(x,z|\theta)] \\ &= \sum_z P(z|x,\theta_i) \cdot \log p(x,z|\theta) \\ &= \log p(x,z|\theta) \cdot \frac{p(x,z|\theta_i)}{p(x|\theta_i)} &&(15)\\ &\propto \log p(x,z|\theta) \cdot p(x,z|\theta_i) &&(16)\
\end{aligned}
$$</p>
<p>Since we know $x$ and $\theta_i$, $p(x|\theta_i)$ is a constant and therefore we can write from $(15)$ to $(16)$. In the earlier section &ldquo;<em>Settings of the Hidden Markov Model</em>&rdquo; of the post, we deduce that</p>
<p>$$P(x, z|\theta) = p(z_1) \cdot [p(z_2|z_1)\cdot p(z_3|z_2)\cdot &mldr; \cdotp(z_n|z_{n-1})] \cdot [p(x_1|z_1)\cdot p(x_2|z_2)\cdot &mldr; \cdot p(x_n|z_n)]$$</p>
<p>So we can formulate $Q(\theta, \theta_i)$ as</p>
<p>$$
\begin{aligned}
Q(\theta, \theta_i) &= \sum_z \left( \log \pi_{z_i} + \sum_{t=1}^{n-1} \log p(z_{t+1}|z_t) + \sum_{t=1}^{n} \log p(x_n|z_n)\right) \cdot p(x,z|\theta_i) \\ &= \sum_z \log \pi_{z_i} \cdot p(x,z|\theta_i) + \sum_z \sum_{t=1}^{n-1} \log p(z_{t+1}|z_t) \cdot p(x,z|\theta_i) + \sum_z \sum_{t=1}^{n} \log p(x_t|z_t) \cdot p(x,z|\theta_i) \
\end{aligned}
$$</p>
<p><strong>M Step:</strong></p>
<p>We are going to maximize $Q(\theta, \theta_i)$ and update $\theta_{i+1}$.</p>
<p>Note that we write $Q(\theta, \theta_i)$ as the sum of three terms. The first therm is related to $\pi$, the second term is related to $A$, and the third term is related to $B$. Therefore we can maximize each term separately.</p>
<p>We can write the first term as</p>
<p>$$\sum_z \log \pi_{z_i} \cdot p(x,z|\theta_i) = \sum_{j=1}^m \log \pi_j \cdot p(x, z_1 = j|\theta_i)$$</p>
<p>under the constraint $\sum_{j=1}^m \pi_j = 1$. Clearly, this is a convex optimization problem:</p>
<img src=https://img-blog.csdnimg.cn/20200503031605105.png width=320>
<p>The Lagrangian $L$ associated with the problem is</p>
<p>$$ L(\pi, v) = \sum_{j=1}^m \log \pi_j \cdot p(x, z_1 = j|\theta_i) + v \cdot (\sum_{j=1}^m \pi_j - 1)$$</p>
<p>Note that any pair of primal and dual optimal points must satisfy the KKT conditions. So we use one KKT property that the <em>gradient must vanish at the optimal point</em> to find $\pi$. This might not be the optimal $\pi$ since &ldquo;any pair of primal and dual optimal points must satisfy the KKT conditions&rdquo; doesn&rsquo;t imply that a point satisfying the KKT conditions is the optimal.</p>
<p>$$
\begin{aligned}
\frac{\partial L}{\partial \pi_j} = p(x, z_1=j|\theta_i) \cdot \frac{1}{\pi_j} + v & = 0 \\ p(x, z_1=j|\theta_i) + v \cdot \pi_j & = 0 \\ \pi_j & = \frac{-p(x, z_1=j|\theta_i)}{v} & & (17)\
\end{aligned}
$$</p>
<p>By setting $\frac{\partial L}{\partial \pi_j} = 0$ for all $j$, we have</p>
<p>$$
\begin{aligned}
\sum_{j=1}^m p(x, z_1=j|\theta_i) + v \cdot \sum_{j=1}^m \pi_j &= 0 \\ p(x|\theta_i) + v &= 0\\ v &= - p(x|\theta_i) && (18)\
\end{aligned}
$$</p>
<p>By plugging $(18)$ into $(17)$, we have</p>
<p>$$ \pi_j = \frac{-p(x, z_1=j|\theta_i)}{v} = \frac{p(x, z_1=j|\theta_i)}{p(x|\theta_i)} = \gamma_1(j)$$.</p>
<p>In the similar way, we can write the second term as</p>
<p>$$ \sum_z \sum_{t=1}^{n-1} \log p(z_{t+1}|z_t) \cdot p(x,z|\theta_i) =
\sum_{j=1}^m \sum_{k=1}^m \sum_{t=1}^{n-1} \log p(z_{t+1}=k|z_t=j) \cdot p(x,z_t=j, z_{t+1}=k|\theta_i) \
\sum_z \sum_{t=1}^{n} \log p(x_t|z_t) \cdot p(x,z|\theta_i) =
\sum_{j=1}^m \sum_{t=1}^n \log p(x_t|z_t=j) \cdot p(x,z_t=j|\theta_i)
$$</p>
<p>with seperate constraints</p>
<p>$$\sum_{k=1}^m p(z_{t+1}=k|z_t=j) = 1, \
\sum_{j=1}^m p(x_t|z_t=j) = 1
$$</p>
<p>We can solve for optimal parameters similar to solving for $\pi$. After we set the gradient of corresponding Lagrangian to $0$, we have</p>
<p>$$
\begin{aligned}
A_{jk} &= p(z_{t+1}=k|z_t=j) \\ &= \frac{\sum_{t=1}^{n-1} p(x, z_t=j, z_{t+1}=k|\theta_i)}{\sum_{t=1}^{n-1} p(x, z_t=j|\theta_i)} \\ &= \frac{\sum_{t=1}^{n-1} p(x, z_t=j, z_{t+1}=k|\theta_i)/ p(x|\theta_i)}{\sum_{t=1}^{n-1} p(x, z_t=j|\theta_i)/p(x|\theta_i)} \\ &= \frac{\sum_{t=1}^{n-1} \xi_t(jk)}{\sum_{t=1}^{n-1} \gamma_t(j)} &&(19)\\
B_{jk} &= p(x_t= V_k|z_t=j) \\ &= \frac{\sum_{t=1}^{n-1} p(x, z_t=j|\theta_i)\cdot I(x_t= V_k)}{\sum_{t=1}^{n-1} p(x, z_t=j | \theta_i)} \\ &= \frac{\sum_{t=1}^{n-1} p(x, z_t=j|\theta_i)/ p(x|\theta_i) \cdot I(x_t= V_k)}{\sum_{t=1}^{n-1} p(x, z_t=j | \theta_i)/ p(x|\theta_i)} \\ &= \frac{\sum_{t=1}^{n-1} \gamma_t(j) \cdot I(x_t=V_k)}{\sum_{t=1}^{n-1} \gamma_t(j)} &&(20)\
\end{aligned}
$$</p>
<p>Remark: $I(x_t= V_k)$ is an indicator function. If $x_t= V_k$, then $I(x_t= V_k) = 1$, and $0$ otherwise. We get the results $(19)$ and $(20)$ from $(4.43)$ and $(4.44)$.</p>
<p>We also call this algorithm <strong>Baum-Welch algorithm</strong>.</p>
<h2 id=problem-3-inference>Problem 3 (Inference)<a hidden class=anchor aria-hidden=true href=#problem-3-inference>#</a></h2>
<p><strong>Goal: Given an observation sequence $x$ and parameters $\theta = (A, B, \pi)$, discover the best hidden state sequence $z$.</strong></p>
<p><em>Method 1:Brute force</em>.</p>
<p>This is not applicable. Every hidden state has $m$ choices and the sequence has length $n$. So there are $m^n$ possible combinations.</p>
<p><em>Method 2: Use Forward/ Backward Algorithm</em>.
Given a sequence $x$, we know how to compute $p(z_k | x)$ from the top of the post. Therefore, at each time $k$, we can compute $p(z_k=i| x)$ for all $i \in {1,2,&mldr;,m}$ and choose the one with the highest probability. In the way, at every time, we chose the most possible hidden state. However, there is still a problem. It only finds the most possible hidden state locally and doesn&rsquo;t take the whole sequence into account. Even if we chose the most possible hidden state at each time $k$. The combination of them might not be the best one and even doesn&rsquo;t make sense. Foe example, if $A_{ij} = 0$, then if $z_k=i$, $z_{k+1}$ cannot take state $j$. But the Forward/ Backward Algorithm doesn&rsquo;t take it into account. We can think of it as a greedy approach to approximate the best result.</p>
<p><em>Method 3: <strong>Viterbi algorithm</strong>:</em></p>
<p>The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states that results in a sequence of observed events in HMM.</p>
<p>We define $\delta_k(i)$ to be the maximum probability among all paths which are at state $i$ at time $k$. That is,</p>
<p>$$\delta_k(i) = \mathop{\rm max}\limits_{i_1:i_{k-1}} p(i_k=i, i_1:i_{k-1}, x_{1:k}|\theta), \quad i= 1,2,&mldr;,m$$</p>
<p>We can construct a recurssion formula $\delta_k(i)$. That is,</p>
<p>$$
\begin{aligned}
\delta_{k+1}(i) &= \mathop{\rm max}\limits_{i_1:i_{k}} p(i_{k+1}=i, i_1:i_{k}, x_{1:k+1}|\theta) \\ &= \mathop{\rm max}\limits_{1\leq j \leq m} \delta_k(j) \cdot A_{ji} \cdot p(x_{k+1}|z_{k+1}=i) && i= 1,2,&mldr;,m; , k=1,2,&mldr;,n-1\
\end{aligned}
$$</p>
<p>And the base case is $\delta_{1}(i) = \pi_i \cdot p(x_1| z_1=i)$.</p>
<p>Therefore, we compute the optimal probability $P^{*}$</p>
<p>$$P^{*} = \mathop{\rm max}\limits_{1 \leq i \leq m} \delta_n(i)$$</p>
<p>by recursion. During the process of finding the highest probability of a path, we keep recording the hidden states associate with the path. So after we find the the highest probability, we also record the path associated with it and therefore the best sequence $z$.</p>
<hr>
<p>Reference:</p>
<ul>
<li><a href=https://towardsdatascience.com/conditional-independence-the-backbone-of-bayesian-networks-85710f1b35b>https://towardsdatascience.com/conditional-independence-the-backbone-of-bayesian-networks-85710f1b35b</a></li>
<li><a href=https://courses.cs.washington.edu/courses/cse473/16au/slides-16au/25-bn.pdf>https://courses.cs.washington.edu/courses/cse473/16au/slides-16au/25-bn.pdf</a></li>
<li><a href=https://en.wikipedia.org/wiki/Conditional_independence>https://en.wikipedia.org/wiki/Conditional_independence</a></li>
<li><a href=https://web.stanford.edu/~jurafsky/slp3/A.pdf>https://web.stanford.edu/~jurafsky/slp3/A.pdf</a></li>
<li><a href=https://www.cs.cmu.edu/~epxing/Class/10701-08s/recitation/em-hmm.pdf>https://www.cs.cmu.edu/~epxing/Class/10701-08s/recitation/em-hmm.pdf</a></li>
<li><a href=https://people.eecs.berkeley.edu/~stephentu/writeups/hmm-baum-welch-derivation.pdf>https://people.eecs.berkeley.edu/~stephentu/writeups/hmm-baum-welch-derivation.pdf</a></li>
</ul>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://tangliyan.com/blog/tags/nlp/>NLP</a></li>
<li><a href=https://tangliyan.com/blog/tags/math/>MATH</a></li>
</ul>
<nav class=paginav>
<a class=prev href=https://tangliyan.com/blog/posts/pgm/>
<span class=title>« Prev Page</span>
<br>
<span>Probabilistic Graphical Model (PGM)</span>
</a>
<a class=next href=https://tangliyan.com/blog/posts/em/>
<span class=title>Next Page »</span>
<br>
<span>EM (Expectation–Maximization) Algorithm</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Hidden Markov Model (HMM) on twitter" href="https://twitter.com/intent/tweet/?text=Hidden%20Markov%20Model%20%28HMM%29&url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fhmm%2f&hashtags=NLP%2cMATH"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Hidden Markov Model (HMM) on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fhmm%2f&title=Hidden%20Markov%20Model%20%28HMM%29&summary=Hidden%20Markov%20Model%20%28HMM%29&source=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fhmm%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Hidden Markov Model (HMM) on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fhmm%2f&title=Hidden%20Markov%20Model%20%28HMM%29"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Hidden Markov Model (HMM) on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fhmm%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Hidden Markov Model (HMM) on whatsapp" href="https://api.whatsapp.com/send?text=Hidden%20Markov%20Model%20%28HMM%29%20-%20https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fhmm%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Hidden Markov Model (HMM) on telegram" href="https://telegram.me/share/url?text=Hidden%20Markov%20Model%20%28HMM%29&url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fhmm%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href=https://tangliyan.com/blog/>Liyan Tang</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
<script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script>
</body>
</html>