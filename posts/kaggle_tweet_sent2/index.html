<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Kaggle: Tweet Sentiment Extraction - top solutions | Liyan Tang</title>
<meta name=keywords content="NLP,COMPETITION">
<meta name=description content="Note This post is the second part of overall summarization of the competition. The first half is here.
Noteworthy ideas in 1st place solution Idea First step:
Use transformers to extract token level start and end probabilities.
Second step:
Feed these probabilities to a character level model. This step gives the team a huge improve on the final score since it handled the &ldquo;noise&rdquo; in the data properly.
Last step:">
<meta name=author content>
<link rel=canonical href=https://tangliyan.com/blog/posts/kaggle_tweet_sent2/>
<link crossorigin=anonymous href=/blog/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/blog/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://tangliyan.com/blog/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://tangliyan.com/blog/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://tangliyan.com/blog/favicon-32x32.png>
<link rel=apple-touch-icon href=https://tangliyan.com/blog/apple-touch-icon.png>
<link rel=mask-icon href=https://tangliyan.com/blog/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.92.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-202974782-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="Kaggle: Tweet Sentiment Extraction - top solutions">
<meta property="og:description" content="Note This post is the second part of overall summarization of the competition. The first half is here.
Noteworthy ideas in 1st place solution Idea First step:
Use transformers to extract token level start and end probabilities.
Second step:
Feed these probabilities to a character level model. This step gives the team a huge improve on the final score since it handled the &ldquo;noise&rdquo; in the data properly.
Last step:">
<meta property="og:type" content="article">
<meta property="og:url" content="https://tangliyan.com/blog/posts/kaggle_tweet_sent2/"><meta property="og:image" content="https://tangliyan.com/blog/papermod-cover.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2020-07-02T00:00:00+00:00">
<meta property="article:modified_time" content="2020-07-02T00:00:00+00:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://tangliyan.com/blog/papermod-cover.png">
<meta name=twitter:title content="Kaggle: Tweet Sentiment Extraction - top solutions">
<meta name=twitter:description content="Note This post is the second part of overall summarization of the competition. The first half is here.
Noteworthy ideas in 1st place solution Idea First step:
Use transformers to extract token level start and end probabilities.
Second step:
Feed these probabilities to a character level model. This step gives the team a huge improve on the final score since it handled the &ldquo;noise&rdquo; in the data properly.
Last step:">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tangliyan.com/blog/posts/"},{"@type":"ListItem","position":2,"name":"Kaggle: Tweet Sentiment Extraction - top solutions","item":"https://tangliyan.com/blog/posts/kaggle_tweet_sent2/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Kaggle: Tweet Sentiment Extraction - top solutions","name":"Kaggle: Tweet Sentiment Extraction - top solutions","description":"Note This post is the second part of overall summarization of the competition. The first half is here.\nNoteworthy ideas in 1st place solution Idea First step:\nUse transformers to extract token level start and end probabilities.\nSecond step:\nFeed these probabilities to a character level model. This step gives the team a huge improve on the final score since it handled the \u0026ldquo;noise\u0026rdquo; in the data properly.\nLast step:","keywords":["NLP","COMPETITION"],"articleBody":"Note This post is the second part of overall summarization of the competition. The first half is here.\nNoteworthy ideas in 1st place solution Idea First step:\nUse transformers to extract token level start and end probabilities.\nSecond step:\nFeed these probabilities to a character level model. This step gives the team a huge improve on the final score since it handled the “noise” in the data properly.\nLast step:\nEnsemble.\nSecond level models Architectures The following three Char-NN architectures uses character-level probabilities as input. The first level models output token-level probabilities and the following code convert token-level probabilities to character-level probabilities. The idea in the following cide is to assigning each character the probability of the corresponding token.\ndef token_level_to_char_level(text, offsets, preds): probas_char = np.zeros(len(text)) for i, offset in enumerate(offsets): if offset[0] or offset[1]: # remove padding and sentiment probas_char[offset[0]:offset[1]] = preds[i] return probas_char Things you need to know for nn.Embedding\nThe following architectures all train the embedding from scratch. Here we want to shortly discuss how nn.Embedding works.\nnn.Embedding holds a Tensor of dimension (vocab_size, vector_size), i.e., of (the size of the vocabulary, the dimension of each vector embedding), and a method that does the lookup. When you create an embedding layer, the Tensor is initialised randomly.\nYou can also add pretrained weights with the command nn.Embedding.from_pretrained(weight).\nArchitecture 1: RNN In the following, the parameter len_voc is calculated by\ntokenizer.fit_on_texts(df_train['text'].values) len_voc = len(tokenizer.word_index) + 1 Compare the following code with the figure above.\nclass TweetCharModel(nn.Module): # check the config in the original code post def __init__(self, len_voc, use_msd=True, embed_dim=64, lstm_dim=64, char_embed_dim=32, sent_embed_dim=32, ft_lstm_dim=32, n_models=1): super().__init__() self.use_msd = use_msd self.char_embeddings = nn.Embedding(len_voc, char_embed_dim) self.sentiment_embeddings = nn.Embedding(3, sent_embed_dim) # 3 sentiments self.proba_lstm = nn.LSTM(n_models * 2, ft_lstm_dim, batch_first=True, bidirectional=True) self.lstm = nn.LSTM(char_embed_dim + ft_lstm_dim * 2 + sent_embed_dim, lstm_dim, batch_first=True, bidirectional=True) self.lstm2 = nn.LSTM(lstm_dim * 2, lstm_dim, batch_first=True, bidirectional=True) self.logits = nn.Sequential( nn.Linear(lstm_dim * 4, lstm_dim), nn.ReLU(), nn.Linear(lstm_dim, 2)) self.high_dropout = nn.Dropout(p=0.5) def forward(self, tokens, sentiment, start_probas, end_probas): bs, T = tokens.size() probas = torch.cat([start_probas, end_probas], -1) probas_fts, _ = self.proba_lstm(probas) char_fts = self.char_embeddings(tokens) sentiment_fts = self.sentiment_embeddings(sentiment).view(bs, 1, -1) sentiment_fts = sentiment_fts.repeat((1, T, 1)) features = torch.cat([char_fts, sentiment_fts, probas_fts], -1) features, _ = self.lstm(features) features2, _ = self.lstm2(features) features = torch.cat([features, features2], -1) # Multi-sample dropout (MSD) if self.use_msd and self.training: logits = torch.mean( torch.stack( [self.logits(self.high_dropout(features)) for _ in range(5)], dim=0), dim=0) else: logits = self.logits(features) start_logits, end_logits = logits[:, :, 0], logits[:, :, 1] return start_logits, end_logits Architecture 2: CNN class ConvBlock(nn.Module): # check the config in the original code post def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dilation=1, padding=\"same\", use_bn=True): super().__init__() if padding == \"same\": padding = kernel_size // 2 * dilation if use_bn: self.conv = nn.Sequential( nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding, stride=stride, dilation=dilation), nn.BatchNorm1d(out_channels), nn.ReLU()) else: self.conv = nn.Sequential( nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding, stride=stride, dilation=dilation), nn.ReLU()) def forward(self, x): return self.conv(x) class TweetCharModel(nn.Module): def __init__(self, len_voc, use_msd=True, cnn_dim=64, char_embed_dim=32, sent_embed_dim=32, proba_cnn_dim=32, n_models=1, kernel_size=3, use_bn=False): super().__init__() self.use_msd = use_msd self.char_embeddings = nn.Embedding(len_voc, char_embed_dim) self.sentiment_embeddings = nn.Embedding(3, sent_embed_dim) self.probas_cnn = ConvBlock(n_models * 2, proba_cnn_dim, kernel_size=kernel_size, use_bn=use_bn) self.cnn = nn.Sequential( ConvBlock(char_embed_dim + sent_embed_dim + proba_cnn_dim, cnn_dim, kernel_size=kernel_size, use_bn=use_bn), ConvBlock(cnn_dim, cnn_dim * 2, kernel_size=kernel_size, use_bn=use_bn), ConvBlock(cnn_dim * 2 , cnn_dim * 4, kernel_size=kernel_size, use_bn=use_bn), ConvBlock(cnn_dim * 4, cnn_dim * 8, kernel_size=kernel_size, use_bn=use_bn)) self.logits = nn.Sequential( nn.Linear(cnn_dim * 8, cnn_dim), nn.ReLU(), nn.Linear(cnn_dim, 2)) self.high_dropout = nn.Dropout(p=0.5) def forward(self, tokens, sentiment, start_probas, end_probas): bs, T = tokens.size() probas = torch.cat([start_probas, end_probas], -1).permute(0, 2, 1) probas_fts = self.probas_cnn(probas).permute(0, 2, 1) char_fts = self.char_embeddings(tokens) sentiment_fts = self.sentiment_embeddings(sentiment).view(bs, 1, -1) sentiment_fts = sentiment_fts.repeat((1, T, 1)) x = torch.cat([char_fts, sentiment_fts, probas_fts], -1).permute(0, 2, 1) features = self.cnn(x).permute(0, 2, 1) # [Bs x T x nb_ft] if self.use_msd and self.training: logits = torch.mean( torch.stack( [self.logits(self.high_dropout(features)) for _ in range(5)], dim=0), dim=0) else: logits = self.logits(features) start_logits, end_logits = logits[:, :, 0], logits[:, :, 1] return start_logits, end_logits Architecture 3: WaveNet This is a model architecture from another competition, so I ignore the author’s detail here. I attached the source code in the reference.\nstacking ensemble Their solution has no post-processing and just modeling. The following is the idea how they did the final ensemble.\nNoteworthy ideas in 2nd place solution Ensemble  Using two different seeds (seed averaging):  RoBERTa Base 11th layer + RoBERTa Large 23th layer + RoBERTa Base MSD + RoBERTa Large MSD\n$4$ models $\\times$ $2$ seeds = Total $8$ models\nPost-processing on the extra space I attached the pp in the reference. I tried out this pp and it raised my rank to around $20$th.\nReranking-model training (Create multi candidates and choose best one) What is re-ranking Their model can predict not only a top-$1$ selected_text candidate but also top-$n$ candidates. So re-ranking means that they re-score these top-$n$ candidate.\nWhy re-ranking “I calculated the upper bound jaccard score of top-5 candidates in the validation set and that was 0.87-0.88. (If I choose only top-1, the score is only 0.71-0.72.)\nSo I realized that there is a huge room for improving score by re-ranking. In fact, in the field of question answering (similar to this task), the re-ranking approach is developed.”\nHow to re-rank To re-rank candidates, they used two score.\nFirst one is based on start \u0026 end value(after applying softmax) from base-model. Second one is a predicted jaccard score using re-ranking model.\nRe-ranking model Build a second level model on top of previous model.\n input: triple (sentiment, tweet, candidate) predict: jaccard score  The way they pass the tuple (sentiment, tweet, candidate) to the model is\ntweet_candidate = TOKENIZER.encode(str(tweet) + \" \" + str(candidate)) token_ids = [0] + [sentiment] + [2] + [2] + tweet_candidate.ids + [2] In concrete, they calculated top-$5$ candidates in training and validation set and memorize their jaccard score.\nThey use a simple roberta-base model to predict jaccard score using MSELoss().\nFinal re-ranking score Finally, candidates are re-ranked using this score.\n(start value + end value) * 0.5 + predicted jaccard score\nHere, start and end value means logits calculated by the base model (i.e. start and end position logits after softmax function). This part of the code is under the reference section.\nsequence bucketing (dynamic padding) Team:\"inference time speed up x2 and surprisingly got a better result than not using.\"\nIn RNNs, the input sequences are often all padded to the same length by doing something along the lines of this:\nx_train = pad_sequences(x_train, maxlen=MAX_LEN)\nThis is suboptimal because when iterating over the dataset in batches, there will be some batches where the length of all samples is smaller than MAX_LEN. So there will be tokens which are zero everywhere in the batch but are still processed by the RNN. Using sequence bucketing, we can speed this up by dynamically padding every batch to the maximum sequence length which occurs in that batch. Or to e.g. the $95$th percentile of lengths in that batch.\nclass RerankingCollate: def __init__(self): self.CONFIG = {} self.CONFIG['BUCKET'] = True self.CONFIG['MAX_LEN'] = MAX_LEN def __call__(self, batch): out = { 'orig_tweet' : [], 'sentiment' : [], 'orig_selected' : [], 'jaccard' : [], 'score' : [], 'ids' : [], 'mask' : [], 'token_type_ids' : [], } for i in range(len(batch)): for k, v in batch[i].items(): out[k].append(v) # Deciding the number of padding if self.CONFIG['BUCKET']: max_pad = 0 for p in out['ids']: if len(p)max_pad: max_pad = len(p) else: max_pad = self.CONFIG['MAX_LEN'] # Padding for i in range(len(batch)): tokenized_text = out['ids'][i] token_type_ids = out['token_type_ids'][i] mask = out['mask'][i] text_len = len(tokenized_text) out['ids'][i] = (tokenized_text + [1]*(max_pad - text_len))[:max_pad] out['token_type_ids'][i] = (token_type_ids + [0]*(max_pad - text_len)[:max_pad] out['mask'][i] = (mask + [0]*(max_pad - text_len))[:max_pad] # torch.float out['jaccard'] = torch.tensor(out['jaccard'], dtype=torch.float) out['score'] = torch.tensor(out['score'], dtype=torch.float) # torch.long out['ids'] = torch.tensor(out['ids'], dtype=torch.long) out['mask'] = torch.tensor(out['mask'], dtype=torch.long) out['token_type_ids'] = torch.tensor(out['token_type_ids'], dtype=torch.long) return out Here is how to use it:\nvalid_data_loader = torch.utils.data.DataLoader( valid_dataset, batch_size=val_nums, collate_fn=RerankingCollate(), num_workers=0, ) Noteworthy ideas in 3rd place solution Idea 1: Normal model with beamsearch-like decoder Copied XLNet’s decoder head for question answering to RoBERTa. Basically you predict the start index, get the $k$ hidden states at the top-$k$ indices. For each hidden state, concat it to the end index logits and predict the corresponding top-$k$ end indices. The best $k$ is 3, for whatever reasons, which resulted in a $3 \\times 3$ start-end pairs. I ranked them by taking the product of the two probs.\nGeneral explanation for idea 1 Training Step:\n Predict the start index normally. Take the hidden representation at the target index (ignoring the predicted) and concat it into the representations at every position. The new presentation is then fed to a MLP to predict the end index.  Inference:\n Predicting the start index normally. Take top-$k$ hidden states corresponding to top-$k$ start indices with highest probabilities. Each hidden state is then concatenated into the representations at every position. The new representation is fed to a MLP, similar to training. Then select top-$k$ end indices for each selected hidden state, resulting in $k \\times k$ top start-end pairs. The best k is $3$, which resulted in a $3 \\times 3$ start-end pairs. They ranked them by taking the product of the two probs.  Idea 2: Character level model with GRU head Address the noisy targets by adding a prediction head that enables character wise span-prediction and completely learns the noise. They trained all models using a 5-seed average. Their best submission consists of a total of 3x5x2 models (backbones x seeds x team mates).\nGeneral explanation for idea 2 They realized that the key to a decent performance is the capability to predict a character-wise span. A good example, which they are also using in the illustration below is the tweet text “is back home now gonna miss everyone” which weirdly had the label “onna”. They knew that if a model would be able to predict “onna”, that would put them in a top spot.\nIn fact a character-wise prediction would solves two issues:\n Definition of label: you now can just put the selected text as it as label. Predicting noise: you now are able to predict “half words” which was the key of the competition.  The key idea of this method is that “The model uses a standard transformer backbone which takes the word-level tokenized text and outputs hidden states with a certain dimension (in case of roberta-base 768). Instead of predicting the start and end word now, as done by “standard” models I replicate the hiddenstate of each word as often as the word has characters, so we get a hidden state for each character. In order to differentiate between characters I add a few 768 - 768 RNN layers. Finally, two linear layers predict the start and end character of the selected text.”\nIn the following, I illustrate how the idea “replicate the hiddenstate of each word as often as the word has characters, so we get a hidden state for each character” is implemented. (Suppose we have $2$ words both having length $4$, with unique hidden states.)\n x = torch.tensor([[[1,2,5,7], [5,6,7,9]]])  x tensor([[[1, 2, 5, 7], [5, 6, 7, 9]]])  x.size() torch.Size([1, 2, 4])  x.unsqueeze(-1) tensor([[[[1], [2], [5], [7]], [[5], [6], [7], [9]]]])  x.unsqueeze(-1).size() torch.Size([1, 2, 4, 1])  x.unsqueeze(-1).expand(-1,-1,-1, 5) tensor([[[[1, 1, 1, 1, 1], [2, 2, 2, 2, 2], [5, 5, 5, 5, 5], [7, 7, 7, 7, 7]], [[5, 5, 5, 5, 5], [6, 6, 6, 6, 6], [7, 7, 7, 7, 7], [9, 9, 9, 9, 9]]]]) For the following ideas, we assume that we are writing a customized roberta model and here is the beginning of the customized roberta class:\nIdea 3: fastai style freeze-unfreeze scheme class CustomRoberta(nn.Module): def __init__(self, path='path/to/roberta-base/pytorch_model.bin'): super(CustomRoberta, self).__init__() config = RobertaConfig.from_pretrained( 'path/to/roberta-base/config.json', output_hidden_states=True) self.roberta = RobertaModel.from_pretrained(path, config=config) self.weights_init_custom() # ignore the detail def forward(*args): pass fastai style freeze-unfreeze scheme is the following:\ndef freeze(self): for child in self.roberta.children(): for param in child.parameters(): param.requires_grad = False def unfreeze(self): for child in self.roberta.children(): for param in child.parameters(): param.requires_grad = True idea 4: Customized Layer Initialization The following code is an initialization of the last three layers of the model.\ndef weights_init_custom(self): init_layers = [9, 10, 11] dense_names = [\"query\", \"key\", \"value\", \"dense\"] layernorm_names = [\"LayerNorm\"] for name, module in self.roberta.named_parameters(): if any(f\".{i}.\" in name for i in init_layers): if any(n in name for n in dense_names): if \"bias\" in name: module.data.zero_() elif \"weight\" in name: module.data.normal_(mean=0.0, std=0.02) elif any(n in name for n in layernorm_names): if \"bias\" in name: module.data.zero_() elif \"weight\" in name: module.data.fill_(1.0) Let’s break it into parts. Let’s see an example of a pair of name and module in self.roberta.named_parameters():\n name, module ('embeddings.word_embeddings.weight', Parameter containing: tensor([[ 0.1476, -0.0365, 0.0753, ..., -0.0023, 0.0172, -0.0016], [ 0.0156, 0.0076, -0.0118, ..., -0.0022, 0.0081, -0.0156], [-0.0347, -0.0873, -0.0180, ..., 0.1174, -0.0098, -0.0355], ..., [ 0.0304, 0.0504, -0.0307, ..., 0.0377, 0.0096, 0.0084], [ 0.0623, -0.0596, 0.0307, ..., -0.0920, 0.1080, -0.0183], [ 0.1259, -0.0145, 0.0332, ..., 0.0121, 0.0342, 0.0168]], requires_grad=True)) The followings are some examples of weights in the last three layers that they want to initialize:\nencoder.layer.9.attention.self.query.weight\nencoder.layer.9.attention.self.query.bias\nencoder.layer.9.attention.self.key.weight\nencoder.layer.9.attention.self.key.bias\nencoder.layer.9.attention.self.value.weight\nencoder.layer.9.attention.self.value.bias\nencoder.layer.9.attention.output.dense.weight\nencoder.layer.9.attention.output.dense.bias\nencoder.layer.9.attention.output.LayerNorm.weight\nencoder.layer.9.attention.output.LayerNorm.bias\nNoteworthy ideas in 4th place solution They also use the idea of re-ranking like in 2nd place team, but their re-ranking method is quite different, so I would like to do a summary of their ideas also.\nThey add four heads to each of their transformer model and here is the detail:\nHead 1:\nTake hidden states from the last two layers. Add a linear layer without any dropout for predicting start and end tokens (with label smoothing). This is common and used by each team.\nHead 2:\nTake hidden states from the last layer. Add a linear layer to predict binary target for each token: if it should be in selected text or not. Takes hidden states from the last layer. The loss in binary cross-entropy.\nHead 3:\nTake hidden states from the last layer. Add a linear layer to predict a sentiment of each token. Predicts three classes – neutral, positive and negative. Tokens from selected text are labeled as having the same sentiment as the tweet, while all other tokens are assigned neutral class. The loss in binary cross-entropy for each token separately.\nHead 4:\nTake hidden states from the last two layers. Concatenates mean and max pooling over all tokens in a tweet skipping cls and sentiment tokens. Add two linear layers with ReLU in between to predict the sentiment of the whole tweet (with MSD).\nTraining phase During training, the total loss is calculated as the weighted sum of losses from all four heads. Training is performed on $8$ folds with AdamW optimizer and using (Stochastic Weight Averaging) SWA over a get_cosine_with_hard_restarts_schedule_with_warmup scheduler for 10 epochs.\nInference phase Score 1 (from Head 1):\nThe first head is used to create a set of (start, end) candidates. Softmax is applied across all pairs to obtain probabilities for candidates and top $3$ of them are selected to be used for the further processing. Call the probability of a candidate from this head qa_prob.\nScore 2 (from Head 2):\nThe output of the second head is the set of logits: one for each token. To obtain a score for each of the selected (start, end) candidates they took the sigmoid from the tokens and calculated the average log of the resultant token probabilities across candidate tokens. Call the output number as score_per_token.\nScore 3 (from Head 3):\nThe output of the third head is used in a very similar way to the previous. The only difference is to take the softmax over each token logits instead of sigmoid since there are three classes of sentiments. Then the probability corresponding to the sentiment of the tweet is selected. Then the same averaging operation as for previous head is applied to obtain a score for candidates. Call it sentiment_per_token.\nFrom the above, at inference time they now have three (start, end) candidates with three scores assigned to each of them.\nSecond level model Similar to $2$nd team’s solution, they build a second level model on top of previous models.\nArchitecture Used ELECTRA with the following input:\n[CLS] ([POSITIVE]|[NEUTRAL]|[NEGATIVE]) tweet [SEP] selected_text_candidate [SEP]\nSingle head (linear-tanh-dropout-linear) on top of the transformer is fed with the concatenation of the cls token and the hidden states from the last two layers to predict if the current candidate for selected text is correct or not. Loss is computed with cross-entropy.\nTraining phase Dataset for training is built with all tweets each having three candidates from the previous model and also tweet with true selected_text is added if it is not present among candidates. Trained it for 3 epochs with AdamW and SWA.\nInference phase Three candidates for each tweet are scored with this model. It outputs two logits which are softmaxed and then the log of class 1 proba is taken as the score for the candidate. Will call it external_score in the following.\nSo after this step they have three candidates and each of them has four scores.\nThe final score for each candidate is the weighted sum of qa_prob, score_per_token, sentiment_per_token and external_score inside the model type (BERT, RoBERTa or ELECTRA) and then the weighted sum of these sums. The final prediction is the candidate with the largest score, which then goes through post-processing.\n Reference:\n 1st place solution: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159254 1st place solution code: https://www.kaggle.com/theoviel/character-level-model-magic 2nd place solution: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159310 2nd place solution code: https://www.kaggle.com/hiromoon166/inference-8models-seed100101-bucketing-2-ver2/input?select=pre_processed.txt#Inference-of-Reranking-model 2nd place post-processing: https://www.kaggle.com/futureboykid/2nd-place-post-processing 3rd place solution: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159910 3rd place solution code: https://github.com/suicao/tweet-extraction 4th place solution: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159499 5th place solution: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159268 Label Smoothing code: https://www.kaggle.com/shonenkov/tpu-training-super-fast-xlmroberta, https://github.com/pytorch/pytorch/issues/7455 Label Smoothing: https://www.flixstock.com/label-smoothing-an-ingredient-of-higher-model-accuracy, https://www.kaggle.com/shahules/tackle-with-label-smoothing-proved Multi-Sample Dropout for Accelerated Training and Better Generalization: https://arxiv.org/pdf/1905.09788.pdf https://stackoverflow.com/questions/50747947/embedding-in-pytorch sequence-bucketing: https://www.kaggle.com/bminixhofer/speed-up-your-rnn-with-sequence-bucketing#Implementation-\u0026-comparing-static-padding-with-sequence-bucketing Re-ranking in QA paper: https://arxiv.org/pdf/1906.03008.pdf Common model structure: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/143281 SWA: https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/  ","wordCount":"2936","inLanguage":"en","datePublished":"2020-07-02T00:00:00Z","dateModified":"2020-07-02T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://tangliyan.com/blog/posts/kaggle_tweet_sent2/"},"publisher":{"@type":"Organization","name":"Liyan Tang","logo":{"@type":"ImageObject","url":"https://tangliyan.com/blog/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://tangliyan.com/blog/ accesskey=h title="Liyan Tang (Alt + H)">Liyan Tang</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://tangliyan.com/blog/archives title=Archive>
<span>Archive</span>
</a>
</li>
<li>
<a href=https://tangliyan.com/blog/tags/ title=Tags>
<span>Tags</span>
</a>
</li>
<li>
<a href=https://tangliyan.com/blog/search/ title="Search (Alt + /)" accesskey=/>
<span>Search</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://tangliyan.com/blog/>Home</a>&nbsp;»&nbsp;<a href=https://tangliyan.com/blog/posts/>Posts</a></div>
<h1 class=post-title>
Kaggle: Tweet Sentiment Extraction - top solutions
</h1>
<div class=post-meta><span title="2020-07-02 00:00:00 +0000 UTC">July 2, 2020</span>&nbsp;·&nbsp;14 min
</div>
</header> <div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#note aria-label=Note>Note</a></li>
<li>
<a href=#noteworthy-ideas-in-1st-place-solution aria-label="Noteworthy ideas in 1st place solution">Noteworthy ideas in 1st place solution</a><ul>
<li>
<a href=#idea aria-label=Idea>Idea</a></li>
<li>
<a href=#second-level-models-architectures aria-label="Second level models Architectures">Second level models Architectures</a><ul>
<li>
<a href=#architecture-1-rnn aria-label="Architecture 1: RNN">Architecture 1: RNN</a></li>
<li>
<a href=#architecture-2-cnn aria-label="Architecture 2: CNN">Architecture 2: CNN</a></li>
<li>
<a href=#architecture-3-wavenet aria-label="Architecture 3: WaveNet">Architecture 3: WaveNet</a></li></ul>
</li>
<li>
<a href=#stacking-ensemble aria-label="stacking ensemble">stacking ensemble</a></li></ul>
</li>
<li>
<a href=#noteworthy-ideas-in-2nd-place-solution aria-label="Noteworthy ideas in 2nd place solution">Noteworthy ideas in 2nd place solution</a><ul>
<li>
<a href=#ensemble aria-label=Ensemble>Ensemble</a></li>
<li>
<a href=#post-processing-on-the-extra-space aria-label="Post-processing on the extra space">Post-processing on the extra space</a></li>
<li>
<a href=#reranking-model-training-create-multi-candidates-and-choose-best-one aria-label="Reranking-model training (Create multi candidates and choose best one)">Reranking-model training (Create multi candidates and choose best one)</a><ul>
<li>
<a href=#what-is-re-ranking aria-label="What is re-ranking">What is re-ranking</a></li>
<li>
<a href=#why-re-ranking aria-label="Why re-ranking">Why re-ranking</a></li>
<li>
<a href=#how-to-re-rank aria-label="How to re-rank">How to re-rank</a></li>
<li>
<a href=#re-ranking-model aria-label="Re-ranking model">Re-ranking model</a></li></ul>
</li>
<li>
<a href=#final-re-ranking-score aria-label="Final re-ranking score">Final re-ranking score</a></li>
<li>
<a href=#sequence-bucketing-dynamic-padding aria-label="sequence bucketing (dynamic padding)">sequence bucketing (dynamic padding)</a></li></ul>
</li>
<li>
<a href=#noteworthy-ideas-in-3rd-place-solution aria-label="Noteworthy ideas in 3rd place solution">Noteworthy ideas in 3rd place solution</a><ul>
<li>
<a href=#idea-1-normal-model-with-beamsearch-like-decoder aria-label="Idea 1: Normal model with beamsearch-like decoder">Idea 1: Normal model with beamsearch-like decoder</a><ul>
<li>
<a href=#general-explanation-for-idea-1 aria-label="General explanation for idea 1">General explanation for idea 1</a></li></ul>
</li>
<li>
<a href=#idea-2-character-level-model-with-gru-head aria-label="Idea 2: Character level model with GRU head">Idea 2: Character level model with GRU head</a><ul>
<li>
<a href=#general-explanation-for-idea-2 aria-label="General explanation for idea 2">General explanation for idea 2</a></li></ul>
</li>
<li>
<a href=#idea-3-fastai-style-freeze-unfreeze-scheme aria-label="Idea 3: fastai style freeze-unfreeze scheme">Idea 3: fastai style freeze-unfreeze scheme</a></li>
<li>
<a href=#idea-4-customized-layer-initialization aria-label="idea 4: Customized Layer Initialization">idea 4: Customized Layer Initialization</a></li></ul>
</li>
<li>
<a href=#noteworthy-ideas-in-4th-place-solution aria-label="Noteworthy ideas in 4th place solution">Noteworthy ideas in 4th place solution</a><ul>
<li>
<a href=#training-phase aria-label="Training phase">Training phase</a></li>
<li>
<a href=#inference-phase aria-label="Inference phase">Inference phase</a></li>
<li>
<a href=#second-level-model aria-label="Second level model">Second level model</a><ul>
<li>
<a href=#architecture aria-label=Architecture>Architecture</a></li>
<li>
<a href=#training-phase-1 aria-label="Training phase">Training phase</a></li>
<li>
<a href=#inference-phase-1 aria-label="Inference phase">Inference phase</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><h2 id=note>Note<a hidden class=anchor aria-hidden=true href=#note>#</a></h2>
<p>This post is the second part of overall summarization of the competition. The first half is <a href=https://liyantang.blog.csdn.net/article/details/107060211>here</a>.</p>
<h2 id=noteworthy-ideas-in-1st-place-solution>Noteworthy ideas in 1st place solution<a hidden class=anchor aria-hidden=true href=#noteworthy-ideas-in-1st-place-solution>#</a></h2>
<h3 id=idea>Idea<a hidden class=anchor aria-hidden=true href=#idea>#</a></h3>
<p><em>First step</em>:</p>
<p>Use transformers to extract token level start and end probabilities.</p>
<p><em>Second step</em>:</p>
<p>Feed these probabilities to a character level model. This step gives the team a huge improve on the final score since it handled the &ldquo;<em>noise</em>&rdquo; in the data properly.</p>
<p><em>Last step</em>:</p>
<p>Ensemble.</p>
<h3 id=second-level-models-architectures>Second level models Architectures<a hidden class=anchor aria-hidden=true href=#second-level-models-architectures>#</a></h3>
<p>The following three Char-NN architectures uses character-level probabilities as input. The first level models output token-level probabilities and the following code convert token-level probabilities to character-level probabilities. The idea in the following cide is to assigning each character the probability of the corresponding token.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>token_level_to_char_level</span>(text, offsets, preds):
    probas_char <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros(len(text))
    <span style=color:#66d9ef>for</span> i, offset <span style=color:#f92672>in</span> enumerate(offsets):
        <span style=color:#66d9ef>if</span> offset[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>or</span> offset[<span style=color:#ae81ff>1</span>]: <span style=color:#75715e># remove padding and sentiment</span>
            probas_char[offset[<span style=color:#ae81ff>0</span>]:offset[<span style=color:#ae81ff>1</span>]] <span style=color:#f92672>=</span> preds[i]
    
    <span style=color:#66d9ef>return</span> probas_char
</code></pre></div><p><strong>Things you need to know for nn.Embedding</strong></p>
<p>The following architectures all train the embedding from scratch. Here we want to shortly discuss how <code>nn.Embedding</code> works.</p>
<p><code>nn.Embedding</code> holds a Tensor of dimension (vocab_size, vector_size), <em>i.e.</em>, of (the size of the vocabulary, the dimension of each vector embedding), and a method that does the lookup. When you create an embedding layer, the Tensor is initialised randomly.</p>
<p>You can also add pretrained weights with the command <code>nn.Embedding.from_pretrained(weight)</code>.</p>
<h4 id=architecture-1-rnn>Architecture 1: RNN<a hidden class=anchor aria-hidden=true href=#architecture-1-rnn>#</a></h4>
<img src="https://img-blog.csdnimg.cn/20200701111810503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_1,color_FFFFFF,t_70#pic_center" width=700>
<p>In the following, the parameter <code>len_voc</code> is calculated by</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>tokenizer<span style=color:#f92672>.</span>fit_on_texts(df_train[<span style=color:#e6db74>&#39;text&#39;</span>]<span style=color:#f92672>.</span>values)
len_voc <span style=color:#f92672>=</span> len(tokenizer<span style=color:#f92672>.</span>word_index) <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>
</code></pre></div><p>Compare the following code with the figure above.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>TweetCharModel</span>(nn<span style=color:#f92672>.</span>Module):
    <span style=color:#75715e># check the config in the original code post</span>
    <span style=color:#66d9ef>def</span> __init__(self, len_voc, use_msd<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
                 embed_dim<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, lstm_dim<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, char_embed_dim<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, sent_embed_dim<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, ft_lstm_dim<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, n_models<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>):
        super()<span style=color:#f92672>.</span>__init__()
        self<span style=color:#f92672>.</span>use_msd <span style=color:#f92672>=</span> use_msd
        
        self<span style=color:#f92672>.</span>char_embeddings <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Embedding(len_voc, char_embed_dim)
        self<span style=color:#f92672>.</span>sentiment_embeddings <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Embedding(<span style=color:#ae81ff>3</span>, sent_embed_dim) <span style=color:#75715e># 3 sentiments</span>
        
        self<span style=color:#f92672>.</span>proba_lstm <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>LSTM(n_models <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span>, ft_lstm_dim, batch_first<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, bidirectional<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
        
        self<span style=color:#f92672>.</span>lstm <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>LSTM(char_embed_dim <span style=color:#f92672>+</span> ft_lstm_dim <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>+</span> sent_embed_dim, lstm_dim, batch_first<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, bidirectional<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
        self<span style=color:#f92672>.</span>lstm2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>LSTM(lstm_dim <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span>, lstm_dim, batch_first<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, bidirectional<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)

        self<span style=color:#f92672>.</span>logits <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
            nn<span style=color:#f92672>.</span>Linear(lstm_dim <span style=color:#f92672>*</span>  <span style=color:#ae81ff>4</span>, lstm_dim),
            nn<span style=color:#f92672>.</span>ReLU(),
            nn<span style=color:#f92672>.</span>Linear(lstm_dim, <span style=color:#ae81ff>2</span>))
        
        self<span style=color:#f92672>.</span>high_dropout <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Dropout(p<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>)
    
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, tokens, sentiment, start_probas, end_probas):
        bs, T <span style=color:#f92672>=</span> tokens<span style=color:#f92672>.</span>size()
        
        probas <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cat([start_probas, end_probas], <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
        probas_fts, _ <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>proba_lstm(probas)

        char_fts <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>char_embeddings(tokens)
        
        sentiment_fts <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sentiment_embeddings(sentiment)<span style=color:#f92672>.</span>view(bs, <span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
        sentiment_fts <span style=color:#f92672>=</span> sentiment_fts<span style=color:#f92672>.</span>repeat((<span style=color:#ae81ff>1</span>, T, <span style=color:#ae81ff>1</span>))
        
        features <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cat([char_fts, sentiment_fts, probas_fts], <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
        features, _ <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>lstm(features)
        features2, _ <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>lstm2(features)
        
        features <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cat([features, features2], <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
        
        <span style=color:#75715e># Multi-sample dropout (MSD)</span>
        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>use_msd <span style=color:#f92672>and</span> self<span style=color:#f92672>.</span>training:
            logits <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>mean(
                torch<span style=color:#f92672>.</span>stack(
                    [self<span style=color:#f92672>.</span>logits(self<span style=color:#f92672>.</span>high_dropout(features)) <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>5</span>)],
                    dim<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>),
                dim<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
        <span style=color:#66d9ef>else</span>:
            logits <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>logits(features)

        start_logits, end_logits <span style=color:#f92672>=</span> logits[:, :, <span style=color:#ae81ff>0</span>], logits[:, :, <span style=color:#ae81ff>1</span>]

        <span style=color:#66d9ef>return</span> start_logits, end_logits

</code></pre></div><h4 id=architecture-2-cnn>Architecture 2: CNN<a hidden class=anchor aria-hidden=true href=#architecture-2-cnn>#</a></h4>
<img src="https://img-blog.csdnimg.cn/20200701111959201.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_1,color_FFFFFF,t_70#pic_center" width=700>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>ConvBlock</span>(nn<span style=color:#f92672>.</span>Module):
    <span style=color:#75715e># check the config in the original code post</span>
    <span style=color:#66d9ef>def</span> __init__(self, in_channels, out_channels, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, dilation<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, padding<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;same&#34;</span>, use_bn<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>):
        super()<span style=color:#f92672>.</span>__init__()
        <span style=color:#66d9ef>if</span> padding <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;same&#34;</span>:
            padding <span style=color:#f92672>=</span> kernel_size <span style=color:#f92672>//</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> dilation
        
        <span style=color:#66d9ef>if</span> use_bn:
            self<span style=color:#f92672>.</span>conv <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
                nn<span style=color:#f92672>.</span>Conv1d(in_channels, out_channels, kernel_size, padding<span style=color:#f92672>=</span>padding, stride<span style=color:#f92672>=</span>stride, dilation<span style=color:#f92672>=</span>dilation),
                nn<span style=color:#f92672>.</span>BatchNorm1d(out_channels),
                nn<span style=color:#f92672>.</span>ReLU())
        <span style=color:#66d9ef>else</span>:
            self<span style=color:#f92672>.</span>conv <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
                nn<span style=color:#f92672>.</span>Conv1d(in_channels, out_channels, kernel_size, padding<span style=color:#f92672>=</span>padding, stride<span style=color:#f92672>=</span>stride, dilation<span style=color:#f92672>=</span>dilation),
                nn<span style=color:#f92672>.</span>ReLU())
                
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>conv(x)

<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>TweetCharModel</span>(nn<span style=color:#f92672>.</span>Module):
    <span style=color:#66d9ef>def</span> __init__(self, len_voc, use_msd<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
                 cnn_dim<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, char_embed_dim<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, sent_embed_dim<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, proba_cnn_dim<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, n_models<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, use_bn<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>):
        super()<span style=color:#f92672>.</span>__init__()
        self<span style=color:#f92672>.</span>use_msd <span style=color:#f92672>=</span> use_msd
        
        self<span style=color:#f92672>.</span>char_embeddings <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Embedding(len_voc, char_embed_dim)
        self<span style=color:#f92672>.</span>sentiment_embeddings <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Embedding(<span style=color:#ae81ff>3</span>, sent_embed_dim)
    
        self<span style=color:#f92672>.</span>probas_cnn <span style=color:#f92672>=</span> ConvBlock(n_models <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span>, proba_cnn_dim, kernel_size<span style=color:#f92672>=</span>kernel_size, use_bn<span style=color:#f92672>=</span>use_bn)
         
        self<span style=color:#f92672>.</span>cnn <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
            ConvBlock(char_embed_dim <span style=color:#f92672>+</span> sent_embed_dim <span style=color:#f92672>+</span> proba_cnn_dim, cnn_dim, kernel_size<span style=color:#f92672>=</span>kernel_size, use_bn<span style=color:#f92672>=</span>use_bn),
            ConvBlock(cnn_dim, cnn_dim <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span>, kernel_size<span style=color:#f92672>=</span>kernel_size, use_bn<span style=color:#f92672>=</span>use_bn),
            ConvBlock(cnn_dim <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span> , cnn_dim <span style=color:#f92672>*</span> <span style=color:#ae81ff>4</span>, kernel_size<span style=color:#f92672>=</span>kernel_size, use_bn<span style=color:#f92672>=</span>use_bn),
            ConvBlock(cnn_dim <span style=color:#f92672>*</span> <span style=color:#ae81ff>4</span>, cnn_dim <span style=color:#f92672>*</span> <span style=color:#ae81ff>8</span>, kernel_size<span style=color:#f92672>=</span>kernel_size, use_bn<span style=color:#f92672>=</span>use_bn))
        
        self<span style=color:#f92672>.</span>logits <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
            nn<span style=color:#f92672>.</span>Linear(cnn_dim <span style=color:#f92672>*</span> <span style=color:#ae81ff>8</span>, cnn_dim),
            nn<span style=color:#f92672>.</span>ReLU(),
            nn<span style=color:#f92672>.</span>Linear(cnn_dim, <span style=color:#ae81ff>2</span>))
        
        self<span style=color:#f92672>.</span>high_dropout <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Dropout(p<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>)
        
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, tokens, sentiment, start_probas, end_probas):
        bs, T <span style=color:#f92672>=</span> tokens<span style=color:#f92672>.</span>size()
        
        probas <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cat([start_probas, end_probas], <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>permute(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>)
        probas_fts <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>probas_cnn(probas)<span style=color:#f92672>.</span>permute(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>)

        char_fts <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>char_embeddings(tokens)
        
        sentiment_fts <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sentiment_embeddings(sentiment)<span style=color:#f92672>.</span>view(bs, <span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
        sentiment_fts <span style=color:#f92672>=</span> sentiment_fts<span style=color:#f92672>.</span>repeat((<span style=color:#ae81ff>1</span>, T, <span style=color:#ae81ff>1</span>))
        
        x <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cat([char_fts, sentiment_fts, probas_fts], <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>permute(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>)

        features <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>cnn(x)<span style=color:#f92672>.</span>permute(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>) <span style=color:#75715e># [Bs x T x nb_ft]</span>
    
        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>use_msd <span style=color:#f92672>and</span> self<span style=color:#f92672>.</span>training:
            logits <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>mean(
                torch<span style=color:#f92672>.</span>stack(
                    [self<span style=color:#f92672>.</span>logits(self<span style=color:#f92672>.</span>high_dropout(features)) <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>5</span>)],
                    dim<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>),
                dim<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
        <span style=color:#66d9ef>else</span>:
            logits <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>logits(features)

        start_logits, end_logits <span style=color:#f92672>=</span> logits[:, :, <span style=color:#ae81ff>0</span>], logits[:, :, <span style=color:#ae81ff>1</span>]

        <span style=color:#66d9ef>return</span> start_logits, end_logits

</code></pre></div><h4 id=architecture-3-wavenet>Architecture 3: WaveNet<a hidden class=anchor aria-hidden=true href=#architecture-3-wavenet>#</a></h4>
<p>This is a model architecture from another competition, so I ignore the author&rsquo;s detail here. I attached the source code in the reference.</p>
<h3 id=stacking-ensemble>stacking ensemble<a hidden class=anchor aria-hidden=true href=#stacking-ensemble>#</a></h3>
<p>Their solution has no post-processing and just modeling. The following is the idea how they did the final ensemble.</p>
<img src="https://img-blog.csdnimg.cn/20200701112234630.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_1,color_FFFFFF,t_70#pic_center" width=1000>
<img src="https://img-blog.csdnimg.cn/20200701113231351.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_1,color_FFFFFF,t_70#pic_center" width=900>
<h2 id=noteworthy-ideas-in-2nd-place-solution>Noteworthy ideas in 2nd place solution<a hidden class=anchor aria-hidden=true href=#noteworthy-ideas-in-2nd-place-solution>#</a></h2>
<h3 id=ensemble>Ensemble<a hidden class=anchor aria-hidden=true href=#ensemble>#</a></h3>
<ul>
<li>Using two different seeds (seed averaging):</li>
</ul>
<p><strong>RoBERTa Base 11th layer</strong> + <strong>RoBERTa Large 23th layer</strong> + <strong>RoBERTa Base MSD</strong> + <strong>RoBERTa Large MSD</strong></p>
<p>$4$ models $\times$ $2$ seeds = Total $8$ models</p>
<h3 id=post-processing-on-the-extra-space>Post-processing on the extra space<a hidden class=anchor aria-hidden=true href=#post-processing-on-the-extra-space>#</a></h3>
<p>I attached the pp in the reference. I tried out this pp and it raised my rank to around $20$th.</p>
<h3 id=reranking-model-training-create-multi-candidates-and-choose-best-one>Reranking-model training (Create multi candidates and choose best one)<a hidden class=anchor aria-hidden=true href=#reranking-model-training-create-multi-candidates-and-choose-best-one>#</a></h3>
<h4 id=what-is-re-ranking>What is re-ranking<a hidden class=anchor aria-hidden=true href=#what-is-re-ranking>#</a></h4>
<p>Their model can predict not only a top-$1$ selected_text candidate but also top-$n$ candidates. So re-ranking means that they re-score these top-$n$ candidate.</p>
<h4 id=why-re-ranking>Why re-ranking<a hidden class=anchor aria-hidden=true href=#why-re-ranking>#</a></h4>
<p>&ldquo;<em>I calculated the upper bound jaccard score of top-5 candidates in the validation set and that was 0.87-0.88. (If I choose only top-1, the score is only 0.71-0.72.)</em></p>
<p><em>So I realized that there is a huge room for improving score by re-ranking.
In fact, in the field of question answering (similar to this task), the re-ranking approach is developed.</em>&rdquo;</p>
<h4 id=how-to-re-rank>How to re-rank<a hidden class=anchor aria-hidden=true href=#how-to-re-rank>#</a></h4>
<p>To re-rank candidates, they used two score.</p>
<p>First one is based on start & end value(after applying softmax) from base-model. Second one is a predicted jaccard score using <em>re-ranking model</em>.</p>
<h4 id=re-ranking-model>Re-ranking model<a hidden class=anchor aria-hidden=true href=#re-ranking-model>#</a></h4>
<p><em>Build a second level model on top of previous model</em>.</p>
<ul>
<li>input: triple (sentiment, tweet, candidate)</li>
<li>predict: jaccard score</li>
</ul>
<p>The way they pass the tuple (sentiment, tweet, candidate) to the model is</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>tweet_candidate <span style=color:#f92672>=</span> TOKENIZER<span style=color:#f92672>.</span>encode(str(tweet) <span style=color:#f92672>+</span> <span style=color:#e6db74>&#34;  &#34;</span> <span style=color:#f92672>+</span> str(candidate))
token_ids <span style=color:#f92672>=</span> [<span style=color:#ae81ff>0</span>] <span style=color:#f92672>+</span> [sentiment] <span style=color:#f92672>+</span> [<span style=color:#ae81ff>2</span>] <span style=color:#f92672>+</span> [<span style=color:#ae81ff>2</span>] <span style=color:#f92672>+</span> tweet_candidate<span style=color:#f92672>.</span>ids <span style=color:#f92672>+</span> [<span style=color:#ae81ff>2</span>]
</code></pre></div><p>In concrete, they calculated top-$5$ candidates in training and validation set and memorize their jaccard score.</p>
<p>They use a simple roberta-base model to predict jaccard score using <code>MSELoss()</code>.</p>
<h3 id=final-re-ranking-score>Final re-ranking score<a hidden class=anchor aria-hidden=true href=#final-re-ranking-score>#</a></h3>
<p>Finally, candidates are re-ranked using this score.</p>
<p><code>(start value + end value) * 0.5 + predicted jaccard score</code></p>
<p>Here, start and end value means logits calculated by the base model (<em>i.e.</em> start and end position logits after softmax function). This part of the code is under the reference section.</p>
<h3 id=sequence-bucketing-dynamic-padding>sequence bucketing (dynamic padding)<a hidden class=anchor aria-hidden=true href=#sequence-bucketing-dynamic-padding>#</a></h3>
<p>Team:"<em>inference time speed up x2 and surprisingly got a better result than not using.</em>"</p>
<p>In RNNs, the input sequences are often all padded to the same length by doing something along the lines of this:</p>
<p><code>x_train = pad_sequences(x_train, maxlen=MAX_LEN)</code></p>
<p>This is suboptimal because when iterating over the dataset in batches, there will be some batches where the length of all samples is smaller than <code>MAX_LEN</code>. So there will be tokens which are zero everywhere in the batch but are still processed by the RNN. Using sequence bucketing, we can speed this up by dynamically padding every batch to the maximum sequence length which occurs in that batch. Or to <em>e.g.</em> the $95$th percentile of lengths in that batch.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>RerankingCollate</span>:
    <span style=color:#66d9ef>def</span> __init__(self):
        self<span style=color:#f92672>.</span>CONFIG <span style=color:#f92672>=</span> {}
        self<span style=color:#f92672>.</span>CONFIG[<span style=color:#e6db74>&#39;BUCKET&#39;</span>] <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>
        self<span style=color:#f92672>.</span>CONFIG[<span style=color:#e6db74>&#39;MAX_LEN&#39;</span>] <span style=color:#f92672>=</span> MAX_LEN

    <span style=color:#66d9ef>def</span> __call__(self, batch):
        out <span style=color:#f92672>=</span> {
                <span style=color:#e6db74>&#39;orig_tweet&#39;</span>        : [],
                <span style=color:#e6db74>&#39;sentiment&#39;</span>         : [],
                <span style=color:#e6db74>&#39;orig_selected&#39;</span>     : [],
                <span style=color:#e6db74>&#39;jaccard&#39;</span>           : [],
                <span style=color:#e6db74>&#39;score&#39;</span>             : [],
                <span style=color:#e6db74>&#39;ids&#39;</span>               : [], 
                <span style=color:#e6db74>&#39;mask&#39;</span>              : [], 
                <span style=color:#e6db74>&#39;token_type_ids&#39;</span>    : [], 
            }

        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(len(batch)):
            <span style=color:#66d9ef>for</span> k, v <span style=color:#f92672>in</span> batch[i]<span style=color:#f92672>.</span>items():
                out[k]<span style=color:#f92672>.</span>append(v)

        <span style=color:#75715e># Deciding the number of padding</span>
        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>CONFIG[<span style=color:#e6db74>&#39;BUCKET&#39;</span>]:
            max_pad <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
            <span style=color:#66d9ef>for</span> p <span style=color:#f92672>in</span> out[<span style=color:#e6db74>&#39;ids&#39;</span>]:
                <span style=color:#66d9ef>if</span> len(p)<span style=color:#f92672>&gt;</span>max_pad:
                    max_pad <span style=color:#f92672>=</span> len(p)
        <span style=color:#66d9ef>else</span>:
            max_pad <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>CONFIG[<span style=color:#e6db74>&#39;MAX_LEN&#39;</span>]
            
        <span style=color:#75715e># Padding</span>
        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(len(batch)):
            tokenized_text <span style=color:#f92672>=</span> out[<span style=color:#e6db74>&#39;ids&#39;</span>][i]
            token_type_ids <span style=color:#f92672>=</span> out[<span style=color:#e6db74>&#39;token_type_ids&#39;</span>][i]
            mask           <span style=color:#f92672>=</span> out[<span style=color:#e6db74>&#39;mask&#39;</span>][i]
            text_len       <span style=color:#f92672>=</span> len(tokenized_text)
            out[<span style=color:#e6db74>&#39;ids&#39;</span>][i]  <span style=color:#f92672>=</span> (tokenized_text <span style=color:#f92672>+</span> [<span style=color:#ae81ff>1</span>]<span style=color:#f92672>*</span>(max_pad <span style=color:#f92672>-</span> text_len))[:max_pad]
            out[<span style=color:#e6db74>&#39;token_type_ids&#39;</span>][i] <span style=color:#f92672>=</span> (token_type_ids <span style=color:#f92672>+</span> [<span style=color:#ae81ff>0</span>]<span style=color:#f92672>*</span>(max_pad <span style=color:#f92672>-</span> text_len)[:max_pad]
            out[<span style=color:#e6db74>&#39;mask&#39;</span>][i] <span style=color:#f92672>=</span> (mask <span style=color:#f92672>+</span> [<span style=color:#ae81ff>0</span>]<span style=color:#f92672>*</span>(max_pad <span style=color:#f92672>-</span> text_len))[:max_pad]

        <span style=color:#75715e># torch.float</span>
        out[<span style=color:#e6db74>&#39;jaccard&#39;</span>] <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(out[<span style=color:#e6db74>&#39;jaccard&#39;</span>], dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>float)
        out[<span style=color:#e6db74>&#39;score&#39;</span>]   <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(out[<span style=color:#e6db74>&#39;score&#39;</span>], dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>float)
        <span style=color:#75715e># torch.long</span>
        out[<span style=color:#e6db74>&#39;ids&#39;</span>] <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(out[<span style=color:#e6db74>&#39;ids&#39;</span>], dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>long)
        out[<span style=color:#e6db74>&#39;mask&#39;</span>] <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(out[<span style=color:#e6db74>&#39;mask&#39;</span>], dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>long)
        out[<span style=color:#e6db74>&#39;token_type_ids&#39;</span>] <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(out[<span style=color:#e6db74>&#39;token_type_ids&#39;</span>], dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>long)

        <span style=color:#66d9ef>return</span> out
</code></pre></div><p>Here is how to use it:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>valid_data_loader <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>utils<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>DataLoader(
    valid_dataset,
    batch_size<span style=color:#f92672>=</span>val_nums,
    collate_fn<span style=color:#f92672>=</span>RerankingCollate(),
    num_workers<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,
)
</code></pre></div><h2 id=noteworthy-ideas-in-3rd-place-solution>Noteworthy ideas in 3rd place solution<a hidden class=anchor aria-hidden=true href=#noteworthy-ideas-in-3rd-place-solution>#</a></h2>
<h3 id=idea-1-normal-model-with-beamsearch-like-decoder>Idea 1: Normal model with beamsearch-like decoder<a hidden class=anchor aria-hidden=true href=#idea-1-normal-model-with-beamsearch-like-decoder>#</a></h3>
<p>Copied XLNet&rsquo;s decoder head for question answering to RoBERTa. Basically you predict the start index, get the $k$ hidden states at the top-$k$ indices. For each hidden state, concat it to the end index logits and predict the corresponding top-$k$ end indices. The best $k$ is 3, for whatever reasons, which resulted in a $3 \times 3$ start-end pairs. I ranked them by taking the product of the two probs.</p>
<h4 id=general-explanation-for-idea-1>General explanation for idea 1<a hidden class=anchor aria-hidden=true href=#general-explanation-for-idea-1>#</a></h4>
<p>Training Step:</p>
<ul>
<li>Predict the start index normally.</li>
<li>Take the hidden representation at the target index (ignoring the predicted) and concat it into the representations at every position.</li>
<li>The new presentation is then fed to a MLP to predict the end index.</li>
</ul>
<img src="https://img-blog.csdnimg.cn/20200701112727825.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_1,color_FFFFFF,t_70#pic_center" width=650>
<p>Inference:</p>
<ul>
<li>Predicting the start index normally.</li>
<li>Take top-$k$ hidden states corresponding to top-$k$ start indices with highest probabilities.</li>
<li>Each hidden state is then concatenated into the representations at every position.</li>
<li>The new representation is fed to a MLP, similar to training. Then select top-$k$ end indices for each selected hidden state, resulting in $k \times k$ top start-end pairs.</li>
<li>The best k is $3$, which resulted in a $3 \times 3$ start-end pairs. They ranked them by taking the product of the two probs.</li>
</ul>
<img src="https://img-blog.csdnimg.cn/20200701112822997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_1,color_FFFFFF,t_70#pic_center" width=750>
<h3 id=idea-2-character-level-model-with-gru-head>Idea 2: Character level model with GRU head<a hidden class=anchor aria-hidden=true href=#idea-2-character-level-model-with-gru-head>#</a></h3>
<p>Address the noisy targets by adding a prediction head that enables character wise span-prediction and completely learns the noise. They trained all models using a 5-seed average. Their best submission consists of a total of 3x5x2 models (backbones x seeds x team mates).</p>
<h4 id=general-explanation-for-idea-2>General explanation for idea 2<a hidden class=anchor aria-hidden=true href=#general-explanation-for-idea-2>#</a></h4>
<p>They realized that the key to a decent performance is the capability to predict a character-wise span. A good example, which they are also using in the illustration below is the tweet text “is back home now gonna miss everyone” which weirdly had the label “onna”. They knew that if a model would be able to predict “onna”, that would put them in a top spot.</p>
<img src="https://img-blog.csdnimg.cn/20200701112907968.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_1,color_FFFFFF,t_70#pic_center" width=850>
<p>In fact a character-wise prediction would solves two issues:</p>
<ul>
<li>Definition of label: you now can just put the selected text as it as label.</li>
<li>Predicting noise: you now are able to predict “half words” which was the key of the competition.</li>
</ul>
<p>The key idea of this method is that &ldquo;<em>The model uses a standard transformer backbone which takes the word-level tokenized text and outputs hidden states with a certain dimension (in case of roberta-base 768). Instead of predicting the start and end word now, as done by “standard” models I replicate the hiddenstate of each word as often as the word has characters, so we get a hidden state for each character. In order to differentiate between characters I add a few 768 -> 768 RNN layers. Finally, two linear layers predict the start and end character of the selected text.</em>&rdquo;</p>
<p>In the following, I illustrate how the idea &ldquo;<em>replicate the hiddenstate of each word as often as the word has characters, so we get a hidden state for each character</em>&rdquo; is implemented. <em>(Suppose we have $2$ words both having length $4$, with unique hidden states.)</em></p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> x <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor([[[<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>2</span>,<span style=color:#ae81ff>5</span>,<span style=color:#ae81ff>7</span>], [<span style=color:#ae81ff>5</span>,<span style=color:#ae81ff>6</span>,<span style=color:#ae81ff>7</span>,<span style=color:#ae81ff>9</span>]]])
<span style=color:#f92672>&gt;&gt;&gt;</span> x
tensor([[[<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>7</span>],
         [<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>9</span>]]])

<span style=color:#f92672>&gt;&gt;&gt;</span> x<span style=color:#f92672>.</span>size()
torch<span style=color:#f92672>.</span>Size([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>])

<span style=color:#f92672>&gt;&gt;&gt;</span> x<span style=color:#f92672>.</span>unsqueeze(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
tensor([[[[<span style=color:#ae81ff>1</span>],
          [<span style=color:#ae81ff>2</span>],
          [<span style=color:#ae81ff>5</span>],
          [<span style=color:#ae81ff>7</span>]],

         [[<span style=color:#ae81ff>5</span>],
          [<span style=color:#ae81ff>6</span>],
          [<span style=color:#ae81ff>7</span>],
          [<span style=color:#ae81ff>9</span>]]]])

<span style=color:#f92672>&gt;&gt;&gt;</span> x<span style=color:#f92672>.</span>unsqueeze(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>size()
torch<span style=color:#f92672>.</span>Size([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>1</span>])

<span style=color:#f92672>&gt;&gt;&gt;</span> x<span style=color:#f92672>.</span>unsqueeze(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>expand(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>5</span>)
tensor([[[[<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>],
          [<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>],
          [<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>],
          [<span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>7</span>]],

         [[<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>],
          [<span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>6</span>],
          [<span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>7</span>],
          [<span style=color:#ae81ff>9</span>, <span style=color:#ae81ff>9</span>, <span style=color:#ae81ff>9</span>, <span style=color:#ae81ff>9</span>, <span style=color:#ae81ff>9</span>]]]])
</code></pre></div><p>For the following ideas, we assume that we are writing a customized roberta model and here is the beginning of the customized roberta class:</p>
<h3 id=idea-3-fastai-style-freeze-unfreeze-scheme>Idea 3: fastai style freeze-unfreeze scheme<a hidden class=anchor aria-hidden=true href=#idea-3-fastai-style-freeze-unfreeze-scheme>#</a></h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>CustomRoberta</span>(nn<span style=color:#f92672>.</span>Module):

    <span style=color:#66d9ef>def</span> __init__(self, path<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;path/to/roberta-base/pytorch_model.bin&#39;</span>):
        super(CustomRoberta, self)<span style=color:#f92672>.</span>__init__()
        
        config <span style=color:#f92672>=</span> RobertaConfig<span style=color:#f92672>.</span>from_pretrained(
            <span style=color:#e6db74>&#39;path/to/roberta-base/config.json&#39;</span>, output_hidden_states<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>) 

        self<span style=color:#f92672>.</span>roberta <span style=color:#f92672>=</span> RobertaModel<span style=color:#f92672>.</span>from_pretrained(path, config<span style=color:#f92672>=</span>config)
        self<span style=color:#f92672>.</span>weights_init_custom()
     
    <span style=color:#75715e># ignore the detail</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(<span style=color:#f92672>*</span>args):
        <span style=color:#66d9ef>pass</span>
</code></pre></div><p>fastai style freeze-unfreeze scheme is the following:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>freeze</span>(self):
    <span style=color:#66d9ef>for</span> child <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>roberta<span style=color:#f92672>.</span>children():
        <span style=color:#66d9ef>for</span> param <span style=color:#f92672>in</span> child<span style=color:#f92672>.</span>parameters():
            param<span style=color:#f92672>.</span>requires_grad <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span>

<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>unfreeze</span>(self):
    <span style=color:#66d9ef>for</span> child <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>roberta<span style=color:#f92672>.</span>children():
        <span style=color:#66d9ef>for</span> param <span style=color:#f92672>in</span> child<span style=color:#f92672>.</span>parameters():
            param<span style=color:#f92672>.</span>requires_grad <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>
</code></pre></div><h3 id=idea-4-customized-layer-initialization>idea 4: Customized Layer Initialization<a hidden class=anchor aria-hidden=true href=#idea-4-customized-layer-initialization>#</a></h3>
<p>The following code is an initialization of the last three layers of the model.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>weights_init_custom</span>(self):
    init_layers <span style=color:#f92672>=</span> [<span style=color:#ae81ff>9</span>, <span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>11</span>]
    dense_names <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;query&#34;</span>, <span style=color:#e6db74>&#34;key&#34;</span>, <span style=color:#e6db74>&#34;value&#34;</span>, <span style=color:#e6db74>&#34;dense&#34;</span>]
    layernorm_names <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;LayerNorm&#34;</span>]
    <span style=color:#66d9ef>for</span> name, module <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>roberta<span style=color:#f92672>.</span>named_parameters():
        <span style=color:#66d9ef>if</span> any(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;.</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74>.&#34;</span> <span style=color:#f92672>in</span> name <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> init_layers):
            <span style=color:#66d9ef>if</span> any(n <span style=color:#f92672>in</span> name <span style=color:#66d9ef>for</span> n <span style=color:#f92672>in</span> dense_names):
                <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#34;bias&#34;</span> <span style=color:#f92672>in</span> name:
                    module<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>zero_()
                <span style=color:#66d9ef>elif</span> <span style=color:#e6db74>&#34;weight&#34;</span> <span style=color:#f92672>in</span> name:
                    module<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>normal_(mean<span style=color:#f92672>=</span><span style=color:#ae81ff>0.0</span>, std<span style=color:#f92672>=</span><span style=color:#ae81ff>0.02</span>)
            <span style=color:#66d9ef>elif</span> any(n <span style=color:#f92672>in</span> name <span style=color:#66d9ef>for</span> n <span style=color:#f92672>in</span> layernorm_names):
                <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#34;bias&#34;</span> <span style=color:#f92672>in</span> name:
                        module<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>zero_()
                <span style=color:#66d9ef>elif</span> <span style=color:#e6db74>&#34;weight&#34;</span> <span style=color:#f92672>in</span> name:
                    module<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>fill_(<span style=color:#ae81ff>1.0</span>) 
</code></pre></div><p>Let&rsquo;s break it into parts. Let&rsquo;s see an example of a pair of <code>name</code> and <code>module</code> in <code>self.roberta.named_parameters()</code>:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> name, module
(<span style=color:#e6db74>&#39;embeddings.word_embeddings.weight&#39;</span>, Parameter containing:
 tensor([[ <span style=color:#ae81ff>0.1476</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0365</span>,  <span style=color:#ae81ff>0.0753</span>,  <span style=color:#f92672>...</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0023</span>,  <span style=color:#ae81ff>0.0172</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0016</span>],
         [ <span style=color:#ae81ff>0.0156</span>,  <span style=color:#ae81ff>0.0076</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0118</span>,  <span style=color:#f92672>...</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0022</span>,  <span style=color:#ae81ff>0.0081</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0156</span>],
         [<span style=color:#f92672>-</span><span style=color:#ae81ff>0.0347</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0873</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0180</span>,  <span style=color:#f92672>...</span>,  <span style=color:#ae81ff>0.1174</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0098</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0355</span>],
         <span style=color:#f92672>...</span>,
         [ <span style=color:#ae81ff>0.0304</span>,  <span style=color:#ae81ff>0.0504</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0307</span>,  <span style=color:#f92672>...</span>,  <span style=color:#ae81ff>0.0377</span>,  <span style=color:#ae81ff>0.0096</span>,  <span style=color:#ae81ff>0.0084</span>],
         [ <span style=color:#ae81ff>0.0623</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0596</span>,  <span style=color:#ae81ff>0.0307</span>,  <span style=color:#f92672>...</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0920</span>,  <span style=color:#ae81ff>0.1080</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0183</span>],
         [ <span style=color:#ae81ff>0.1259</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0145</span>,  <span style=color:#ae81ff>0.0332</span>,  <span style=color:#f92672>...</span>,  <span style=color:#ae81ff>0.0121</span>,  <span style=color:#ae81ff>0.0342</span>,  <span style=color:#ae81ff>0.0168</span>]],
        requires_grad<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>))
</code></pre></div><p>The followings are some examples of weights in the last three layers that they want to initialize:</p>
<p><code>encoder.layer.9.attention.self.query.weight</code><br>
<code>encoder.layer.9.attention.self.query.bias</code><br>
<code>encoder.layer.9.attention.self.key.weight</code><br>
<code>encoder.layer.9.attention.self.key.bias</code><br>
<code>encoder.layer.9.attention.self.value.weight</code><br>
<code>encoder.layer.9.attention.self.value.bias</code><br>
<code>encoder.layer.9.attention.output.dense.weight</code><br>
<code>encoder.layer.9.attention.output.dense.bias</code><br>
<code>encoder.layer.9.attention.output.LayerNorm.weight</code><br>
<code>encoder.layer.9.attention.output.LayerNorm.bias</code></p>
<h2 id=noteworthy-ideas-in-4th-place-solution>Noteworthy ideas in 4th place solution<a hidden class=anchor aria-hidden=true href=#noteworthy-ideas-in-4th-place-solution>#</a></h2>
<p>They also use the idea of re-ranking like in 2nd place team, but their re-ranking method is quite different, so I would like to do a summary of their ideas also.</p>
<p>They add four heads to each of their transformer model and here is the detail:</p>
<p><strong>Head 1</strong>:</p>
<p>Take hidden states from the last two layers. Add a linear layer without any dropout for predicting start and end tokens (with label smoothing). This is common and used by each team.</p>
<p><strong>Head 2</strong>:</p>
<p>Take hidden states from the last layer. Add a linear layer to predict binary target for each token: if it should be in selected text or not. Takes hidden states from the last layer. The loss in binary cross-entropy.</p>
<p><strong>Head 3</strong>:</p>
<p>Take hidden states from the last layer. Add a linear layer to predict a sentiment of each token. Predicts three classes – neutral, positive and negative. Tokens from selected text are labeled as having the same sentiment as the tweet, while all other tokens are assigned neutral class. The loss in binary cross-entropy for each token separately.</p>
<p><strong>Head 4</strong>:</p>
<p>Take hidden states from the last two layers. Concatenates mean and max pooling over all tokens in a tweet skipping <code>cls</code> and <code>sentiment</code> tokens. Add two linear layers with ReLU in between to predict the sentiment of the whole tweet (with MSD).</p>
<h3 id=training-phase>Training phase<a hidden class=anchor aria-hidden=true href=#training-phase>#</a></h3>
<p>During training, the total loss is calculated as the weighted sum of losses from all four heads. Training is performed on $8$ folds with AdamW optimizer and using (Stochastic Weight Averaging) SWA over a <code>get_cosine_with_hard_restarts_schedule_with_warmup</code> scheduler for 10 epochs.</p>
<img src=https://img-blog.csdnimg.cn/20200701113054407.png#pic_center width=700>
<h3 id=inference-phase>Inference phase<a hidden class=anchor aria-hidden=true href=#inference-phase>#</a></h3>
<p><strong>Score 1 (from Head 1):</strong></p>
<p>The first head is used to create a set of (start, end) candidates. Softmax is applied across all pairs to obtain probabilities for candidates and top $3$ of them are selected to be used for the further processing. Call the probability of a candidate from this head <code>qa_prob</code>.</p>
<p><strong>Score 2 (from Head 2):</strong></p>
<p>The output of the second head is the set of logits: one for each token. To obtain a score for each of the selected (start, end) candidates they took the sigmoid from the tokens and calculated the average log of the resultant token probabilities across candidate tokens. Call the output number as <code>score_per_token</code>.</p>
<p><strong>Score 3 (from Head 3):</strong></p>
<p>The output of the third head is used in a very similar way to the previous. The only difference is to take the softmax over each token logits instead of sigmoid since there are three classes of sentiments. Then the probability corresponding to the sentiment of the tweet is selected. Then the same averaging operation as for previous head is applied to obtain a score for candidates. Call it <code>sentiment_per_token</code>.</p>
<p>From the above, at inference time they now have three (start, end) candidates with three scores assigned to each of them.</p>
<h3 id=second-level-model>Second level model<a hidden class=anchor aria-hidden=true href=#second-level-model>#</a></h3>
<p>Similar to $2$nd team&rsquo;s solution, they build a second level model on top of previous models.</p>
<h4 id=architecture>Architecture<a hidden class=anchor aria-hidden=true href=#architecture>#</a></h4>
<p>Used ELECTRA with the following input:</p>
<p><code>[CLS] ([POSITIVE]|[NEUTRAL]|[NEGATIVE]) tweet [SEP] selected_text_candidate [SEP]</code></p>
<p>Single head (linear->tanh->dropout->linear) on top of the transformer is fed with the concatenation of the <code>cls</code> token and the hidden states from the last two layers to predict if the current candidate for selected text is correct or not. Loss is computed with cross-entropy.</p>
<h4 id=training-phase-1>Training phase<a hidden class=anchor aria-hidden=true href=#training-phase-1>#</a></h4>
<p>Dataset for training is built with all tweets each having three candidates from the previous model and also tweet with true selected_text is added if it is not present among candidates. Trained it for 3 epochs with AdamW and SWA.</p>
<h4 id=inference-phase-1>Inference phase<a hidden class=anchor aria-hidden=true href=#inference-phase-1>#</a></h4>
<p>Three candidates for each tweet are scored with this model. It outputs two logits which are softmaxed and then the log of class 1 proba is taken as the score for the candidate. Will call it <code>external_score</code> in the following.</p>
<p>So after this step they have three candidates and each of them has four scores.</p>
<p>The final score for each candidate is the weighted sum of <code>qa_prob</code>, <code>score_per_token</code>, <code>sentiment_per_token</code> and <code>external_score</code> inside the model type (BERT, RoBERTa or ELECTRA) and then the weighted sum of these sums. The final prediction is the candidate with the largest score, which then goes through post-processing.</p>
<hr>
<p>Reference:</p>
<ul>
<li>1st place solution: <a href=https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159254>https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159254</a></li>
<li>1st place solution code: <a href=https://www.kaggle.com/theoviel/character-level-model-magic>https://www.kaggle.com/theoviel/character-level-model-magic</a></li>
<li>2nd place solution: <a href=https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159310>https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159310</a></li>
<li>2nd place solution code: <a href="https://www.kaggle.com/hiromoon166/inference-8models-seed100101-bucketing-2-ver2/input?select=pre_processed.txt#Inference-of-Reranking-model">https://www.kaggle.com/hiromoon166/inference-8models-seed100101-bucketing-2-ver2/input?select=pre_processed.txt#Inference-of-Reranking-model</a></li>
<li>2nd place post-processing: <a href=https://www.kaggle.com/futureboykid/2nd-place-post-processing>https://www.kaggle.com/futureboykid/2nd-place-post-processing</a></li>
<li>3rd place solution: <a href=https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159910>https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159910</a></li>
<li>3rd place solution code: <a href=https://github.com/suicao/tweet-extraction>https://github.com/suicao/tweet-extraction</a></li>
<li>4th place solution: <a href=https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159499>https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159499</a></li>
<li>5th place solution: <a href=https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159268>https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/159268</a></li>
<li>Label Smoothing code: <a href=https://www.kaggle.com/shonenkov/tpu-training-super-fast-xlmroberta>https://www.kaggle.com/shonenkov/tpu-training-super-fast-xlmroberta</a>, <a href=https://github.com/pytorch/pytorch/issues/7455>https://github.com/pytorch/pytorch/issues/7455</a></li>
<li>Label Smoothing: <a href=https://www.flixstock.com/label-smoothing-an-ingredient-of-higher-model-accuracy>https://www.flixstock.com/label-smoothing-an-ingredient-of-higher-model-accuracy</a>, <a href=https://www.kaggle.com/shahules/tackle-with-label-smoothing-proved>https://www.kaggle.com/shahules/tackle-with-label-smoothing-proved</a></li>
<li><em>Multi-Sample Dropout for Accelerated Training and Better Generalization</em>: <a href=https://arxiv.org/pdf/1905.09788.pdf>https://arxiv.org/pdf/1905.09788.pdf</a></li>
<li><a href=https://stackoverflow.com/questions/50747947/embedding-in-pytorch>https://stackoverflow.com/questions/50747947/embedding-in-pytorch</a></li>
<li>sequence-bucketing: <a href=https://www.kaggle.com/bminixhofer/speed-up-your-rnn-with-sequence-bucketing#Implementation-&-comparing-static-padding-with-sequence-bucketing>https://www.kaggle.com/bminixhofer/speed-up-your-rnn-with-sequence-bucketing#Implementation-&-comparing-static-padding-with-sequence-bucketing</a></li>
<li>Re-ranking in QA paper: <a href=https://arxiv.org/pdf/1906.03008.pdf>https://arxiv.org/pdf/1906.03008.pdf</a></li>
<li>Common model structure: <a href=https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/143281>https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/143281</a></li>
<li>SWA: <a href=https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/>https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/</a></li>
</ul>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://tangliyan.com/blog/tags/nlp/>NLP</a></li>
<li><a href=https://tangliyan.com/blog/tags/competition/>COMPETITION</a></li>
</ul>
<nav class=paginav>
<a class=prev href=https://tangliyan.com/blog/posts/distillation/>
<span class=title>« Prev Page</span>
<br>
<span>Knowledge Distillation</span>
</a>
<a class=next href=https://tangliyan.com/blog/posts/kaggle_tweet_sent1/>
<span class=title>Next Page »</span>
<br>
<span>Kaggle: Tweet Sentiment Extraction - common methods</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Kaggle: Tweet Sentiment Extraction - top solutions on twitter" href="https://twitter.com/intent/tweet/?text=Kaggle%3a%20Tweet%20Sentiment%20Extraction%20-%20top%20solutions&url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fkaggle_tweet_sent2%2f&hashtags=NLP%2cCOMPETITION"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Kaggle: Tweet Sentiment Extraction - top solutions on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fkaggle_tweet_sent2%2f&title=Kaggle%3a%20Tweet%20Sentiment%20Extraction%20-%20top%20solutions&summary=Kaggle%3a%20Tweet%20Sentiment%20Extraction%20-%20top%20solutions&source=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fkaggle_tweet_sent2%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Kaggle: Tweet Sentiment Extraction - top solutions on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fkaggle_tweet_sent2%2f&title=Kaggle%3a%20Tweet%20Sentiment%20Extraction%20-%20top%20solutions"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Kaggle: Tweet Sentiment Extraction - top solutions on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fkaggle_tweet_sent2%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Kaggle: Tweet Sentiment Extraction - top solutions on whatsapp" href="https://api.whatsapp.com/send?text=Kaggle%3a%20Tweet%20Sentiment%20Extraction%20-%20top%20solutions%20-%20https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fkaggle_tweet_sent2%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Kaggle: Tweet Sentiment Extraction - top solutions on telegram" href="https://telegram.me/share/url?text=Kaggle%3a%20Tweet%20Sentiment%20Extraction%20-%20top%20solutions&url=https%3a%2f%2ftangliyan.com%2fblog%2fposts%2fkaggle_tweet_sent2%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href=https://tangliyan.com/blog/>Liyan Tang</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
<script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script>
</body>
</html>